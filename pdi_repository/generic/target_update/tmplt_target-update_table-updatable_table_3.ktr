<transformation>
  <info>
    <name>tmplt_target-update_table-updatable_table_3</name>
    <description />
    <extended_description />
    <trans_version />
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>/generic/target_update</directory>
    <parameters>
      <parameter>
        <name>PARAM_CDC_CURRENT_LOAD_UTC</name>
        <default_value>1900.01.01 00:00:00</default_value>
        <description>Timestamp of the current load (no rows after this timestamp will be loaded)</description>
      </parameter>
      <parameter>
        <name>PARAM_CDC_LAST_LOAD_UTC</name>
        <default_value>1900.01.01 00:00:00</default_value>
        <description>Timestamp for when the target DB was most recently updated successfully</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE</name>
        <default_value />
        <description />
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER</name>
        <default_value />
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_HOST</name>
        <default_value />
        <description />
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD</name>
        <default_value />
        <description />
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_PORT</name>
        <default_value />
        <description />
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_URL</name>
        <default_value />
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME</name>
        <default_value />
        <description />
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_DATABASE</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_DRIVER</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_HOST</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_PORT</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_URL</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_USERNAME</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_ETL_RUN_ID</name>
        <default_value />
        <description>Primary key for the ${QF_ETL_DB_SCHEMA}.etl_run row for the current "run"</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_INSERTED_ON_COLNAME</name>
        <default_value>inserted_on</default_value>
        <description>Name of column acting as "inserted_on" timestamp column of source table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_INSERT_ID_COLNAME</name>
        <default_value>insert_id</default_value>
        <description>Name of column acting as "insert_id" column of source table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_LAST_UPDATED_ON_COLNAME</name>
        <default_value>last_updated_on</default_value>
        <description>Name of "last_updated_on" timestamp column of source table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_SCHEMA</name>
        <default_value>passage</default_value>
        <description>Name of schema containing source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_TABLE</name>
        <default_value>passage</default_value>
        <description>Name of source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_TABLE_MAX_INSERT_ID</name>
        <default_value>0</default_value>
        <description>Maximum value of the "insert_id" column for rows to load from the source DB table</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_INSERTED_ON_COLNAME</name>
        <default_value>inserted_on</default_value>
        <description>Name of column acting as "inserted_on" timestamp column of target table</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_INSERT_ID_COLNAME</name>
        <default_value>insert_id</default_value>
        <description>Name of column acting as "insert_id" column of target table</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_LAST_UPDATED_ON_COLNAME</name>
        <default_value>last_updated_on</default_value>
        <description>Name of "last_updated_on" timestamp column of target table</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_SCHEMA</name>
        <default_value>passage</default_value>
        <description>Name of schema containing target table to update</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_TABLE</name>
        <default_value>passage</default_value>
        <description>Name of target table to update</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_TABLE_UPDATE_ID</name>
        <default_value />
        <description>Primary key of ${QF_ETL_DB_SCHEMA}.target_table_update row to be updated by this job for progress and summary statistics</description>
      </parameter>
    </parameters>
    <log>
      <trans-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANS_SCHEMA}</schema>
        <table>${QF_LOG_TRANS_TABLE}</table>
        <size_limit_lines />
        <interval />
        <timeout_days>${QF_LOG_TRANS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STATUS</id>
          <enabled>Y</enabled>
          <name>STATUS</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
          <subject>Table output - target_db.schema.table</subject>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
          <subject>Table output - target_db.schema.table</subject>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
          <subject>Table output - target_db.schema.table</subject>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
          <subject>Table input -  source_db.schema.table</subject>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
          <subject>Table output - target_db.schema.table</subject>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
          <subject>Table output - target_db.schema.table</subject>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>STARTDATE</id>
          <enabled>Y</enabled>
          <name>STARTDATE</name>
        </field>
        <field>
          <id>ENDDATE</id>
          <enabled>Y</enabled>
          <name>ENDDATE</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>DEPDATE</id>
          <enabled>Y</enabled>
          <name>DEPDATE</name>
        </field>
        <field>
          <id>REPLAYDATE</id>
          <enabled>Y</enabled>
          <name>REPLAYDATE</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>Y</enabled>
          <name>LOG_FIELD</name>
        </field>
        <field>
          <id>EXECUTING_SERVER</id>
          <enabled>N</enabled>
          <name>EXECUTING_SERVER</name>
        </field>
        <field>
          <id>EXECUTING_USER</id>
          <enabled>N</enabled>
          <name>EXECUTING_USER</name>
        </field>
        <field>
          <id>CLIENT</id>
          <enabled>N</enabled>
          <name>CLIENT</name>
        </field>
      </trans-log-table>
      <perf-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSPERF_SCHEMA}</schema>
        <table>${QF_LOG_TRANSPERF_TABLE}</table>
        <interval />
        <timeout_days>${QF_LOG_TRANSPERF_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>SEQ_NR</id>
          <enabled>Y</enabled>
          <name>SEQ_NR</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>INPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>INPUT_BUFFER_ROWS</name>
        </field>
        <field>
          <id>OUTPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>OUTPUT_BUFFER_ROWS</name>
        </field>
      </perf-log-table>
      <channel-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_CHANNEL_SCHEMA}</schema>
        <table>${QF_LOG_CHANNEL_TABLE}</table>
        <timeout_days>${QF_LOG_CHANNEL_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>LOGGING_OBJECT_TYPE</id>
          <enabled>Y</enabled>
          <name>LOGGING_OBJECT_TYPE</name>
        </field>
        <field>
          <id>OBJECT_NAME</id>
          <enabled>Y</enabled>
          <name>OBJECT_NAME</name>
        </field>
        <field>
          <id>OBJECT_COPY</id>
          <enabled>Y</enabled>
          <name>OBJECT_COPY</name>
        </field>
        <field>
          <id>REPOSITORY_DIRECTORY</id>
          <enabled>Y</enabled>
          <name>REPOSITORY_DIRECTORY</name>
        </field>
        <field>
          <id>FILENAME</id>
          <enabled>Y</enabled>
          <name>FILENAME</name>
        </field>
        <field>
          <id>OBJECT_ID</id>
          <enabled>Y</enabled>
          <name>OBJECT_ID</name>
        </field>
        <field>
          <id>OBJECT_REVISION</id>
          <enabled>Y</enabled>
          <name>OBJECT_REVISION</name>
        </field>
        <field>
          <id>PARENT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>PARENT_CHANNEL_ID</name>
        </field>
        <field>
          <id>ROOT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>ROOT_CHANNEL_ID</name>
        </field>
      </channel-log-table>
      <step-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSSTEP_SCHEMA}</schema>
        <table>${QF_LOG_TRANSSTEP_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSSTEP_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>N</enabled>
          <name>LOG_FIELD</name>
        </field>
      </step-log-table>
      <metrics-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSMETRICS_SCHEMA}</schema>
        <table>${QF_LOG_TRANSMETRICS_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSMETRICS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>METRICS_DATE</id>
          <enabled>Y</enabled>
          <name>METRICS_DATE</name>
        </field>
        <field>
          <id>METRICS_CODE</id>
          <enabled>Y</enabled>
          <name>METRICS_CODE</name>
        </field>
        <field>
          <id>METRICS_DESCRIPTION</id>
          <enabled>Y</enabled>
          <name>METRICS_DESCRIPTION</name>
        </field>
        <field>
          <id>METRICS_SUBJECT</id>
          <enabled>Y</enabled>
          <name>METRICS_SUBJECT</name>
        </field>
        <field>
          <id>METRICS_TYPE</id>
          <enabled>Y</enabled>
          <name>METRICS_TYPE</name>
        </field>
        <field>
          <id>METRICS_VALUE</id>
          <enabled>Y</enabled>
          <name>METRICS_VALUE</name>
        </field>
      </metrics-log-table>
    </log>
    <maxdate>
      <connection />
      <table />
      <field />
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file />
    <capture_step_performance>Y</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
    <created_user>-</created_user>
    <created_date>2016/04/03 09:57:16.279</created_date>
    <modified_user>-</modified_user>
    <modified_date>2019/09/12 10:51:16.148</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA=</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
    <notepad>
      <note>Load the data from the source DB table that will be moved to the target DB table.

It is important to sort these rows chronologically (by either the "insert_id" or "inserted_on" columns) so that if this transformation
fails in the middle somewhere and if this transaction does not run in a single transaction, then next time this transformation is 
executed, we want to start again where we left off (by computing, e.g., MAX(insert_id) for the target DB table).</note>
      <xloc>512</xloc>
      <yloc>672</yloc>
      <width>723</width>
      <heigth>75</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Get batch ID for current transformation. This will be stored in the target  table for auditing/logging. This step *must* come after the
"Map column names" step because the metadata injected into that step does not include this column/field.</note>
      <xloc>512</xloc>
      <yloc>896</yloc>
      <width>739</width>
      <heigth>36</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This transformation updates the target DB mirror of a table from the source DB that can receive INSERTs or UPDATES. This is a generic algorithm that can work 
with *any* table,  as long as rows cannot be deleted from the source or target table, and it has the necessary "insert_id", "inserted_on" &amp; "last_updated_on"
columns. The "updatable" table generic update algorithm #3 is used. This algorithm appears to be fastest for both local and remote target databases. But 
because of the potential race condition described above, be careful that it is only used where this in not an issue. This transformation has parameters:

	PARAM_ETL_RUN_ID								Primary key for the ${QF_ETL_DB_SCHEMA}.etl_run row for the current "run"
	PARAM_TARGET_TABLE_UPDATE_ID				Primary key of ${QF_ETL_DB_SCHEMA}.target_table_update row to be updated by this job for progress and summary statistics
	PARAM_CDC_LAST_LOAD_UTC					Timestamp for when the target DB was most recently updated successfully
	PARAM_CDC_CURRENT_LOAD_UTC				Used so that a consistent max timestamp is used for all ETL
	PARAM_DYN_DB_CONN_TARGET_DB_HOST		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_PORT		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_DATABASE	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_USERNAME	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_DRIVER		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_URL			for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_HOST		for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_PORT		for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER		for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_URL			for source DB "dynamic" database connections
	PARAM_SOURCE_TABLE_MAX_INSERT_ID			Maximum value of the "insert_id" column for rows to load from the source DB table
	PARAM_SOURCE_SCHEMA						Schema of mirrored table
	PARAM_SOURCE_TABLE							Name of mirrored table to update
	PARAM_SOURCE_INSERT_ID_COLNAME			Name of column acting as "insert_id"  timestamp column of source table
	PARAM_SOURCE_INSERTED_ON_COLNAME		Name of column acting as "inserted_on" column of source table
	PARAM_SOURCE_LAST_UPDATED_ON_COLNAME	Name of "last_updated_on" timestamp column of source table
	PARAM_TARGET_SCHEMA						Name of schema containing target table to update (not currently used)
	PARAM_TARGET_TABLE							Name of target table to update (not currently used)
	PARAM_TARGET_INSERT_ID_COLNAME			Name of column acting as "insert_id"  timestamp column of target table
	PARAM_TARGET_INSERTED_ON_COLNAME		Name of column acting as "inserted_on" column of target table
	PARAM_TARGET_LAST_UPDATED_ON_COLNAME	Name of "last_updated_on" timestamp column of target table</note>
      <xloc>0</xloc>
      <yloc>0</yloc>
      <width>1013</width>
      <heigth>452</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Get the maximum value stored in the "insert_id"column of the target DB table that will be updated by this transformation. 
This will be used to the select data from the source DB table that was inserted since the last update. 

We could, instead, treat this by getting the maximum value the "inserted_on" column and then loading all rows from the source
table whose value of "inserted_on" is >= to this timestamp. We need to include "=" here because of the finite resolutiuon of 
timestamp values. If we used only ">", we could miss rows that were inserted *after* the last update if they received exactly the
same value as MAX(inserted_on) that was obtained here. However, this approach may process a small number of rows from 
the source table that were migrated to the target table during the last successful update (again, because timestamp values are 
not unique), but that is OK here because the algorithm used in this transformation can handle attempts to insert rows that already
exist in the target table.

Alternatively, we could eliminate this step entirely and load source DB table rows for: inserted_on >= PARAM_CDC_LAST_LOAD_UTC,
but this will not be as efficient for the case when we need to re-start the mirroring process after it fails for some reason. In that
case we would re-process all of the rows that were successfully mirrored during the previous run.</note>
      <xloc>512</xloc>
      <yloc>464</yloc>
      <width>737</width>
      <heigth>192</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Although this transformation has parameters whose values are used in its steps, these parameters are not 
passed values from the parent transformation in the usual way this is normally done in PDI. This is because 
the "ETL Metadata Injection" step (which is responsible for executing this template transformation) does not 
support parameter passing. Nevertheless, it appears that the parameters that are defined for this template 
transformation can be used as expected. The explanation for this behaviour *MAY* be that the references to 
these parameters, e.g., ${PARAM_SOURCE_TABLE}, in this transformation are simply using the values defined 
for these variables in the parent transformation that contains the "ETL Metadata Injection" step that 
references this template transformation. Fortunately, all of the parameters that are used by this transformation 
are defined with the correct values in the parent transformation. I have tested this by removing the parameters 
entirely. The result was that the transformation ran as expected, even though it made use of the parameters 
that were removed.

Note that if a target file is created by the "ETL metadata Injection" step, then that transformation *can* have 
its parameters passed to it in the normal fashion because it is a normal transformation (all metadata has been 
injected into it).</note>
      <xloc>912</xloc>
      <yloc>0</yloc>
      <width>628</width>
      <heigth>205</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>255</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Select and possibly map/rename fields (table column names), as appropriate.</note>
      <xloc>512</xloc>
      <yloc>832</yloc>
      <width>427</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Metadata injected -></note>
      <xloc>240</xloc>
      <yloc>832</yloc>
      <width>124</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>255</fontcolorred>
      <fontcolorgreen>255</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>0</backgroundcolorred>
      <backgroundcolorgreen>0</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>&lt;- Metadata injected</note>
      <xloc>528</xloc>
      <yloc>1264</yloc>
      <width>124</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>255</fontcolorred>
      <fontcolorgreen>255</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>0</backgroundcolorred>
      <backgroundcolorgreen>0</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Metadata injected -></note>
      <xloc>240</xloc>
      <yloc>688</yloc>
      <width>124</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>255</fontcolorred>
      <fontcolorgreen>255</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>0</backgroundcolorred>
      <backgroundcolorgreen>0</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This algorithm cannot be implemented 
unless I replace the "Database Value Lookup" 
step with a "Table input"and "Stream Lookup"
step because the "Database Value Lookup"
step does not support metadata injection!
I am not convinced this is worth the effort.
Could I somehow use, instead, a 
"Combination lookup-update" step?</note>
      <xloc>912</xloc>
      <yloc>224</yloc>
      <width>613</width>
      <heigth>266</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>22</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>173</backgroundcolorred>
      <backgroundcolorgreen>216</backgroundcolorgreen>
      <backgroundcolorblue>230</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Metadata injected ->			This step does not currently support metadata injection, so this algorithm cannot be made generic!!!</note>
      <xloc>240</xloc>
      <yloc>960</yloc>
      <width>726</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>255</fontcolorred>
      <fontcolorgreen>255</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>0</backgroundcolorred>
      <backgroundcolorgreen>0</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Metadata injected -> 			This injection has not been tested!</note>
      <xloc>240</xloc>
      <yloc>1040</yloc>
      <width>367</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>255</fontcolorred>
      <fontcolorgreen>255</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>0</backgroundcolorred>
      <backgroundcolorgreen>0</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>The progress-related fields must be removed here because the "Table output" step attempts to write 
*all* fields to the target table. Alternatively, we would not need to remove the progress-related
fields here if we injected into the "Table output" step the fields that *shall* be written.</note>
      <xloc>512</xloc>
      <yloc>768</yloc>
      <width>570</width>
      <heigth>49</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This stream logs progress statistics every
QF_ETL_PROGRESS_INTERVAL_ROWS 
rows that are processed by this algorithm.</note>
      <xloc>16</xloc>
      <yloc>1008</yloc>
      <width>240</width>
      <heigth>49</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>&lt;- Metadata injected</note>
      <xloc>144</xloc>
      <yloc>880</yloc>
      <width>124</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>255</fontcolorred>
      <fontcolorgreen>255</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>0</backgroundcolorred>
      <backgroundcolorgreen>0</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <connection>
    <name>generic_source_db</name>
    <server>${PARAM_DYN_DB_CONN_SOURCE_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE}</database>
    <port>${PARAM_DYN_DB_CONN_SOURCE_DB_PORT}</port>
    <username>${PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME}</username>
    <password>${PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${PARAM_DYN_DB_CONN_SOURCE_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>generic_target_db</name>
    <server>${PARAM_DYN_DB_CONN_TARGET_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${PARAM_DYN_DB_CONN_TARGET_DB_DATABASE}</database>
    <port>${PARAM_DYN_DB_CONN_TARGET_DB_PORT}</port>
    <username>${PARAM_DYN_DB_CONN_TARGET_DB_USERNAME}</username>
    <password>${PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${PARAM_DYN_DB_CONN_TARGET_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>logging_db</name>
    <server>${QF_LOGGING_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_LOGGING_DB_DATABASE}</database>
    <port>${QF_LOGGING_DB_PORT}</port>
    <username>${QF_LOGGING_DB_USERNAME}</username>
    <password>${QF_LOGGING_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_LOGGING_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <order>
    <hop>
      <from>Get max id &amp; date: target_db.schema.table</from>
      <to>Write to log: parameters, max id &amp; date</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Write to log: parameters, max id &amp; date</from>
      <to>Table input -  source_db.schema.table</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Set etl_batch_id_last_update = Xform batch ID</from>
      <to>Update - target_db.schema.table</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Map column names</from>
      <to>Set etl_batch_id_insert = Xform batch ID</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>INSERT or UPDATE?</from>
      <to>Perform INSERT</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>INSERT or UPDATE?</from>
      <to>Perform UPDATE</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Perform INSERT</from>
      <to>Remove field "insert_if_null"</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Set insert_if_null flag field</from>
      <to>INSERT or UPDATE?</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Set etl_batch_id_insert = Xform batch ID</from>
      <to>Set insert_if_null flag field</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Remove field "insert_if_null"</from>
      <to>Table output - target_db.schema.table</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Perform UPDATE</from>
      <to>Set etl_batch_id_last_update = Xform batch ID</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Compute number of rows inserted</from>
      <to>Set QF_UPDATE_TABLE_NUM_INSERTS</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Table output - target_db.schema.table</from>
      <to>Compute number of rows inserted</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Compute number of rows updated</from>
      <to>Set QF_UPDATE_TABLE_NUM_UPDATES</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Update - target_db.schema.table</from>
      <to>Compute number of rows updated</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Set QF_UPDATE_TABLE_NUM_INSERTS</from>
      <to>Get transformation name</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Get transformation name</from>
      <to>Log number of rows inserted</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Set QF_UPDATE_TABLE_NUM_UPDATES</from>
      <to>Get transformation name 2</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Get transformation name 2</from>
      <to>Log number of rows updated</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Table input -  source_db.schema.table</from>
      <to>Remove progress-related fields</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Remove progress-related fields</from>
      <to>Map column names</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Select fields for progress monitoring</from>
      <to>tr_log_table_progress</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Select rows for progress monitoring</from>
      <to>Discard rows</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Select rows for progress monitoring</from>
      <to>Select fields for progress monitoring</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Table input -  source_db.schema.table</from>
      <to>Select rows for progress monitoring</to>
      <enabled>Y</enabled>
    </hop>
  </order>
  <step>
    <name>Compute number of rows inserted</name>
    <type>MemoryGroupBy</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <give_back_row>Y</give_back_row>
    <group>
      </group>
    <fields>
      <field>
        <aggregate>num_rows_inserted</aggregate>
        <subject />
        <type>COUNT_ANY</type>
        <valuefield />
      </field>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>272</xloc>
      <yloc>1328</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Compute number of rows updated</name>
    <type>MemoryGroupBy</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <give_back_row>Y</give_back_row>
    <group>
      </group>
    <fields>
      <field>
        <aggregate>num_rows_updated</aggregate>
        <subject />
        <type>COUNT_ANY</type>
        <valuefield />
      </field>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>496</xloc>
      <yloc>1328</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Get max id &amp; date: target_db.schema.table</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>generic_target_db</connection>
    <sql>SELECT
    COALESCE(MAX(${PARAM_TARGET_INSERT_ID_COLNAME}), ${QF_INSERT_ID_LOWER_BOUND})       AS max_target_insert_id,
    COALESCE(MAX(${PARAM_TARGET_LAST_UPDATED_ON_COLNAME}) , '${QF_LAST_UPDATED_ON_LOWER_BOUND}') AS max_target_last_updated_on
FROM
    ${PARAM_TARGET_SCHEMA}.${PARAM_TARGET_TABLE}
</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>368</xloc>
      <yloc>480</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Get transformation name</name>
    <type>SystemInfo</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>current_transformation</name>
        <type>transformation name</type>
      </field>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>272</xloc>
      <yloc>1456</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Get transformation name 2</name>
    <type>SystemInfo</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>current_transformation</name>
        <type>transformation name</type>
      </field>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>496</xloc>
      <yloc>1456</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>INSERT or UPDATE?</name>
    <type>FilterRows</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <send_true_to>Perform INSERT</send_true_to>
    <send_false_to>Perform UPDATE</send_false_to>
    <compare>
      <condition>
        <negated>N</negated>
        <leftvalue>insert_if_null</leftvalue>
        <function>=</function>
        <rightvalue />
        <value>
          <name>constant</name>
          <type>Integer</type>
          <text>-1</text>
          <length>-1</length>
          <precision>0</precision>
          <isnull>N</isnull>
          <mask>####0;-####0</mask>
        </value>
      </condition>
    </compare>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>368</xloc>
      <yloc>1040</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Log number of rows inserted</name>
    <type>WriteToLog</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <loglevel>log_level_minimal</loglevel>
    <displayHeader>Y</displayHeader>
    <limitRows>N</limitRows>
    <limitRowsNumber>0</limitRowsNumber>
    <logmessage>PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE   = ${PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE}
PARAM_DYN_DB_CONN_TARGET_DB_DATABASE   = ${PARAM_DYN_DB_CONN_TARGET_DB_DATABASE}
PARAM_SOURCE_SCHEMA                    = ${PARAM_SOURCE_SCHEMA}
PARAM_SOURCE_TABLE                     = ${PARAM_SOURCE_TABLE}
PARAM_TARGET_SCHEMA                    = ${PARAM_TARGET_SCHEMA}
PARAM_TARGET_TABLE                     = ${PARAM_TARGET_TABLE}</logmessage>
    <fields>
      <field>
        <name>current_transformation</name>
      </field>
      <field>
        <name>num_rows_inserted</name>
      </field>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>272</xloc>
      <yloc>1520</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Log number of rows updated</name>
    <type>WriteToLog</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <loglevel>log_level_minimal</loglevel>
    <displayHeader>Y</displayHeader>
    <limitRows>N</limitRows>
    <limitRowsNumber>0</limitRowsNumber>
    <logmessage>PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE   = ${PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE}
PARAM_DYN_DB_CONN_TARGET_DB_DATABASE   = ${PARAM_DYN_DB_CONN_TARGET_DB_DATABASE}
PARAM_SOURCE_SCHEMA                    = ${PARAM_SOURCE_SCHEMA}
PARAM_SOURCE_TABLE                     = ${PARAM_SOURCE_TABLE}
PARAM_TARGET_SCHEMA                    = ${PARAM_TARGET_SCHEMA}
PARAM_TARGET_TABLE                     = ${PARAM_TARGET_TABLE}</logmessage>
    <fields>
      <field>
        <name>current_transformation</name>
      </field>
      <field>
        <name>num_rows_updated</name>
      </field>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>496</xloc>
      <yloc>1520</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Map column names</name>
    <type>SelectValues</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <select_unspecified>N</select_unspecified>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>368</xloc>
      <yloc>832</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Perform INSERT</name>
    <type>Dummy</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>272</xloc>
      <yloc>1136</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Perform UPDATE</name>
    <type>Dummy</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>496</xloc>
      <yloc>1136</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Remove field "insert_if_null"</name>
    <type>SelectValues</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <select_unspecified>N</select_unspecified>
      <remove>
        <name>insert_if_null</name>
      </remove>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>272</xloc>
      <yloc>1200</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Remove progress-related fields</name>
    <type>SelectValues</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <select_unspecified>N</select_unspecified>
      <remove>
        <name>current_row_num</name>
      </remove>
      <remove>
        <name>num_rows_to_process</name>
      </remove>
      <remove>
        <name>update_progress</name>
      </remove>
      <remove>
        <name>null_column</name>
      </remove>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>368</xloc>
      <yloc>768</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Set QF_UPDATE_TABLE_NUM_INSERTS</name>
    <type>SetVariable</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <field_name>num_rows_inserted</field_name>
        <variable_name>QF_UPDATE_TABLE_NUM_INSERTS</variable_name>
        <variable_type>ROOT_JOB</variable_type>
        <default_value />
      </field>
    </fields>
    <use_formatting>Y</use_formatting>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>272</xloc>
      <yloc>1392</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Set QF_UPDATE_TABLE_NUM_UPDATES</name>
    <type>SetVariable</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <field_name>num_rows_updated</field_name>
        <variable_name>QF_UPDATE_TABLE_NUM_UPDATES</variable_name>
        <variable_type>ROOT_JOB</variable_type>
        <default_value />
      </field>
    </fields>
    <use_formatting>Y</use_formatting>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>496</xloc>
      <yloc>1392</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Set etl_batch_id_insert = Xform batch ID</name>
    <type>SystemInfo</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>etl_batch_id_insert</name>
        <type>batch ID</type>
      </field>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>368</xloc>
      <yloc>896</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Set etl_batch_id_last_update = Xform batch ID</name>
    <type>SystemInfo</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>etl_batch_id_last_update</name>
        <type>batch ID</type>
      </field>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>496</xloc>
      <yloc>1200</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Set insert_if_null flag field</name>
    <type>DBLookup</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>generic_target_db</connection>
    <cache>N</cache>
    <cache_load_all>N</cache_load_all>
    <cache_size>0</cache_size>
    <lookup>
      <schema>${PARAM_TARGET_SCHEMA}</schema>
      <table>${PARAM_TARGET_TABLE}</table>
      <orderby />
      <fail_on_multiple>N</fail_on_multiple>
      <eat_row_on_failure>N</eat_row_on_failure>
      <key>
        <name>pedd_id</name>
        <field>pedd_id</field>
        <condition>=</condition>
        <name2 />
      </key>
      <value>
        <name>pedd_id</name>
        <rename>insert_if_null</rename>
        <default>-1</default>
        <type>Integer</type>
      </value>
    </lookup>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>368</xloc>
      <yloc>960</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Table input -  source_db.schema.table</name>
    <type>TableInput</type>
    <description />
    <distribute>N</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>generic_source_db</connection>
    <sql>-- This statement is commented out because the SQL statement is, 
-- instead, injected via ETL Metadata Injection:
--
--SELECT
--    *
--FROM
--    ${PARAM_SOURCE_SCHEMA}.${PARAM_SOURCE_TABLE}
--WHERE
--    (
--        ${PARAM_SOURCE_INSERT_ID_COLNAME} > ?                                 -- newly INSERTed rows, since the last run
--      --${PARAM_SOURCE_INSERTED_ON_COLNAME} > '${PARAM_CDC_LAST_LOAD_UTC}'    -- alternate condition, instead of the previous line
--     OR ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME} >= ?                          -- UPDATEd rows, since the last run. This is needed to be able to select rows that
--                                                                              -- are modified during a period when the table is being treated as an insert-only
--                                                                              -- table (not a likely scenario, but it is a possibility).
--                                                                              -- Because ">=" is used here, not ">", this will include a least one row that was
--                                                                              -- updated on the previous run (assuming that there was at least one row updated).
--                                                                              -- This/these rows will have ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME} = ?. The reason why
--                                                                              -- ">=" is used is in case there were one or more rows that were *not* updated on the
--                                                                              -- previous run, but which have ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME} = ?. This can occur
--                                                                              -- because of the finite resolution of timestamp values. As a result, more than one
--                                                                              -- row can have the *same* value of ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME}, but not all of
--                                                                              -- them were loaded and treated on the previous run, i.e., the cutoff imposed by
--                                                                              -- the condition ${PARAM_SOURCE_INSERT_ID_COLNAME} &lt;= ${PARAM_SOURCE_TABLE_MAX_INSERT_ID} or
--                                                                              -- ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME} &lt;= '${PARAM_CDC_CURRENT_LOAD_UTC}' loaded some,
--                                                                              -- but not all, of the rows with this value of ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME}.
--      --OR ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME} >= '${PARAM_CDC_LAST_LOAD_UTC}'       -- alternate condition, instead of the previous line
--    )
--    AND ${PARAM_SOURCE_INSERT_ID_COLNAME}   &lt;= ${PARAM_SOURCE_TABLE_MAX_INSERT_ID}         -- to avoid loading rows that are *inserted* after the job starts
--  --AND ${PARAM_SOURCE_INSERTED_ON_COLNAME} &lt;= '${PARAM_CDC_CURRENT_LOAD_UTC}'    -- alternate condition, instead of the previous line 
--    AND (
--            ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME} IS NULL OR                       -- rows that have been inserted but not modified
--            ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME} &lt;= '${PARAM_CDC_CURRENT_LOAD_UTC}'   -- to avoid loading rows that are *modified* after the job starts
--        )
--ORDER BY
--    ${PARAM_SOURCE_INSERT_ID_COLNAME}</sql>
    <limit>0</limit>
    <lookup>Write to log: parameters, max id &amp; date</lookup>
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>368</xloc>
      <yloc>688</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Table output - target_db.schema.table</name>
    <type>TableOutput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>generic_target_db</connection>
    <schema>${PARAM_TARGET_SCHEMA}</schema>
    <table>${PARAM_TARGET_TABLE}</table>
    <commit>1000</commit>
    <truncate>N</truncate>
    <ignore_errors>N</ignore_errors>
    <use_batch>Y</use_batch>
    <specify_fields>N</specify_fields>
    <partitioning_enabled>N</partitioning_enabled>
    <partitioning_field />
    <partitioning_daily>N</partitioning_daily>
    <partitioning_monthly>Y</partitioning_monthly>
    <tablename_in_field>N</tablename_in_field>
    <tablename_field />
    <tablename_in_table>Y</tablename_in_table>
    <return_keys>N</return_keys>
    <return_field />
    <fields>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>272</xloc>
      <yloc>1264</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Update - target_db.schema.table</name>
    <type>Update</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>generic_target_db</connection>
    <skip_lookup>Y</skip_lookup>
    <commit>100</commit>
    <use_batch>Y</use_batch>
    <error_ignored>N</error_ignored>
    <ignore_flag_field />
    <lookup>
      <schema>${PARAM_TARGET_SCHEMA}</schema>
      <table>${PARAM_TARGET_TABLE}</table>
    </lookup>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>496</xloc>
      <yloc>1264</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Write to log: parameters, max id &amp; date</name>
    <type>WriteToLog</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <loglevel>log_level_basic</loglevel>
    <displayHeader>Y</displayHeader>
    <limitRows>N</limitRows>
    <limitRowsNumber>0</limitRowsNumber>
    <logmessage>tmplt_target-update_table-updatable_table_3:
PARAM_CDC_LAST_LOAD_UTC              = ${PARAM_CDC_LAST_LOAD_UTC}
PARAM_CDC_CURRENT_LOAD_UTC           = ${PARAM_CDC_CURRENT_LOAD_UTC}
PARAM_DYN_DB_CONN_SOURCE_DB_HOST     = ${PARAM_DYN_DB_CONN_SOURCE_DB_HOST}
PARAM_DYN_DB_CONN_SOURCE_DB_PORT     = ${PARAM_DYN_DB_CONN_SOURCE_DB_PORT}
PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE = ${PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE}
PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD = ${PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD}
PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME = ${PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME}
PARAM_DYN_DB_CONN_SOURCE_DB_URL      = ${PARAM_DYN_DB_CONN_SOURCE_DB_URL}
PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER   = ${PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER}
PARAM_DYN_DB_CONN_TARGET_DB_HOST     = ${PARAM_DYN_DB_CONN_TARGET_DB_HOST}
PARAM_DYN_DB_CONN_TARGET_DB_PORT     = ${PARAM_DYN_DB_CONN_TARGET_DB_PORT}
PARAM_DYN_DB_CONN_TARGET_DB_DATABASE = ${PARAM_DYN_DB_CONN_TARGET_DB_DATABASE}
PARAM_DYN_DB_CONN_TARGET_DB_USERNAME = ${PARAM_DYN_DB_CONN_TARGET_DB_USERNAME}
PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD = ${PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD}
PARAM_DYN_DB_CONN_TARGET_DB_URL      = ${PARAM_DYN_DB_CONN_TARGET_DB_URL}
PARAM_DYN_DB_CONN_TARGET_DB_DRIVER   = ${PARAM_DYN_DB_CONN_TARGET_DB_DRIVER}
PARAM_SOURCE_TABLE_MAX_INSERT_ID                  = ${PARAM_SOURCE_TABLE_MAX_INSERT_ID}
PARAM_SOURCE_SCHEMA                  = ${PARAM_SOURCE_SCHEMA}
PARAM_SOURCE_TABLE                   = ${PARAM_SOURCE_TABLE}
PARAM_SOURCE_INSERT_ID_COLNAME       = ${PARAM_SOURCE_INSERT_ID_COLNAME}   
PARAM_SOURCE_INSERTED_ON_COLNAME     = ${PARAM_SOURCE_INSERTED_ON_COLNAME}
PARAM_SOURCE_LAST_UPDATED_ON_COLNAME = ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME}
PARAM_TARGET_SCHEMA                  = ${PARAM_TARGET_SCHEMA}
PARAM_TARGET_TABLE                   = ${PARAM_TARGET_TABLE}
PARAM_TARGET_INSERT_ID_COLNAME       = ${PARAM_TARGET_INSERT_ID_COLNAME}   
PARAM_TARGET_INSERTED_ON_COLNAME     = ${PARAM_TARGET_INSERTED_ON_COLNAME}
PARAM_TARGET_LAST_UPDATED_ON_COLNAME = ${PARAM_TARGET_LAST_UPDATED_ON_COLNAME}</logmessage>
    <fields>
      <field>
        <name>max_target_insert_id</name>
      </field>
      <field>
        <name>max_target_last_updated_on</name>
      </field>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>368</xloc>
      <yloc>608</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Discard rows</name>
    <type>Dummy</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>48</xloc>
      <yloc>800</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Select fields for progress monitoring</name>
    <type>SelectValues</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <select_unspecified>N</select_unspecified>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>112</xloc>
      <yloc>880</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Select rows for progress monitoring</name>
    <type>FilterRows</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <send_true_to>Select fields for progress monitoring</send_true_to>
    <send_false_to>Discard rows</send_false_to>
    <compare>
      <condition>
        <negated>N</negated>
        <leftvalue>update_progress</leftvalue>
        <function>=</function>
        <rightvalue />
        <value>
          <name>constant</name>
          <type>Integer</type>
          <text>0</text>
          <length>-1</length>
          <precision>0</precision>
          <isnull>N</isnull>
          <mask>#</mask>
        </value>
      </condition>
    </compare>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>112</xloc>
      <yloc>688</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>tr_log_table_progress</name>
    <type>SimpleMapping</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <specification_method>rep_name</specification_method>
    <trans_object_id />
    <trans_name>tr_log_table_progress</trans_name>
    <filename />
    <directory_path>/generic</directory_path>
    <mappings>
      <input>
        <mapping>
          <input_step />
          <output_step />
          <main_path>Y</main_path>
          <rename_on_output>Y</rename_on_output>
          <description />
          <connector>
            <parent>current_row_num</parent>
            <child>current_row_num</child>
          </connector>
          <connector>
            <parent>num_rows_to_process</parent>
            <child>num_rows_to_process</child>
          </connector>
          <connector>
            <parent>insert_id</parent>
            <child>insert_id</child>
          </connector>
          <connector>
            <parent>last_updated_on</parent>
            <child>last_updated_on</child>
          </connector>
        </mapping>
      </input>
      <output>
        <mapping>
          <input_step />
          <output_step />
          <main_path>Y</main_path>
          <rename_on_output>N</rename_on_output>
          <description />
        </mapping>
      </output>
      <parameters>
        <variablemapping>
          <variable>PARAM_ETL_OPERATION</variable>
          <input>insert</input>
        </variablemapping>
        <inherit_all_vars>Y</inherit_all_vars>
      </parameters>
    </mappings>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>112</xloc>
      <yloc>944</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step_error_handling>
    <error>
      <source_step>Table output - target_db.schema.table</source_step>
      <target_step />
      <is_enabled>N</is_enabled>
      <nr_valuename />
      <descriptions_valuename />
      <fields_valuename />
      <codes_valuename />
      <max_errors />
      <max_pct_errors />
      <min_pct_rows />
    </error>
  </step_error_handling>
  <slave-step-copy-partition-distribution>
  </slave-step-copy-partition-distribution>
  <slave_transformation>N</slave_transformation>
  <attributes />
</transformation>
