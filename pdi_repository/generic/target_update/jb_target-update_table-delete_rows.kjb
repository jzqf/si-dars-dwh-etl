<job>
  <name>jb_target-update_table-delete_rows</name>
  <description />
  <extended_description />
  <job_version />
  <job_status>0</job_status>
  <directory>/generic/target_update</directory>
  <created_user>-</created_user>
  <created_date>2016/04/03 14:57:58.609</created_date>
  <modified_user>-</modified_user>
  <modified_date>2020/11/24 08:23:58.088</modified_date>
  <parameters>
    <parameter>
      <name>PARAM_CDC_CONTROL_SCHEMA_NAME</name>
      <default_value />
      <description>The name of the schema in the source database that contains the "CDC control table"</description>
    </parameter>
    <parameter>
      <name>PARAM_CDC_CONTROL_TABLE_BATCH_SIZE</name>
      <default_value />
      <description>The number of CDC control rows that will be processed in a single transaction</description>
    </parameter>
    <parameter>
      <name>PARAM_CDC_CONTROL_TABLE_NAME</name>
      <default_value />
      <description>The name of the "CDC control table"</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE</name>
      <default_value>obo_opr</default_value>
      <description>for source DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER</name>
      <default_value>org.postgresql.Driver</default_value>
      <description>for source DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_SOURCE_DB_HOST</name>
      <default_value>si01-qfr-07cl.si01.q-free.com</default_value>
      <description>for source DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD</name>
      <default_value>kc2H2F5mY8U2b4Vwp6BT4OnY_hq4p7+Y</default_value>
      <description>for source DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_SOURCE_DB_PORT</name>
      <default_value>5432</default_value>
      <description>for source DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_SOURCE_DB_URL</name>
      <default_value>jdbc:postgresql://si01-qfr-07cl.si01.q-free.com:5432/obo_opr</default_value>
      <description>for source DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME</name>
      <default_value>qfree_bi</default_value>
      <description>for source DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_TARGET_DB_DATABASE</name>
      <default_value>dwh_psa_obo</default_value>
      <description>for target DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_TARGET_DB_DRIVER</name>
      <default_value>org.postgresql.Driver</default_value>
      <description>for target DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_TARGET_DB_HOST</name>
      <default_value>localhost</default_value>
      <description>for target DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD</name>
      <default_value>qfree_admin</default_value>
      <description>for target DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_TARGET_DB_PORT</name>
      <default_value>5432</default_value>
      <description>for target DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_TARGET_DB_URL</name>
      <default_value>jdbc:postgresql://localhost:5432/dwh_psa_obo</default_value>
      <description>for target DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_TARGET_DB_USERNAME</name>
      <default_value>qfree_admin</default_value>
      <description>for target DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_ETL_RUN_ID</name>
      <default_value />
      <description>Primary key for the ${QF_ETL_DB_SCHEMA}.etl_run row for the current "run"</description>
    </parameter>
    <parameter>
      <name>PARAM_ITER_COUNTER</name>
      <default_value />
      <description>Will have the value 1, 2,  .., PARAM_ITER_COUNTER_MAX on successive calls to this job</description>
    </parameter>
    <parameter>
      <name>PARAM_ITER_COUNTER_MAX</name>
      <default_value />
      <description>the maximum value that will be reached by PARAM_ITER_COUNTER on successive calls for the target table being treated</description>
    </parameter>
    <parameter>
      <name>PARAM_ROWS_DELETED</name>
      <default_value />
      <description>the number of rows ofthe target table so far deleted = (PARAM_ITER_COUNTER-1) * PARAM_CDC_CONTROL_TABLE_BATCH_SIZE</description>
    </parameter>
    <parameter>
      <name>PARAM_ROWS_TO_DELETE</name>
      <default_value />
      <description>the number of rows of the target table that will be deleted after PARAM_ITER_COUNTER has reached PARAM_ITER_COUNTER_MAX</description>
    </parameter>
    <parameter>
      <name>PARAM_SOURCE_DB_ID</name>
      <default_value />
      <description>ID the "source" database containing tables will be mirrored to a "target" database</description>
    </parameter>
    <parameter>
      <name>PARAM_SOURCE_SCHEMA</name>
      <default_value />
      <description>Name of schema containing source table to mirror to target table</description>
    </parameter>
    <parameter>
      <name>PARAM_SOURCE_TABLE</name>
      <default_value />
      <description>Name of source table to mirror to target table</description>
    </parameter>
    <parameter>
      <name>PARAM_TABLE_META_ID</name>
      <default_value>2392</default_value>
      <description>Primary key of ${QF_ETL_DB_SCHEMA}.table_meta row for "source" table from which rows will be deleted</description>
    </parameter>
    <parameter>
      <name>PARAM_TARGET_DB_ID</name>
      <default_value />
      <description>ID of the "target" database to which "source" DB tables will be archived/mirrored</description>
    </parameter>
    <parameter>
      <name>PARAM_TARGET_INSERT_ID_COLNAME</name>
      <default_value />
      <description>Name of column acting as "insert_id" column of target table</description>
    </parameter>
    <parameter>
      <name>PARAM_TARGET_SCHEMA</name>
      <default_value />
      <description>Name of schema containing target table to update</description>
    </parameter>
    <parameter>
      <name>PARAM_TARGET_TABLE</name>
      <default_value />
      <description>Name of target table to update</description>
    </parameter>
    <parameter>
      <name>PARAM_TARGET_TABLE_UPDATE_ID</name>
      <default_value />
      <description>Primary key of ${QF_ETL_DB_SCHEMA}.target_table_update row to be updated by this job for progress and summary statistics</description>
    </parameter>
  </parameters>
  <connection>
    <name>logging_db</name>
    <server>${QF_LOGGING_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_LOGGING_DB_DATABASE}</database>
    <port>${QF_LOGGING_DB_PORT}</port>
    <username>${QF_LOGGING_DB_USERNAME}</username>
    <password>${QF_LOGGING_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>INITIAL_POOL_SIZE</code>
        <attribute>10</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>MAXIMUM_POOL_SIZE</code>
        <attribute>10</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_LOGGING_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>Y</attribute>
      </attribute>
    </attributes>
  </connection>
  <slaveservers>
    </slaveservers>
  <job-log-table>
    <connection>${QF_LOGGING_DB_CONNECTION}</connection>
    <schema>${QF_LOG_JOB_SCHEMA}</schema>
    <table>${QF_LOG_JOB_TABLE}</table>
    <size_limit_lines />
    <interval />
    <timeout_days>${QF_LOG_JOB_TIMEOUT_IN_DAYS}</timeout_days>
    <field>
      <id>ID_JOB</id>
      <enabled>Y</enabled>
      <name>ID_JOB</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>JOBNAME</name>
    </field>
    <field>
      <id>STATUS</id>
      <enabled>Y</enabled>
      <name>STATUS</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>STARTDATE</id>
      <enabled>Y</enabled>
      <name>STARTDATE</name>
    </field>
    <field>
      <id>ENDDATE</id>
      <enabled>Y</enabled>
      <name>ENDDATE</name>
    </field>
    <field>
      <id>LOGDATE</id>
      <enabled>Y</enabled>
      <name>LOGDATE</name>
    </field>
    <field>
      <id>DEPDATE</id>
      <enabled>Y</enabled>
      <name>DEPDATE</name>
    </field>
    <field>
      <id>REPLAYDATE</id>
      <enabled>Y</enabled>
      <name>REPLAYDATE</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>Y</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>EXECUTING_SERVER</id>
      <enabled>N</enabled>
      <name>EXECUTING_SERVER</name>
    </field>
    <field>
      <id>EXECUTING_USER</id>
      <enabled>N</enabled>
      <name>EXECUTING_USER</name>
    </field>
    <field>
      <id>START_JOB_ENTRY</id>
      <enabled>N</enabled>
      <name>START_JOB_ENTRY</name>
    </field>
    <field>
      <id>CLIENT</id>
      <enabled>N</enabled>
      <name>CLIENT</name>
    </field>
  </job-log-table>
  <jobentry-log-table>
    <connection>${QF_LOGGING_DB_CONNECTION}</connection>
    <schema>${QF_LOG_JOBENTRY_SCHEMA}</schema>
    <table>${QF_LOG_JOBENTRY_TABLE}</table>
    <timeout_days>${QF_LOG_JOBENTRY_TIMEOUT_IN_DAYS}</timeout_days>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>TRANSNAME</name>
    </field>
    <field>
      <id>JOBENTRYNAME</id>
      <enabled>Y</enabled>
      <name>STEPNAME</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>RESULT</id>
      <enabled>Y</enabled>
      <name>RESULT</name>
    </field>
    <field>
      <id>NR_RESULT_ROWS</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_ROWS</name>
    </field>
    <field>
      <id>NR_RESULT_FILES</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_FILES</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>N</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>COPY_NR</id>
      <enabled>N</enabled>
      <name>COPY_NR</name>
    </field>
  </jobentry-log-table>
  <channel-log-table>
    <connection>${QF_LOGGING_DB_CONNECTION}</connection>
    <schema>${QF_LOG_CHANNEL_SCHEMA}</schema>
    <table>${QF_LOG_CHANNEL_TABLE}</table>
    <timeout_days>${QF_LOG_CHANNEL_TIMEOUT_IN_DAYS}</timeout_days>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>LOGGING_OBJECT_TYPE</id>
      <enabled>Y</enabled>
      <name>LOGGING_OBJECT_TYPE</name>
    </field>
    <field>
      <id>OBJECT_NAME</id>
      <enabled>Y</enabled>
      <name>OBJECT_NAME</name>
    </field>
    <field>
      <id>OBJECT_COPY</id>
      <enabled>Y</enabled>
      <name>OBJECT_COPY</name>
    </field>
    <field>
      <id>REPOSITORY_DIRECTORY</id>
      <enabled>Y</enabled>
      <name>REPOSITORY_DIRECTORY</name>
    </field>
    <field>
      <id>FILENAME</id>
      <enabled>Y</enabled>
      <name>FILENAME</name>
    </field>
    <field>
      <id>OBJECT_ID</id>
      <enabled>Y</enabled>
      <name>OBJECT_ID</name>
    </field>
    <field>
      <id>OBJECT_REVISION</id>
      <enabled>Y</enabled>
      <name>OBJECT_REVISION</name>
    </field>
    <field>
      <id>PARENT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>PARENT_CHANNEL_ID</name>
    </field>
    <field>
      <id>ROOT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>ROOT_CHANNEL_ID</name>
    </field>
  </channel-log-table>
  <pass_batchid>Y</pass_batchid>
  <shared_objects_file />
  <entries>
    <entry>
      <name>START</name>
      <description />
      <type>SPECIAL</type>
      <attributes />
      <start>Y</start>
      <dummy>N</dummy>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>176</xloc>
      <yloc>656</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Abort job</name>
      <description />
      <type>ABORT</type>
      <attributes />
      <message>${QF_ABORT_JOB_MESSAGE}</message>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>48</xloc>
      <yloc>784</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Log parameters</name>
      <description />
      <type>WRITE_TO_LOG</type>
      <attributes />
      <logmessage>PARAM_ETL_RUN_ID                     = ${PARAM_ETL_RUN_ID}
PARAM_TARGET_TABLE_UPDATE_ID         = ${PARAM_TARGET_TABLE_UPDATE_ID}

PARAM_CDC_CONTROL_SCHEMA_NAME        = ${PARAM_CDC_CONTROL_SCHEMA_NAME}
PARAM_CDC_CONTROL_TABLE_NAME         = ${PARAM_CDC_CONTROL_TABLE_NAME}
PARAM_CDC_CONTROL_TABLE_BATCH_SIZE   = ${PARAM_CDC_CONTROL_TABLE_BATCH_SIZE}
PARAM_ITER_COUNTER_MAX               = ${PARAM_ITER_COUNTER_MAX}
PARAM_ROWS_DELETED                   = ${PARAM_ROWS_DELETED}
PARAM_ROWS_TO_DELETE                 = ${PARAM_ROWS_TO_DELETE}

PARAM_TABLE_META_ID                  = ${PARAM_TABLE_META_ID}

PARAM_DYN_DB_CONN_TARGET_DB_HOST     = ${PARAM_DYN_DB_CONN_TARGET_DB_HOST}
PARAM_DYN_DB_CONN_TARGET_DB_PORT     = ${PARAM_DYN_DB_CONN_TARGET_DB_PORT}
PARAM_DYN_DB_CONN_TARGET_DB_DATABASE = ${PARAM_DYN_DB_CONN_TARGET_DB_DATABASE}
PARAM_DYN_DB_CONN_TARGET_DB_USERNAME = ${PARAM_DYN_DB_CONN_TARGET_DB_USERNAME}
PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD = ${PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD}
PARAM_DYN_DB_CONN_TARGET_DB_DRIVER   = ${PARAM_DYN_DB_CONN_TARGET_DB_DRIVER}
PARAM_DYN_DB_CONN_TARGET_DB_URL      = ${PARAM_DYN_DB_CONN_TARGET_DB_URL}

PARAM_DYN_DB_CONN_SOURCE_DB_HOST     = ${PARAM_DYN_DB_CONN_SOURCE_DB_HOST}
PARAM_DYN_DB_CONN_SOURCE_DB_PORT     = ${PARAM_DYN_DB_CONN_SOURCE_DB_PORT}
PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE = ${PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE}
PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME = ${PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME}
PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD = ${PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD}
PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER   = ${PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER}
PARAM_DYN_DB_CONN_SOURCE_DB_URL      = ${PARAM_DYN_DB_CONN_SOURCE_DB_URL}</logmessage>
      <loglevel>Minimal</loglevel>
      <logsubject>${Internal.Job.Name}</logsubject>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>288</xloc>
      <yloc>656</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>tr_target-update_table-delete_rows-without_mi</name>
      <description />
      <type>TRANS</type>
      <attributes />
      <specification_method>rep_name</specification_method>
      <trans_object_id />
      <filename />
      <transname>tr_target-update_table-delete_rows-without_mi</transname>
      <directory>${Internal.Entry.Current.Directory}</directory>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name />
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration>Pentaho local</run_configuration>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>288</xloc>
      <yloc>784</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Success</name>
      <description />
      <type>SUCCESS</type>
      <attributes />
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>496</xloc>
      <yloc>1008</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>tr_log_table_progress-wrapper</name>
      <description />
      <type>TRANS</type>
      <attributes />
      <specification_method>rep_name</specification_method>
      <trans_object_id />
      <filename />
      <transname>tr_log_table_progress-wrapper</transname>
      <directory>/generic</directory>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name />
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration>Pentaho local</run_configuration>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
        <parameter>
          <name>PARAM_CURRENT_ROW_NUMBER</name>
          <stream_name />
          <value>${PARAM_ROWS_DELETED}</value>
        </parameter>
        <parameter>
          <name>PARAM_INSERT_ID</name>
          <stream_name />
          <value>${QF_POSITIVE_INTEGER_NOT_SET_VALUE}</value>
        </parameter>
        <parameter>
          <name>PARAM_LAST_UPDATED_ON</name>
          <stream_name />
          <value>${QF_TIMESTAMP_NOT_SET_VALUE}</value>
        </parameter>
        <parameter>
          <name>PARAM_NUM_ROWS_TO_PROCESS</name>
          <stream_name />
          <value>${PARAM_ROWS_TO_DELETE}</value>
        </parameter>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>496</xloc>
      <yloc>912</yloc>
      <attributes_kjc />
    </entry>
    <entry>
      <name>Log_ rogress and check for shutdown?</name>
      <description />
      <type>EVAL</type>
      <attributes />
      <script>// The final expression in this script evaluates to false, except when "param_rows_deleted" increases by "QF_ETL_PROGRESS_INTERVAL_ROWS".
// The transformation "tr_log_table_progress-wrapper" is executed only when this expression evaluates to true. As a result, 
// an etl.target_table_progress row is created once for each "QF_ETL_PROGRESS_INTERVAL_ROWS" that are processed (deleted). 
// This throttling is done to avoid creating an unreasonably large number of etl.target_table_progress rows.

var param_rows_deleted                         = parseInt(parent_job.getVariable("PARAM_ROWS_DELETED", "0"));    // This value will increase by PARAM_CDC_CONTROL_TABLE_BATCH_SIZE each time this job is executed (for a given table).
var qf_etl_progress_interval_rows            = parseInt(parent_job.getVariable("QF_ETL_PROGRESS_INTERVAL_ROWS", "0"));
var param_cdc_control_table_batch_size = parseInt(parent_job.getVariable("PARAM_CDC_CONTROL_TABLE_BATCH_SIZE", "0"));

param_rows_deleted % qf_etl_progress_interval_rows &lt; param_cdc_control_table_batch_size

//( parseInt(parent_job.getVariable("PARAM_ROWS_DELETED", "0")) % parseInt(parent_job.getVariable("QF_ETL_PROGRESS_INTERVAL_ROWS", "0")) ) &lt; parseInt(parent_job.getVariable("PARAM_CDC_CONTROL_TABLE_BATCH_SIZE", "0"))</script>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>288</xloc>
      <yloc>912</yloc>
      <attributes_kjc />
    </entry>
  </entries>
  <hops>
    <hop>
      <from>START</from>
      <to>Log parameters</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Log parameters</from>
      <to>tr_target-update_table-delete_rows-without_mi</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>tr_target-update_table-delete_rows-without_mi</from>
      <to>Abort job</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>tr_log_table_progress-wrapper</from>
      <to>Success</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>tr_target-update_table-delete_rows-without_mi</from>
      <to>Log_ rogress and check for shutdown?</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Log_ rogress and check for shutdown?</from>
      <to>tr_log_table_progress-wrapper</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>Log_ rogress and check for shutdown?</from>
      <to>Success</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
  </hops>
  <notepads>
    <notepad>
      <note>This job deletes a block of rows of the "target" table. It is called repeatedly with PARAM_ITER_COUNTER having the value 1, 2, .., PARAM_ITER_COUNTER_MAX on successive calls to this job 
until the required number of rows are deleted. The row deletion is performed in blocks instead of in one single go to make it possible to:

1.	Check for shutdown requests while rows are being deleted.
2.	Monitor the row deletions to be able to log the progress made.

This job has parameters:

	PARAM_ETL_RUN_ID								Primary key for the ${QF_ETL_DB_SCHEMA}.etl_run row for the current "run"
	PARAM_TARGET_TABLE_UPDATE_ID				Primary key of ${QF_ETL_DB_SCHEMA}.target_table_update row to be updated by this job for progress and summary statistics

	PARAM_CDC_CONTROL_SCHEMA_NAME			The name of the schema in the source database that contains the "CDC control table"
	PARAM_CDC_CONTROL_TABLE_NAME				The name of the "CDC control table"
	PARAM_CDC_CONTROL_TABLE_BATCH_SIZE		The number of CDC control rows that will be processed in a single transaction
	PARAM_ITER_COUNTER							Will have the value 1, 2,  .., PARAM_ITER_COUNTER_MAX on successive calls to this job. On each call, this 
													job should attempt to select a batch/block/page of PARAM_CDC_CONTROL_TABLE_BATCH_SIZE rows of the 
													CDC control table and then use these to delete the corresponding rows of the target table
	PARAM_ITER_COUNTER_MAX						the maximum value that will be reached by PARAM_ITER_COUNTER on successive calls for the target table being treated
	PARAM_ROWS_DELETED							the number of rows ofthe target table so far deleted = (PARAM_ITER_COUNTER-1) * PARAM_CDC_CONTROL_TABLE_BATCH_SIZE
	PARAM_ROWS_TO_DELETE						the number of rows of the target table that will be deleted after PARAM_ITER_COUNTER has reached PARAM_ITER_COUNTER_MAX

	PARAM_TABLE_META_ID							Primary key of ${QF_ETL_DB_SCHEMA}.table_meta row for "source" table archived/mirrored to "target" table

	PARAM_DYN_DB_CONN_TARGET_DB_HOST		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_PORT		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_DATABASE	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_USERNAME	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_DRIVER		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_URL			for target DB "dynamic" database connections

	PARAM_DYN_DB_CONN_SOURCE_DB_HOST		for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_PORT		for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER		for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_URL			for source DB "dynamic" database connections

Many of these parameters are probably not used:

	PARAM_SOURCE_DB_ID							ID the "source" database containing tables will be mirrored to a "target" database
	PARAM_SOURCE_SCHEMA						Name of schema containing source table to mirror to target table
	PARAM_SOURCE_TABLE							Name of source table to mirror to target table
	PARAM_TARGET_DB_ID							ID of the "target" database to which "source" DB tables will be archived/mirrored
	PARAM_TARGET_SCHEMA						Name of schema containing target table to update
	PARAM_TARGET_TABLE							Name of target table to update
	PARAM_TARGET_INSERT_ID_COLNAME			Name of column acting as "insert_id"  timestamp column of target table</note>
      <xloc>0</xloc>
      <yloc>0</yloc>
      <width>1049</width>
      <heigth>634</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This "Abort" is needed so that the 
root calling job will know that 
execution has failed. It will then 
direct the execution flow to the 
job that sends out failure e-mails.</note>
      <xloc>16</xloc>
      <yloc>848</yloc>
      <width>198</width>
      <heigth>75</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This transformation uses a "CDC control table" 
to delete rows from the target table.</note>
      <xloc>448</xloc>
      <yloc>784</yloc>
      <width>267</width>
      <heigth>36</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>There exists a transformation named:

	tr_target-update_table-delete_rows

which was planned to implement the same functionality as:

	tr_target-update_table-delete_rows-without_mi

However, the template transformation in tr_target-update_table-delete_rows-without_mi 
makes use of the "Delete" transformation step, which does not support metadata injection.
Metadata injection was not added to the "Delete" step until PDI v9.0. Currenlty, this project 
is using PDI v8.2.</note>
      <xloc>736</xloc>
      <yloc>672</yloc>
      <width>516</width>
      <heigth>166</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>173</backgroundcolorred>
      <backgroundcolorgreen>216</backgroundcolorgreen>
      <backgroundcolorblue>230</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Execute tr_log_table_progress-wrapper after every QF_ETL_PROGRESS_INTERVAL_ROWS are deleted. 
This does the following:

1.	It logs progress in the current etl_run row.

2.	It logs progress by inserting an etl.target_table_progress row, but only if:

		QF_ETL_PROGRESS_LOG_HISTORY = Y

3.	It checks if a shutdown has been requested; if so, it initiates a shutdown. This is only done if:

		PARAM_CHECK_FOR_SHUTDOWN_REQUEST = Y</note>
      <xloc>624</xloc>
      <yloc>864</yloc>
      <width>577</width>
      <heigth>166</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>For each target table that is being updated during a run of the ETL job, this job (jb_target-update_table-delete_rows) is called multiple times  to delete target rows. 
Each execution of this job executes:

	tr_target-update_table-delete_rows-without_mi

to delete QF_CDC_CONTROL_TABLE_BATCH_SIZE rows of the target table, and jb_target-update_table-delete_rows is executed multiple times until it processes all of the 
CDC control table rows for deleting target table rows for the current target table being processed.

However, this job executes:

	tr_log_table_progress-wrapper

only once for each QF_ETL_PROGRESS_INTERVAL_ROWS row that are processed (deleted). This allows for rows to be deleted in much smaller batches than the row
interval where checks for shutdown requests are made and etl.target_table_progress rows are created. If tr_log_table_progress-wrapper were called at the same rate
at which batches of rows are deleted in tr_target-update_table-delete_rows-without_mi, an excessive amount of time might be spent checking for shutdown requests,
inserting etl.target_table_progress rows and updating the etl.etl_run row for the current ETL execution.
</note>
      <xloc>48</xloc>
      <yloc>1072</yloc>
      <width>944</width>
      <heigth>231</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>173</backgroundcolorred>
      <backgroundcolorgreen>216</backgroundcolorgreen>
      <backgroundcolorblue>230</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <attributes>
    <group>
      <name>METASTORE.pentaho</name>
      <attribute>
        <key>Default Run Configuration</key>
        <value>{"namespace":"pentaho","id":"Default Run Configuration","name":"Default Run Configuration","description":"Defines a default run configuration","metaStoreName":null}</value>
      </attribute>
    </group>
    <group>
      <name>{"_":"Embedded MetaStore Elements","namespace":"pentaho","type":"Default Run Configuration"}</name>
      <attribute>
        <key>Pentaho local</key>
        <value>{"children":[{"children":[],"id":"server","value":null},{"children":[],"id":"clustered","value":"N"},{"children":[],"id":"name","value":"Pentaho local"},{"children":[],"id":"description","value":null},{"children":[],"id":"pentaho","value":"N"},{"children":[],"id":"readOnly","value":"Y"},{"children":[],"id":"sendResources","value":"N"},{"children":[],"id":"logRemoteExecutionLocally","value":"N"},{"children":[],"id":"remote","value":"N"},{"children":[],"id":"local","value":"Y"},{"children":[],"id":"showTransformations","value":"N"}],"id":"Pentaho local","value":null,"name":"Pentaho local","owner":null,"ownerPermissionsList":[]}</value>
      </attribute>
    </group>
  </attributes>
</job>
