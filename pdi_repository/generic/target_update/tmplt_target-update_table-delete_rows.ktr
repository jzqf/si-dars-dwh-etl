<transformation>
  <info>
    <name>tmplt_target-update_table-delete_rows</name>
    <description />
    <extended_description />
    <trans_version />
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>/generic/target_update</directory>
    <parameters>
      <parameter>
        <name>PARAM_CDC_CONTROL_SCHEMA_NAME</name>
        <default_value>public</default_value>
        <description>The name of the schema in the source database that contains the "CDC control table"</description>
      </parameter>
      <parameter>
        <name>PARAM_CDC_CONTROL_TABLE_BATCH_SIZE</name>
        <default_value>100</default_value>
        <description>The number of CDC control rows that will be processed in a single transaction</description>
      </parameter>
      <parameter>
        <name>PARAM_CDC_CONTROL_TABLE_NAME</name>
        <default_value>etl_cdc_analysis_request</default_value>
        <description>The name of the "CDC control table"</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE</name>
        <default_value>obo_opr</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER</name>
        <default_value>org.postgresql.Driver</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_HOST</name>
        <default_value>localhost</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD</name>
        <default_value>qfree_admin</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_PORT</name>
        <default_value>5432</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_URL</name>
        <default_value>jdbc:postgresql://localhost:5432/obo_opr</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME</name>
        <default_value>qfree_admin</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_DATABASE</name>
        <default_value>dwh_psa_obo</default_value>
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_DRIVER</name>
        <default_value>org.postgresql.Driver</default_value>
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_HOST</name>
        <default_value>localhost</default_value>
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD</name>
        <default_value>qfree_admin</default_value>
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_PORT</name>
        <default_value>5432</default_value>
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_URL</name>
        <default_value>jdbc:postgresql://localhost:5432/dwh_psa_obo</default_value>
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_USERNAME</name>
        <default_value>qfree_admin</default_value>
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_ETL_RUN_ID</name>
        <default_value>666</default_value>
        <description>Primary key for the ${QF_ETL_DB_SCHEMA}.etl_run row for the current "run"</description>
      </parameter>
      <parameter>
        <name>PARAM_ITER_COUNTER</name>
        <default_value>5</default_value>
        <description>Will have the value 1, 2,  .., PARAM_ITER_COUNTER_MAX on successive calls to this job</description>
      </parameter>
      <parameter>
        <name>PARAM_ITER_COUNTER_MAX</name>
        <default_value>13</default_value>
        <description>the maximum value that will be reached by PARAM_ITER_COUNTER on successive calls for the target table being treated</description>
      </parameter>
      <parameter>
        <name>PARAM_ROWS_DELETED</name>
        <default_value>400</default_value>
        <description>the number of rows ofthe target table so far deleted = (PARAM_ITER_COUNTER-1) * PARAM_CDC_CONTROL_TABLE_BATCH_SIZE</description>
      </parameter>
      <parameter>
        <name>PARAM_ROWS_TO_DELETE</name>
        <default_value>1250</default_value>
        <description>the number of rows of the target table that will be deleted after PARAM_ITER_COUNTER has reached PARAM_ITER_COUNTER_MAX</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_DB_ID</name>
        <default_value>2</default_value>
        <description>ID the "source" database containing tables will be mirrored to a "target" database</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_SCHEMA</name>
        <default_value>public</default_value>
        <description>Name of schema containing source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_TABLE</name>
        <default_value>analysis_request</default_value>
        <description>Name of source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_DB_ID</name>
        <default_value>10</default_value>
        <description>ID of the "target" database to which "source" DB tables will be archived/mirrored</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_SCHEMA</name>
        <default_value>public</default_value>
        <description>Name of schema containing target table to update</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_TABLE</name>
        <default_value>obo__analysis_request</default_value>
        <description>Name of target table to update</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_TABLE_UPDATE_ID</name>
        <default_value>1000000</default_value>
        <description>Primary key of ${QF_ETL_DB_SCHEMA}.target_table_update row to be updated by this job for progress and summary statistics</description>
      </parameter>
    </parameters>
    <log>
      <trans-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANS_SCHEMA}</schema>
        <table>${QF_LOG_TRANS_TABLE}</table>
        <size_limit_lines />
        <interval />
        <timeout_days>${QF_LOG_TRANS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STATUS</id>
          <enabled>Y</enabled>
          <name>STATUS</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
          <subject />
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
          <subject />
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
          <subject />
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
          <subject>Table input -  Source DB CDC control table</subject>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
          <subject />
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
          <subject />
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>STARTDATE</id>
          <enabled>Y</enabled>
          <name>STARTDATE</name>
        </field>
        <field>
          <id>ENDDATE</id>
          <enabled>Y</enabled>
          <name>ENDDATE</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>DEPDATE</id>
          <enabled>Y</enabled>
          <name>DEPDATE</name>
        </field>
        <field>
          <id>REPLAYDATE</id>
          <enabled>Y</enabled>
          <name>REPLAYDATE</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>Y</enabled>
          <name>LOG_FIELD</name>
        </field>
        <field>
          <id>EXECUTING_SERVER</id>
          <enabled>N</enabled>
          <name>EXECUTING_SERVER</name>
        </field>
        <field>
          <id>EXECUTING_USER</id>
          <enabled>N</enabled>
          <name>EXECUTING_USER</name>
        </field>
        <field>
          <id>CLIENT</id>
          <enabled>N</enabled>
          <name>CLIENT</name>
        </field>
      </trans-log-table>
      <perf-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSPERF_SCHEMA}</schema>
        <table>${QF_LOG_TRANSPERF_TABLE}</table>
        <interval />
        <timeout_days>${QF_LOG_TRANSPERF_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>SEQ_NR</id>
          <enabled>Y</enabled>
          <name>SEQ_NR</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>INPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>INPUT_BUFFER_ROWS</name>
        </field>
        <field>
          <id>OUTPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>OUTPUT_BUFFER_ROWS</name>
        </field>
      </perf-log-table>
      <channel-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_CHANNEL_SCHEMA}</schema>
        <table>${QF_LOG_CHANNEL_TABLE}</table>
        <timeout_days>${QF_LOG_CHANNEL_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>LOGGING_OBJECT_TYPE</id>
          <enabled>Y</enabled>
          <name>LOGGING_OBJECT_TYPE</name>
        </field>
        <field>
          <id>OBJECT_NAME</id>
          <enabled>Y</enabled>
          <name>OBJECT_NAME</name>
        </field>
        <field>
          <id>OBJECT_COPY</id>
          <enabled>Y</enabled>
          <name>OBJECT_COPY</name>
        </field>
        <field>
          <id>REPOSITORY_DIRECTORY</id>
          <enabled>Y</enabled>
          <name>REPOSITORY_DIRECTORY</name>
        </field>
        <field>
          <id>FILENAME</id>
          <enabled>Y</enabled>
          <name>FILENAME</name>
        </field>
        <field>
          <id>OBJECT_ID</id>
          <enabled>Y</enabled>
          <name>OBJECT_ID</name>
        </field>
        <field>
          <id>OBJECT_REVISION</id>
          <enabled>Y</enabled>
          <name>OBJECT_REVISION</name>
        </field>
        <field>
          <id>PARENT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>PARENT_CHANNEL_ID</name>
        </field>
        <field>
          <id>ROOT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>ROOT_CHANNEL_ID</name>
        </field>
      </channel-log-table>
      <step-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSSTEP_SCHEMA}</schema>
        <table>${QF_LOG_TRANSSTEP_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSSTEP_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>N</enabled>
          <name>LOG_FIELD</name>
        </field>
      </step-log-table>
      <metrics-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSMETRICS_SCHEMA}</schema>
        <table>${QF_LOG_TRANSMETRICS_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSMETRICS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>METRICS_DATE</id>
          <enabled>Y</enabled>
          <name>METRICS_DATE</name>
        </field>
        <field>
          <id>METRICS_CODE</id>
          <enabled>Y</enabled>
          <name>METRICS_CODE</name>
        </field>
        <field>
          <id>METRICS_DESCRIPTION</id>
          <enabled>Y</enabled>
          <name>METRICS_DESCRIPTION</name>
        </field>
        <field>
          <id>METRICS_SUBJECT</id>
          <enabled>Y</enabled>
          <name>METRICS_SUBJECT</name>
        </field>
        <field>
          <id>METRICS_TYPE</id>
          <enabled>Y</enabled>
          <name>METRICS_TYPE</name>
        </field>
        <field>
          <id>METRICS_VALUE</id>
          <enabled>Y</enabled>
          <name>METRICS_VALUE</name>
        </field>
      </metrics-log-table>
    </log>
    <maxdate>
      <connection />
      <table />
      <field />
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>Y</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file />
    <capture_step_performance>Y</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
    <created_user>-</created_user>
    <created_date>2016/04/03 09:57:16.279</created_date>
    <modified_user>-</modified_user>
    <modified_date>2020/11/18 07:26:29.502</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA=</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
    <notepad>
      <note>Load a block of rows from the "CDC control table" in the source DB that specify rows to delete from the target  table in the target DB.</note>
      <xloc>320</xloc>
      <yloc>688</yloc>
      <width>749</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This transformation deletes a block of rows of the "target" table. It is called repeatedly with PARAM_ITER_COUNTER having the value 1, 2, .., PARAM_ITER_COUNTER_MAX on successive calls to this  
transformation until the required number of rows are deleted. This is a generic algorithm that can work with *any* table,  provided that there exiusts a "CDC control table" for it. This transformation
makes use of metadata injection. The row deletion is performed in blocks instead of in one single go to make it possible to:

1.	Check for shutdown requests while rows are being deleted.
2.	Monitor the row deletions to be able to log the progress made.

This transformation has the following option enabled to ensure that the both blocks of rows from the "CDC control table" and the target table are successfully deleted or nothing is deleted.

	Make the transformation database transactional

This transformation has parameters:

	PARAM_ETL_RUN_ID								Primary key for the ${QF_ETL_DB_SCHEMA}.etl_run row for the current "run"
	PARAM_TARGET_TABLE_UPDATE_ID				Primary key of ${QF_ETL_DB_SCHEMA}.target_table_update row to be updated by this job for progress and summary statistics

	PARAM_CDC_CONTROL_SCHEMA_NAME			The name of the schema in the source database that contains the "CDC control table"
	PARAM_CDC_CONTROL_TABLE_NAME				The name of the "CDC control table"
	PARAM_CDC_CONTROL_TABLE_BATCH_SIZE		The number of CDC control rows that will be processed in a single transaction
	PARAM_ITER_COUNTER							Will have the value 1, 2,  .., PARAM_ITER_COUNTER_MAX on successive calls to this job. On each call, this 
													job should attempt to select a batch/block/page of PARAM_CDC_CONTROL_TABLE_BATCH_SIZE rows of the 
													CDC control table and then use these to delete the corresponding rows of the target table
	PARAM_ITER_COUNTER_MAX						the maximum value that will be reached by PARAM_ITER_COUNTER on successive calls for the target table being treated
	PARAM_ROWS_DELETED							the number of rows ofthe target table so far deleted = (PARAM_ITER_COUNTER-1) * PARAM_CDC_CONTROL_TABLE_BATCH_SIZE
	PARAM_ROWS_TO_DELETE						the number of rows of the target table that will be deleted after PARAM_ITER_COUNTER has reached PARAM_ITER_COUNTER_MAX

	PARAM_DYN_DB_CONN_SOURCE_DB_HOST		for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_PORT		for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER		for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_URL			for source DB "dynamic" database connections

	PARAM_DYN_DB_CONN_TARGET_DB_HOST		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_PORT		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_DATABASE	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_USERNAME	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_DRIVER		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_URL			for target DB "dynamic" database connections

Many or all of these parameters are not being used and may be removed:

	PARAM_SOURCE_DB_ID							ID the "source" database containing tables will be mirrored to a "target" database
	PARAM_SOURCE_SCHEMA						Name of schema containing source table to mirror to target table
	PARAM_SOURCE_TABLE							Name of source table to mirror to target table
	PARAM_TARGET_DB_ID							ID of the "target" database to which "source" DB tables will be archived/mirrored
	PARAM_TARGET_SCHEMA						Name of schema containing target table to update
	PARAM_TARGET_TABLE							Name of target table to update</note>
      <xloc>0</xloc>
      <yloc>0</yloc>
      <width>1093</width>
      <heigth>660</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Although this transformation has parameters whose values are used in its steps, these parameters are not 
passed values from the parent transformation in the usual way this is normally done in PDI. This is because 
the "ETL Metadata Injection" step (which is responsible for executing this template transformation) does not 
support parameter passing. Nevertheless, it appears that the parameters that are defined for this template 
transformation can be used as expected. The explanation for this behaviour *MAY* be that the references to 
these parameters, e.g., ${PARAM_SOURCE_TABLE}, in this transformation are simply using the values defined 
for these variables in the parent transformation that contains the "ETL Metadata Injection" step that 
references this template transformation. Fortunately, all of the parameters that are used by this transformation 
are defined with the correct values in the parent transformation. I have tested this by removing the parameters 
entirely. The result was that the transformation ran as expected, even though it made use of the parameters 
that were removed.

Note that if a target file is created by the "ETL metadata Injection" step, then that transformation *can* have 
its parameters passed to it in the normal fashion because it is a normal transformation (all metadata has been 
injected into it).</note>
      <xloc>608</xloc>
      <yloc>352</yloc>
      <width>628</width>
      <heigth>205</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>255</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Metadata injected -></note>
      <xloc>48</xloc>
      <yloc>768</yloc>
      <width>124</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>255</fontcolorred>
      <fontcolorgreen>255</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>0</backgroundcolorred>
      <backgroundcolorgreen>0</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Set PDI variable:

	QF_UPDATE_TABLE_NUM_DELETES</note>
      <xloc>320</xloc>
      <yloc>1008</yloc>
      <width>229</width>
      <heigth>49</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Delete target rows specified by the stream of CDC control table rows.</note>
      <xloc>320</xloc>
      <yloc>768</yloc>
      <width>394</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This should always equal PARAM_CDC_CONTROL_TABLE_BATCH_SIZE, except for the last batch of deletes.</note>
      <xloc>320</xloc>
      <yloc>928</yloc>
      <width>592</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This template transformation cannot be used with PDI 8.2 since 
this version of PDI does not support metadata injection for the 
Delete transformation step. Metadata injection for this step 
was added in version 9.0 !

To get around this problem, I wrote the transformation:

	tr_target-update_table-delete_rows-without_mi

which can be used with PDI 8.2.</note>
      <xloc>944</xloc>
      <yloc>720</yloc>
      <width>559</width>
      <heigth>230</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>14</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>173</backgroundcolorred>
      <backgroundcolorgreen>216</backgroundcolorgreen>
      <backgroundcolorblue>230</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Delete the stream of CDC control table rows from the source database.</note>
      <xloc>320</xloc>
      <yloc>848</yloc>
      <width>402</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <connection>
    <name>generic_source_db</name>
    <server>${PARAM_DYN_DB_CONN_SOURCE_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE}</database>
    <port>${PARAM_DYN_DB_CONN_SOURCE_DB_PORT}</port>
    <username>${PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME}</username>
    <password>${PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${PARAM_DYN_DB_CONN_SOURCE_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>generic_target_db</name>
    <server>${PARAM_DYN_DB_CONN_TARGET_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${PARAM_DYN_DB_CONN_TARGET_DB_DATABASE}</database>
    <port>${PARAM_DYN_DB_CONN_TARGET_DB_PORT}</port>
    <username>${PARAM_DYN_DB_CONN_TARGET_DB_USERNAME}</username>
    <password>${PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${PARAM_DYN_DB_CONN_TARGET_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>logging_db</name>
    <server>${QF_LOGGING_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_LOGGING_DB_DATABASE}</database>
    <port>${QF_LOGGING_DB_PORT}</port>
    <username>${QF_LOGGING_DB_USERNAME}</username>
    <password>${QF_LOGGING_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>INITIAL_POOL_SIZE</code>
        <attribute>10</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>MAXIMUM_POOL_SIZE</code>
        <attribute>10</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_LOGGING_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>Y</attribute>
      </attribute>
    </attributes>
  </connection>
  <order>
    <hop>
      <from>Compute number of rows deleted</from>
      <to>QF_UPDATE_TABLE_NUM_DELETES</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>QF_UPDATE_TABLE_NUM_DELETES</from>
      <to>Get transformation name</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Get transformation name</from>
      <to>Log number of rows deleted</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Table input -  Source DB CDC control table</from>
      <to>Delete block of target rows</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Delete block of target rows</from>
      <to>Delete block of CDC control table rows</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Delete block of target rows</from>
      <to>Write to log</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Write to log</from>
      <to>Abort</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Write to log 2</from>
      <to>Abort 2</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Delete block of CDC control table rows</from>
      <to>Compute number of rows deleted</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Delete block of CDC control table rows</from>
      <to>Write to log 2</to>
      <enabled>Y</enabled>
    </hop>
  </order>
  <step>
    <name>Abort</name>
    <type>Abort</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <row_threshold>0</row_threshold>
    <message />
    <always_log_rows>Y</always_log_rows>
    <abort_option>ABORT</abort_option>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>896</xloc>
      <yloc>768</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Abort 2</name>
    <type>Abort</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <row_threshold>0</row_threshold>
    <message />
    <always_log_rows>Y</always_log_rows>
    <abort_option>ABORT</abort_option>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>896</xloc>
      <yloc>848</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Compute number of rows deleted</name>
    <type>MemoryGroupBy</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <give_back_row>Y</give_back_row>
    <group>
      </group>
    <fields>
      <field>
        <aggregate>num_rows_deleted</aggregate>
        <subject />
        <type>COUNT_ANY</type>
        <valuefield />
      </field>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>176</xloc>
      <yloc>928</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Delete block of CDC control table rows</name>
    <type>Delete</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>generic_source_db</connection>
    <commit>${PARAM_CDC_CONTROL_TABLE_BATCH_SIZE}</commit>
    <lookup>
      <schema>${PARAM_CDC_CONTROL_SCHEMA_NAME}</schema>
      <table>${PARAM_CDC_CONTROL_TABLE_NAME}</table>
      <key>
        <name>cdc_id</name>
        <field>cdc_id</field>
        <condition>=</condition>
        <name2 />
      </key>
    </lookup>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>176</xloc>
      <yloc>848</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Delete block of target rows</name>
    <type>Delete</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>generic_target_db</connection>
    <commit>${PARAM_CDC_CONTROL_TABLE_BATCH_SIZE}</commit>
    <lookup>
      <schema>public</schema>
      <table>obo__analysis_request</table>
      <key>
        <name>cdc_key_id</name>
        <field>analysis_request_id</field>
        <condition>=</condition>
        <name2 />
      </key>
    </lookup>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>176</xloc>
      <yloc>768</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Get transformation name</name>
    <type>SystemInfo</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>current_transformation</name>
        <type>transformation name</type>
      </field>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>176</xloc>
      <yloc>1088</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Log number of rows deleted</name>
    <type>WriteToLog</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <loglevel>log_level_minimal</loglevel>
    <displayHeader>Y</displayHeader>
    <limitRows>N</limitRows>
    <limitRowsNumber>0</limitRowsNumber>
    <logmessage>PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE   = ${PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE}
PARAM_DYN_DB_CONN_TARGET_DB_DATABASE   = ${PARAM_DYN_DB_CONN_TARGET_DB_DATABASE}
PARAM_SOURCE_SCHEMA                    = ${PARAM_SOURCE_SCHEMA}
PARAM_SOURCE_TABLE                     = ${PARAM_SOURCE_TABLE}
PARAM_TARGET_SCHEMA                    = ${PARAM_TARGET_SCHEMA}
PARAM_TARGET_TABLE                     = ${PARAM_TARGET_TABLE}</logmessage>
    <fields>
      <field>
        <name>current_transformation</name>
      </field>
      <field>
        <name>num_rows_deleted</name>
      </field>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>176</xloc>
      <yloc>1168</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>QF_UPDATE_TABLE_NUM_DELETES</name>
    <type>SetVariable</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <field_name>num_rows_deleted</field_name>
        <variable_name>QF_UPDATE_TABLE_NUM_DELETES</variable_name>
        <variable_type>ROOT_JOB</variable_type>
        <default_value />
      </field>
    </fields>
    <use_formatting>Y</use_formatting>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>176</xloc>
      <yloc>1008</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Table input -  Source DB CDC control table</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>generic_source_db</connection>
    <sql>-- This statement is commented out because the SQL statement is, instead, injected via ETL Metadata Injection:
--
SELECT
    cdc_id,
--    cdc_type,
    cdc_key_id,
    cdc_timestamp
FROM
    ${PARAM_CDC_CONTROL_SCHEMA_NAME}.${PARAM_CDC_CONTROL_TABLE_NAME}
WHERE
    cdc_type='${QF_CDC_CONTROL_TABLE_OP_CODE_DELETE}'
ORDER BY
    cdc_id
LIMIT 
    ${PARAM_CDC_CONTROL_TABLE_BATCH_SIZE}</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>176</xloc>
      <yloc>688</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Write to log</name>
    <type>WriteToLog</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <loglevel>log_level_minimal</loglevel>
    <displayHeader>Y</displayHeader>
    <limitRows>N</limitRows>
    <limitRowsNumber>0</limitRowsNumber>
    <logmessage>**********************************************************
**********************************************************
**********************************************************
Error handling triggered for "Delete block of target rows"
**********************************************************
**********************************************************
**********************************************************</logmessage>
    <fields>
      <field>
        <name>cdc_id</name>
      </field>
      <field>
        <name>cdc_key_id</name>
      </field>
      <field>
        <name>cdc_timestamp</name>
      </field>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>784</xloc>
      <yloc>768</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Write to log 2</name>
    <type>WriteToLog</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <loglevel>log_level_minimal</loglevel>
    <displayHeader>Y</displayHeader>
    <limitRows>N</limitRows>
    <limitRowsNumber>0</limitRowsNumber>
    <logmessage>**********************************************************
**********************************************************
**********************************************************
Error handling triggered for "Delete block of CDC control table rows"
**********************************************************
**********************************************************
**********************************************************</logmessage>
    <fields>
      <field>
        <name>cdc_id</name>
      </field>
      <field>
        <name>cdc_key_id</name>
      </field>
      <field>
        <name>cdc_timestamp</name>
      </field>
    </fields>
    <attributes />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>784</xloc>
      <yloc>848</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step_error_handling>
    <error>
      <source_step>Delete block of CDC control table rows</source_step>
      <target_step>Write to log 2</target_step>
      <is_enabled>Y</is_enabled>
      <nr_valuename />
      <descriptions_valuename />
      <fields_valuename />
      <codes_valuename />
      <max_errors />
      <max_pct_errors />
      <min_pct_rows />
    </error>
    <error>
      <source_step>Delete block of target rows</source_step>
      <target_step>Write to log</target_step>
      <is_enabled>Y</is_enabled>
      <nr_valuename />
      <descriptions_valuename />
      <fields_valuename />
      <codes_valuename />
      <max_errors />
      <max_pct_errors />
      <min_pct_rows />
    </error>
  </step_error_handling>
  <slave-step-copy-partition-distribution>
  </slave-step-copy-partition-distribution>
  <slave_transformation>N</slave_transformation>
  <attributes />
</transformation>
