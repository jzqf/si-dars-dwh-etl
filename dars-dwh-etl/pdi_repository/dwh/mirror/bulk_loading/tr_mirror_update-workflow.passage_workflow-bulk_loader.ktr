<transformation>
  <info>
    <name>tr_mirror_update-workflow.passage_workflow-bulk_loader</name>
    <description/>
    <extended_description/>
    <trans_version/>
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>&#x2f;dwh&#x2f;mirror&#x2f;bulk_loading</directory>
    <parameters>
        <parameter>
            <name>PARAM_CDC_CURRENT_LOAD_UTC</name>
            <default_value>1900.01.01 00&#x3a;00&#x3a;00</default_value>
            <description>Timestamp of the current load &#x28;no rows after this timestamp will be loaded&#x29;</description>
        </parameter>
        <parameter>
            <name>PARAM_CDC_LAST_LOAD_UTC</name>
            <default_value>1900.01.01 00&#x3a;00&#x3a;00</default_value>
            <description>Timestamp of last successful load from the source database</description>
        </parameter>
    </parameters>
    <log>
<trans-log-table><connection>logging_db</connection>
<schema>&#x24;&#x7b;QF_LOG_TRANS_SCHEMA&#x7d;</schema>
<table>&#x24;&#x7b;QF_LOG_TRANS_TABLE&#x7d;</table>
<size_limit_lines/>
<interval/>
<timeout_days>&#x24;&#x7b;QF_LOG_TRANS_TIMEOUT_IN_DAYS&#x7d;</timeout_days>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STATUS</id><enabled>Y</enabled><name>STATUS</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name><subject>PostgreSQL Bulk Loader - DWH.workflow.passage_workflow</subject></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name><subject>PostgreSQL Bulk Loader - DWH.workflow.passage_workflow</subject></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name><subject>PostgreSQL Bulk Loader - DWH.workflow.passage_workflow</subject></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name><subject>Table input -  TDP.workflow.passage_workflow</subject></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name><subject>PostgreSQL Bulk Loader - DWH.workflow.passage_workflow</subject></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name><subject>PostgreSQL Bulk Loader - DWH.workflow.passage_workflow</subject></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>STARTDATE</id><enabled>Y</enabled><name>STARTDATE</name></field><field><id>ENDDATE</id><enabled>Y</enabled><name>ENDDATE</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>DEPDATE</id><enabled>Y</enabled><name>DEPDATE</name></field><field><id>REPLAYDATE</id><enabled>Y</enabled><name>REPLAYDATE</name></field><field><id>LOG_FIELD</id><enabled>Y</enabled><name>LOG_FIELD</name></field><field><id>EXECUTING_SERVER</id><enabled>N</enabled><name>EXECUTING_SERVER</name></field><field><id>EXECUTING_USER</id><enabled>N</enabled><name>EXECUTING_USER</name></field><field><id>CLIENT</id><enabled>N</enabled><name>CLIENT</name></field></trans-log-table>
<perf-log-table><connection>logging_db</connection>
<schema>&#x24;&#x7b;QF_LOG_TRANSPERFORMANCE_SCHEMA&#x7d;</schema>
<table>&#x24;&#x7b;QF_LOG_TRANSPERFORMANCE_TABLE&#x7d;</table>
<interval/>
<timeout_days>&#x24;&#x7b;QF_LOG_TRANSPERFORMANCE_TIMEOUT_IN_DAYS&#x7d;</timeout_days>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>SEQ_NR</id><enabled>Y</enabled><name>SEQ_NR</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>INPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>INPUT_BUFFER_ROWS</name></field><field><id>OUTPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>OUTPUT_BUFFER_ROWS</name></field></perf-log-table>
<channel-log-table><connection>logging_db</connection>
<schema>&#x24;&#x7b;QF_LOG_CHANNEL_SCHEMA&#x7d;</schema>
<table>&#x24;&#x7b;QF_LOG_CHANNEL_TABLE&#x7d;</table>
<timeout_days>&#x24;&#x7b;QF_LOG_CHANNEL_TIMEOUT_IN_DAYS&#x7d;</timeout_days>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>LOGGING_OBJECT_TYPE</id><enabled>Y</enabled><name>LOGGING_OBJECT_TYPE</name></field><field><id>OBJECT_NAME</id><enabled>Y</enabled><name>OBJECT_NAME</name></field><field><id>OBJECT_COPY</id><enabled>Y</enabled><name>OBJECT_COPY</name></field><field><id>REPOSITORY_DIRECTORY</id><enabled>Y</enabled><name>REPOSITORY_DIRECTORY</name></field><field><id>FILENAME</id><enabled>Y</enabled><name>FILENAME</name></field><field><id>OBJECT_ID</id><enabled>Y</enabled><name>OBJECT_ID</name></field><field><id>OBJECT_REVISION</id><enabled>Y</enabled><name>OBJECT_REVISION</name></field><field><id>PARENT_CHANNEL_ID</id><enabled>Y</enabled><name>PARENT_CHANNEL_ID</name></field><field><id>ROOT_CHANNEL_ID</id><enabled>Y</enabled><name>ROOT_CHANNEL_ID</name></field></channel-log-table>
<step-log-table><connection>logging_db</connection>
<schema>&#x24;&#x7b;QF_LOG_TRANSSTEP_SCHEMA&#x7d;</schema>
<table>&#x24;&#x7b;QF_LOG_TRANSSTEP_TABLE&#x7d;</table>
<timeout_days>&#x24;&#x7b;QF_LOG_TRANSSTEP_TIMEOUT_IN_DAYS&#x7d;</timeout_days>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>LOG_FIELD</id><enabled>N</enabled><name>LOG_FIELD</name></field></step-log-table>
<metrics-log-table><connection>logging_db</connection>
<schema>&#x24;&#x7b;QF_LOG_TRANSMETRICS_SCHEMA&#x7d;</schema>
<table>&#x24;&#x7b;QF_LOG_TRANSMETRICS_TABLE&#x7d;</table>
<timeout_days>&#x24;&#x7b;QF_LOG_TRANSMETRICS_TIMEOUT_IN_DAYS&#x7d;</timeout_days>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>METRICS_DATE</id><enabled>Y</enabled><name>METRICS_DATE</name></field><field><id>METRICS_CODE</id><enabled>Y</enabled><name>METRICS_CODE</name></field><field><id>METRICS_DESCRIPTION</id><enabled>Y</enabled><name>METRICS_DESCRIPTION</name></field><field><id>METRICS_SUBJECT</id><enabled>Y</enabled><name>METRICS_SUBJECT</name></field><field><id>METRICS_TYPE</id><enabled>Y</enabled><name>METRICS_TYPE</name></field><field><id>METRICS_VALUE</id><enabled>Y</enabled><name>METRICS_VALUE</name></field></metrics-log-table>
    </log>
    <maxdate>
      <connection/>
      <table/>
      <field/>
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file/>
    <capture_step_performance>Y</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
  <created_user>-</created_user>
  <created_date>2016&#x2f;04&#x2f;03 09&#x3a;57&#x3a;16.279</created_date>
  <modified_user>-</modified_user>
  <modified_date>2016&#x2f;06&#x2f;03 15&#x3a;14&#x3a;05.733</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA&#x3d;</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
    <notepad>
      <note>Convert Timestamp fields to type Date. The bulk loader does not work with type Timestamp.&#xa;&#xa;Convert Boolean fields to type String. The bulk loader has problems with the encoding of &#xa;Boolean fields. For example, if the field value is Y, then the bulk loader will complain with&#x3a;&#xa;&#xa;    ERROR&#x3a;  invalid input syntax for type boolean&#x3a; &#x22;1.0&#x22;&#xa;&#xa;Converting the Boolean field to String seems to work. The target PostgreSQL column type&#xa;can still be &#x22;boolean&#x22;&#x3b; it is not necessary to change it to type &#x22;varchar&#x28;&#x29;&#x22;.</note>
      <xloc>416</xloc>
      <yloc>496</yloc>
      <width>625</width>
      <heigth>163</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Load the data from the source database table that will be moved to the DWH table.&#xa;&#xa;It is important here to select &#x22;replace variables in script&#x3f;&#x22;so that the references &#x22;&#x3f;&#x22;,&#xa;&#x24;&#x7b;PARAM_CDC_LAST_LOAD_UTC&#x7d; and &#x24;&#x7b;PARAM_CDC_CURRENT_LOAD_UTC&#x7d; will be evaluated.&#xa;&#xa;It is also necessary to specify the step from which fields will  be used to supply values &#xa;for the &#x22;&#x3f;&#x22; replacement characters.  In this case, the previous step is specified.</note>
      <xloc>416</xloc>
      <yloc>304</yloc>
      <width>576</width>
      <heigth>129</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Insert the new rows into the DWH using a PostgreSQL Bulk Loader step.</note>
      <xloc>416</xloc>
      <yloc>672</yloc>
      <width>484</width>
      <heigth>27</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Write parameters and max_target_insert_id value to the log so it will be obvious which values &#xa;were used.</note>
      <xloc>416</xloc>
      <yloc>240</yloc>
      <width>538</width>
      <heigth>44</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Get batch ID for current transformation. This will be stored in the DWH table.</note>
      <xloc>416</xloc>
      <yloc>448</yloc>
      <width>522</width>
      <heigth>27</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Get the maximum value stored in column &#x22;archive_id&#x22; of the DWH table that will &#xa;be updated by this transformation. This will be used to the select data from the &#xa;source table in the TDP archive database that was inserted since the last update. &#xa;&#xa;IMPORTANT&#x3a;	We &#x2a;cannot&#x2a; use MAX&#x28;archive_date&#x29; for this purpose because the&#xa;				&#x22;archive_date&#x22; column will not, in general, be unique.</note>
      <xloc>416</xloc>
      <yloc>112</yloc>
      <width>547</width>
      <heigth>112</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Limited testing has indicated that this &#x22;Bulk Loader&#x22; transformation is aproximately 300&#x25; faster than the &#xa;corresponding &#x22;Table Output&#x22; transformation, tr_mirror_update-workflow.passage_workflow-table_output&#x21;&#xa;&#xa;This was based on transferring 450000 rows to a DWH database on my local PC &#x28;where I have an SSD&#x29;.</note>
      <xloc>128</xloc>
      <yloc>752</yloc>
      <width>736</width>
      <heigth>78</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This transformation updates the DWH mirror of the &#x22;dynamic&#x22; table workflow.passage_workflow from the TDP archive database.&#xa;This transformation has parameters&#x3a;&#xa;&#xa;	PARAM_CDC_LAST_LOAD_UTC		&#x3c;- not used in this transformation - MAX&#x28;archive_id&#x29; is used instead&#xa;	PARAM_CDC_CURRENT_LOAD_UTC</note>
      <xloc>16</xloc>
      <yloc>0</yloc>
      <width>873</width>
      <heigth>95</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <connection>
    <name>dwh_db</name>
    <server>&#x24;&#x7b;QF_DWH_DB_HOST&#x7d;</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>&#x24;&#x7b;QF_DWH_DB_DATABASE&#x7d;</database>
    <port>&#x24;&#x7b;QF_DWH_DB_PORT&#x7d;</port>
    <username>&#x24;&#x7b;QF_DWH_DB_USERNAME&#x7d;</username>
    <password>&#x24;&#x7b;QF_DWH_DB_PASSWORD&#x7d;</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute><code>FORCE_IDENTIFIERS_TO_LOWERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_UPPERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>IS_CLUSTERED</code><attribute>N</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>&#x24;&#x7b;QF_DWH_DB_PORT&#x7d;</attribute></attribute>
      <attribute><code>PRESERVE_RESERVED_WORD_CASE</code><attribute>N</attribute></attribute>
      <attribute><code>QUOTE_ALL_FIELDS</code><attribute>N</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_TIMESTAMP_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>USE_POOLING</code><attribute>N</attribute></attribute>
    </attributes>
  </connection>
  <connection>
    <name>logging_db</name>
    <server>&#x24;&#x7b;QF_LOGGING_DB_HOST&#x7d;</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>&#x24;&#x7b;QF_LOGGING_DB_DATABASE&#x7d;</database>
    <port>&#x24;&#x7b;QF_LOGGING_DB_PORT&#x7d;</port>
    <username>&#x24;&#x7b;QF_LOGGING_DB_USERNAME&#x7d;</username>
    <password>&#x24;&#x7b;QF_LOGGING_DB_PASSWORD&#x7d;</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute><code>FORCE_IDENTIFIERS_TO_LOWERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_UPPERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>IS_CLUSTERED</code><attribute>N</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>&#x24;&#x7b;QF_LOGGING_DB_PORT&#x7d;</attribute></attribute>
      <attribute><code>PRESERVE_RESERVED_WORD_CASE</code><attribute>N</attribute></attribute>
      <attribute><code>QUOTE_ALL_FIELDS</code><attribute>N</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_TIMESTAMP_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>USE_POOLING</code><attribute>N</attribute></attribute>
    </attributes>
  </connection>
  <connection>
    <name>obo_opr_db</name>
    <server>&#x24;&#x7b;QF_OBO_OPR_DB_HOST&#x7d;</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>&#x24;&#x7b;QF_OBO_OPR_DB_DATABASE&#x7d;</database>
    <port>&#x24;&#x7b;QF_OBO_OPR_DB_PORT&#x7d;</port>
    <username>&#x24;&#x7b;QF_OBO_OPR_DB_USERNAME&#x7d;</username>
    <password>&#x24;&#x7b;QF_OBO_OPR_DB_PASSWORD&#x7d;</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute><code>FORCE_IDENTIFIERS_TO_LOWERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_UPPERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>IS_CLUSTERED</code><attribute>N</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>&#x24;&#x7b;QF_OBO_OPR_DB_PORT&#x7d;</attribute></attribute>
      <attribute><code>PRESERVE_RESERVED_WORD_CASE</code><attribute>N</attribute></attribute>
      <attribute><code>QUOTE_ALL_FIELDS</code><attribute>N</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_TIMESTAMP_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>USE_POOLING</code><attribute>N</attribute></attribute>
    </attributes>
  </connection>
  <order>
  <hop> <from>Select values</from><to>PostgreSQL Bulk Loader - DWH.workflow.passage_workflow</to><enabled>Y</enabled> </hop>
  <hop> <from>Table input -  TDP.workflow.passage_workflow</from><to>Get System Info - transformation batch ID</to><enabled>Y</enabled> </hop>
  <hop> <from>Get System Info - transformation batch ID</from><to>Select values</to><enabled>Y</enabled> </hop>
  <hop> <from>Get max ID for CDC&#x3a; DWH.workflow.passage_workflow</from><to>Write to log&#x3a; parameters, max_target_insert_id</to><enabled>Y</enabled> </hop>
  <hop> <from>Write to log&#x3a; parameters, max_target_insert_id</from><to>Table input -  TDP.workflow.passage_workflow</to><enabled>Y</enabled> </hop>
  </order>
  <step>
    <name>Get System Info - transformation batch ID</name>
    <type>SystemInfo</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <fields>
      <field>
        <name>etl_batch_id_insert</name>
        <type>batch ID</type>
        </field>
      </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>192</xloc>
      <yloc>448</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Get max ID for CDC&#x3a; DWH.workflow.passage_workflow</name>
    <type>TableInput</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <connection>dwh_db</connection>
    <sql>SELECT&#xa;    COALESCE&#x28;MAX&#x28;archive_id&#x29;, &#x24;&#x7b;QF_INSERT_ID_LOWER_BOUND&#x7d;&#x29; AS max_target_insert_id&#xa;FROM&#xa;    workflow.passage_workflow&#xa;</sql>
    <limit>0</limit>
    <lookup/>
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>192</xloc>
      <yloc>160</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>PostgreSQL Bulk Loader - DWH.workflow.passage_workflow</name>
    <type>PGBulkLoader</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <connection>dwh_db</connection>
    <schema>workflow</schema>
    <table>passage_workflow</table>
    <load_action>INSERT</load_action>
    <PsqlPath>&#x24;&#x7b;QF_POSTGRESQL_BULK_LOADER_PSQL_PATH&#x7d;</PsqlPath>
    <dbname_override/>
    <enclosure>&#x22;</enclosure>
    <delimiter>&#x3b;</delimiter>
    <stop_on_error>N</stop_on_error>
      <mapping>
        <stream_name>pw_id</stream_name>
        <field_name>pw_id</field_name>
        <date_mask/>
      </mapping>
      <mapping>
        <stream_name>passage_id</stream_name>
        <field_name>passage_id</field_name>
        <date_mask/>
      </mapping>
      <mapping>
        <stream_name>workflow_step_id</stream_name>
        <field_name>workflow_step_id</field_name>
        <date_mask/>
      </mapping>
      <mapping>
        <stream_name>new_time</stream_name>
        <field_name>new_time</field_name>
        <date_mask/>
      </mapping>
      <mapping>
        <stream_name>proc_time</stream_name>
        <field_name>proc_time</field_name>
        <date_mask/>
      </mapping>
      <mapping>
        <stream_name>done_time</stream_name>
        <field_name>done_time</field_name>
        <date_mask/>
      </mapping>
      <mapping>
        <stream_name>next_workflow_step_id</stream_name>
        <field_name>next_workflow_step_id</field_name>
        <date_mask/>
      </mapping>
      <mapping>
        <stream_name>workflow_complete</stream_name>
        <field_name>workflow_complete</field_name>
        <date_mask/>
      </mapping>
      <mapping>
        <stream_name>archive_id</stream_name>
        <field_name>archive_id</field_name>
        <date_mask/>
      </mapping>
      <mapping>
        <stream_name>archive_date</stream_name>
        <field_name>archive_date</field_name>
        <date_mask/>
      </mapping>
      <mapping>
        <stream_name>etl_batch_id_insert</stream_name>
        <field_name>etl_batch_id_insert</field_name>
        <date_mask/>
      </mapping>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>192</xloc>
      <yloc>672</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Select values</name>
    <type>SelectValues</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <fields>        <select_unspecified>N</select_unspecified>
      <meta>        <name>new_time</name>
        <rename>new_time</rename>
        <type>Date</type>
        <length>-2</length>
        <precision>-2</precision>
        <conversion_mask/>
        <date_format_lenient>false</date_format_lenient>
        <date_format_locale/>
        <date_format_timezone/>
        <lenient_string_to_number>false</lenient_string_to_number>
        <encoding/>
        <decimal_symbol/>
        <grouping_symbol/>
        <currency_symbol/>
        <storage_type/>
      </meta>      <meta>        <name>proc_time</name>
        <rename>proc_time</rename>
        <type>Date</type>
        <length>-2</length>
        <precision>-2</precision>
        <conversion_mask/>
        <date_format_lenient>false</date_format_lenient>
        <date_format_locale/>
        <date_format_timezone/>
        <lenient_string_to_number>false</lenient_string_to_number>
        <encoding/>
        <decimal_symbol/>
        <grouping_symbol/>
        <currency_symbol/>
        <storage_type/>
      </meta>      <meta>        <name>done_time</name>
        <rename>done_time</rename>
        <type>Date</type>
        <length>-2</length>
        <precision>-2</precision>
        <conversion_mask/>
        <date_format_lenient>false</date_format_lenient>
        <date_format_locale/>
        <date_format_timezone/>
        <lenient_string_to_number>false</lenient_string_to_number>
        <encoding/>
        <decimal_symbol/>
        <grouping_symbol/>
        <currency_symbol/>
        <storage_type/>
      </meta>      <meta>        <name>workflow_complete</name>
        <rename>workflow_complete</rename>
        <type>String</type>
        <length>-2</length>
        <precision>-2</precision>
        <conversion_mask/>
        <date_format_lenient>false</date_format_lenient>
        <date_format_locale/>
        <date_format_timezone/>
        <lenient_string_to_number>false</lenient_string_to_number>
        <encoding/>
        <decimal_symbol/>
        <grouping_symbol/>
        <currency_symbol/>
        <storage_type/>
      </meta>      <meta>        <name>archive_date</name>
        <rename>archive_date</rename>
        <type>Date</type>
        <length>-2</length>
        <precision>-2</precision>
        <conversion_mask/>
        <date_format_lenient>false</date_format_lenient>
        <date_format_locale/>
        <date_format_timezone/>
        <lenient_string_to_number>false</lenient_string_to_number>
        <encoding/>
        <decimal_symbol/>
        <grouping_symbol/>
        <currency_symbol/>
        <storage_type/>
      </meta>    </fields>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>192</xloc>
      <yloc>560</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Table input -  TDP.workflow.passage_workflow</name>
    <type>TableInput</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <connection>obo_opr_db</connection>
    <sql>SELECT&#xa;    &#x2a;&#xa;FROM&#xa;    workflow.passage_workflow&#xa;WHERE&#xa;    archive_id &#x3e; &#x3f; AND&#xa;    --archive_date &#x3e;  &#x27;&#x24;&#x7b;PARAM_CDC_LAST_LOAD_UTC&#x7d;&#x27; AND &#xa;	archive_date &#x3c;&#x3d; &#x27;&#x24;&#x7b;PARAM_CDC_CURRENT_LOAD_UTC&#x7d;&#x27;&#xa;ORDER BY&#xa;    archive_id&#xa;</sql>
    <limit>0</limit>
    <lookup>Write to log&#x3a; parameters, max_target_insert_id</lookup>
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>192</xloc>
      <yloc>352</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Write to log&#x3a; parameters, max_target_insert_id</name>
    <type>WriteToLog</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
      <loglevel>log_level_basic</loglevel>
      <displayHeader>Y</displayHeader>
      <limitRows>N</limitRows>
      <limitRowsNumber>0</limitRowsNumber>
      <logmessage>PARAM_CDC_LAST_LOAD_UTC	&#x3d; &#x24;&#x7b;PARAM_CDC_LAST_LOAD_UTC&#x7d;&#xa;PARAM_CDC_CURRENT_LOAD_UTC	&#x3d; &#x24;&#x7b;PARAM_CDC_CURRENT_LOAD_UTC&#x7d;</logmessage>
    <fields>
      <field>
        <name>max_target_insert_id</name>
        </field>
      </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>192</xloc>
      <yloc>240</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step_error_handling>
  </step_error_handling>
   <slave-step-copy-partition-distribution>
</slave-step-copy-partition-distribution>
   <slave_transformation>N</slave_transformation>

</transformation>
