<transformation>
  <info>
    <name>tr_mirrored_insert_only_table-update</name>
    <description/>
    <extended_description/>
    <trans_version/>
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>&#x2f;dwh&#x2f;mirror</directory>
    <parameters>
        <parameter>
            <name>PARAM_CDC_CURRENT_LOAD</name>
            <default_value>1900.01.01 00&#x3a;00&#x3a;00</default_value>
            <description>Timestamp of the current load &#x28;no rows after this timestamp will be loaded&#x29;</description>
        </parameter>
        <parameter>
            <name>PARAM_CDC_LAST_LOAD</name>
            <default_value>1900.01.01 00&#x3a;00&#x3a;00</default_value>
            <description>Timestamp of last successful load from the source database</description>
        </parameter>
        <parameter>
            <name>PARAM_SOURCE_SCHEMA</name>
            <default_value>passage</default_value>
            <description>Schema of table to mirror</description>
        </parameter>
        <parameter>
            <name>PARAM_SOURCE_TABLE</name>
            <default_value>image</default_value>
            <description>Name of table to mirror</description>
        </parameter>
    </parameters>
    <log>
<trans-log-table><connection>logging_db</connection>
<schema>&#x24;&#x7b;QF_LOG_TRANS_SCHEMA&#x7d;</schema>
<table>&#x24;&#x7b;QF_LOG_TRANS_TABLE&#x7d;</table>
<size_limit_lines/>
<interval/>
<timeout_days>&#x24;&#x7b;QF_LOG_TRANS_TIMEOUT_IN_DAYS&#x7d;</timeout_days>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STATUS</id><enabled>Y</enabled><name>STATUS</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name><subject>Table output - DWH.schema.table</subject></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name><subject>Table output - DWH.schema.table</subject></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name><subject>Table output - DWH.schema.table</subject></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name><subject>Table input -  TDP.schema.table</subject></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name><subject>Table output - DWH.schema.table</subject></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name><subject>Table output - DWH.schema.table</subject></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>STARTDATE</id><enabled>Y</enabled><name>STARTDATE</name></field><field><id>ENDDATE</id><enabled>Y</enabled><name>ENDDATE</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>DEPDATE</id><enabled>Y</enabled><name>DEPDATE</name></field><field><id>REPLAYDATE</id><enabled>Y</enabled><name>REPLAYDATE</name></field><field><id>LOG_FIELD</id><enabled>Y</enabled><name>LOG_FIELD</name></field><field><id>EXECUTING_SERVER</id><enabled>N</enabled><name>EXECUTING_SERVER</name></field><field><id>EXECUTING_USER</id><enabled>N</enabled><name>EXECUTING_USER</name></field><field><id>CLIENT</id><enabled>N</enabled><name>CLIENT</name></field></trans-log-table>
<perf-log-table><connection>logging_db</connection>
<schema>&#x24;&#x7b;QF_LOG_TRANSPERFORMANCE_SCHEMA&#x7d;</schema>
<table>&#x24;&#x7b;QF_LOG_TRANSPERFORMANCE_TABLE&#x7d;</table>
<interval/>
<timeout_days>&#x24;&#x7b;QF_LOG_TRANSPERFORMANCE_TIMEOUT_IN_DAYS&#x7d;</timeout_days>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>SEQ_NR</id><enabled>Y</enabled><name>SEQ_NR</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>INPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>INPUT_BUFFER_ROWS</name></field><field><id>OUTPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>OUTPUT_BUFFER_ROWS</name></field></perf-log-table>
<channel-log-table><connection>logging_db</connection>
<schema>&#x24;&#x7b;QF_LOG_CHANNEL_SCHEMA&#x7d;</schema>
<table>&#x24;&#x7b;QF_LOG_CHANNEL_TABLE&#x7d;</table>
<timeout_days>&#x24;&#x7b;QF_LOG_CHANNEL_TIMEOUT_IN_DAYS&#x7d;</timeout_days>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>LOGGING_OBJECT_TYPE</id><enabled>Y</enabled><name>LOGGING_OBJECT_TYPE</name></field><field><id>OBJECT_NAME</id><enabled>Y</enabled><name>OBJECT_NAME</name></field><field><id>OBJECT_COPY</id><enabled>Y</enabled><name>OBJECT_COPY</name></field><field><id>REPOSITORY_DIRECTORY</id><enabled>Y</enabled><name>REPOSITORY_DIRECTORY</name></field><field><id>FILENAME</id><enabled>Y</enabled><name>FILENAME</name></field><field><id>OBJECT_ID</id><enabled>Y</enabled><name>OBJECT_ID</name></field><field><id>OBJECT_REVISION</id><enabled>Y</enabled><name>OBJECT_REVISION</name></field><field><id>PARENT_CHANNEL_ID</id><enabled>Y</enabled><name>PARENT_CHANNEL_ID</name></field><field><id>ROOT_CHANNEL_ID</id><enabled>Y</enabled><name>ROOT_CHANNEL_ID</name></field></channel-log-table>
<step-log-table><connection>logging_db</connection>
<schema>&#x24;&#x7b;QF_LOG_TRANSSTEP_SCHEMA&#x7d;</schema>
<table>&#x24;&#x7b;QF_LOG_TRANSSTEP_TABLE&#x7d;</table>
<timeout_days>&#x24;&#x7b;QF_LOG_TRANSSTEP_TIMEOUT_IN_DAYS&#x7d;</timeout_days>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>LOG_FIELD</id><enabled>N</enabled><name>LOG_FIELD</name></field></step-log-table>
<metrics-log-table><connection>logging_db</connection>
<schema>&#x24;&#x7b;QF_LOG_TRANSMETRICS_SCHEMA&#x7d;</schema>
<table>&#x24;&#x7b;QF_LOG_TRANSMETRICS_TABLE&#x7d;</table>
<timeout_days>&#x24;&#x7b;QF_LOG_TRANSMETRICS_TIMEOUT_IN_DAYS&#x7d;</timeout_days>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>METRICS_DATE</id><enabled>Y</enabled><name>METRICS_DATE</name></field><field><id>METRICS_CODE</id><enabled>Y</enabled><name>METRICS_CODE</name></field><field><id>METRICS_DESCRIPTION</id><enabled>Y</enabled><name>METRICS_DESCRIPTION</name></field><field><id>METRICS_SUBJECT</id><enabled>Y</enabled><name>METRICS_SUBJECT</name></field><field><id>METRICS_TYPE</id><enabled>Y</enabled><name>METRICS_TYPE</name></field><field><id>METRICS_VALUE</id><enabled>Y</enabled><name>METRICS_VALUE</name></field></metrics-log-table>
    </log>
    <maxdate>
      <connection/>
      <table/>
      <field/>
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file/>
    <capture_step_performance>Y</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
  <created_user>-</created_user>
  <created_date>2016&#x2f;04&#x2f;03 09&#x3a;57&#x3a;16.279</created_date>
  <modified_user>-</modified_user>
  <modified_date>2016&#x2f;08&#x2f;19 09&#x3a;01&#x3a;03.955</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA&#x3d;</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
    <notepad>
      <note>Load the data from the source database table that will be moved to the DWH table.&#xa;&#xa;It is important here to select &#x22;replace variables in script&#x3f;&#x22;so that the references &#x22;&#x3f;&#x22;, &#x24;&#x7b;PARAM_CDC_LAST_LOAD&#x7d; and &#xa;&#x24;&#x7b;PARAM_CDC_CURRENT_LOAD&#x7d; will be evaluated.&#xa;&#xa;It is also necessary to specify the step from which fields will  be used to supply values for the &#x22;&#x3f;&#x22; replacement characters. &#xa;In this case, the previous step is specified.</note>
      <xloc>320</xloc>
      <yloc>528</yloc>
      <width>733</width>
      <heigth>122</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Insert the new rows into the DWH using a &#x22;Table output&#x22; step.</note>
      <xloc>320</xloc>
      <yloc>752</yloc>
      <width>383</width>
      <heigth>26</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Write parameters and max_id value to the log so it will be obvious which values &#xa;were used.</note>
      <xloc>320</xloc>
      <yloc>464</yloc>
      <width>487</width>
      <heigth>42</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Get batch ID for current transformation. This will be stored in the DWH table.</note>
      <xloc>320</xloc>
      <yloc>672</yloc>
      <width>470</width>
      <heigth>26</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Get the maximum value stored in column &#x22;archive_id&#x22; of the DWH table that will be updated by this transformation. This will be used &#xa;to the select data from the source table in the TDP archive database that was inserted since the last update. &#xa;&#xa;IMPORTANT&#x3a;	We &#x2a;cannot&#x2a; use MAX&#x28;archive_date&#x29; for this purpose because the &#x22;archive_date&#x22; column will not, in general, be unique.</note>
      <xloc>320</xloc>
      <yloc>160</yloc>
      <width>820</width>
      <heigth>74</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This transformation updates the DWH mirror of an &#x22;insert-only&#x22; table from the TDP archive database. This is a generic algorithm that &#xa;can work with &#x2a;any&#x2a; table, as long as it is insert-only and it has the necessary &#x22;archive_id&#x22; &#x26; &#x22;archive_date&#x22; columns.&#xa;This transformation has parameters&#x3a;&#xa;&#xa;	PARAM_CDC_LAST_LOAD		&#x3c;- not used in this transformation - MAX&#x28;archive_id&#x29; is used instead&#xa;	PARAM_CDC_CURRENT_LOAD&#xa;	PARAM_SOURCE_SCHEMA					Schema of mirrored table&#xa;	PARAM_SOURCE_TABLE					Name of mirrored table to update</note>
      <xloc>16</xloc>
      <yloc>0</yloc>
      <width>894</width>
      <heigth>146</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This step is only for generating the SQL for creating a new table using the &#x22;SQL&#x22; button of the &#x22;Table output&#x22; step below. To do this&#x3a;&#xa;	1.	Disable the hop from the &#x22;Get max ID for ...&#x22; step and enable the hop from the &#x22;Set max ID &#x3d; -1&#x22; step.&#xa;	2.	Disable the hop to the &#x22;Table output&#x22; step below.&#xa;	3.	Preview the &#x22;Get System Info&#x22; step, specifying the required schema and table names for the appropriate parameters and the &#xa;		value &#x27;2100.01.01 00&#x3a;00&#x3a;00&#x27; for the parameter PARAM_CDC_CURRENT_LOAD. Ensure that the expected rows are displayed.&#xa;	4.	Re-enable the hop to the &#x22;Table output&#x22; step below.&#xa;	5.	Double-click the &#x22;Table output&#x22; step and then click the &#x22;SQL&#x22; button to generate the appropriete SQL to create the table. &#xa;		The schema and table names that you specified in step 3 above will be used to generate the SQL DDL commands for that table.&#xa;		Before executing the SQL, modify it where appropriate. For example, replace &#x22;UNKNOWN&#x22; for timestamp columns with &#xa;		&#x22;timestamp without time zone&#x22;, ...&#xa;	6.	Re-enable the hop from the &#x22;Get max ID for ...&#x22; step and disable the hop from the &#x22;Set max ID &#x3d; -1&#x22; step.	</note>
      <xloc>320</xloc>
      <yloc>256</yloc>
      <width>817</width>
      <heigth>186</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <connection>
    <name>dma_db</name>
    <server>&#x24;&#x7b;QF_DMA_DB_HOST&#x7d;</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>&#x24;&#x7b;QF_DMA_DB_DATABASE&#x7d;</database>
    <port>&#x24;&#x7b;QF_DMA_DB_PORT&#x7d;</port>
    <username>&#x24;&#x7b;QF_DMA_DB_USERNAME&#x7d;</username>
    <password>&#x24;&#x7b;QF_DMA_DB_PASSWORD&#x7d;</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute><code>FORCE_IDENTIFIERS_TO_LOWERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_UPPERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>IS_CLUSTERED</code><attribute>N</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>&#x24;&#x7b;QF_DMA_DB_PORT&#x7d;</attribute></attribute>
      <attribute><code>PRESERVE_RESERVED_WORD_CASE</code><attribute>N</attribute></attribute>
      <attribute><code>QUOTE_ALL_FIELDS</code><attribute>N</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_TIMESTAMP_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>USE_POOLING</code><attribute>N</attribute></attribute>
    </attributes>
  </connection>
  <connection>
    <name>logging_db</name>
    <server>&#x24;&#x7b;QF_LOGGING_DB_HOST&#x7d;</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>&#x24;&#x7b;QF_LOGGING_DB_DATABASE&#x7d;</database>
    <port>&#x24;&#x7b;QF_LOGGING_DB_PORT&#x7d;</port>
    <username>&#x24;&#x7b;QF_LOGGING_DB_USERNAME&#x7d;</username>
    <password>&#x24;&#x7b;QF_LOGGING_DB_PASSWORD&#x7d;</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute><code>FORCE_IDENTIFIERS_TO_LOWERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_UPPERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>IS_CLUSTERED</code><attribute>N</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>&#x24;&#x7b;QF_LOGGING_DB_PORT&#x7d;</attribute></attribute>
      <attribute><code>PRESERVE_RESERVED_WORD_CASE</code><attribute>N</attribute></attribute>
      <attribute><code>QUOTE_ALL_FIELDS</code><attribute>N</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_TIMESTAMP_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>USE_POOLING</code><attribute>N</attribute></attribute>
    </attributes>
  </connection>
  <connection>
    <name>dwh_db</name>
    <server>&#x24;&#x7b;QF_DWH_DB_HOST&#x7d;</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>&#x24;&#x7b;QF_DWH_DB_DATABASE&#x7d;</database>
    <port>&#x24;&#x7b;QF_DWH_DB_PORT&#x7d;</port>
    <username>&#x24;&#x7b;QF_DWH_DB_USERNAME&#x7d;</username>
    <password>&#x24;&#x7b;QF_DWH_DB_PASSWORD&#x7d;</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute><code>FORCE_IDENTIFIERS_TO_LOWERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_UPPERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>IS_CLUSTERED</code><attribute>N</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>&#x24;&#x7b;QF_DWH_DB_PORT&#x7d;</attribute></attribute>
      <attribute><code>PRESERVE_RESERVED_WORD_CASE</code><attribute>N</attribute></attribute>
      <attribute><code>QUOTE_ALL_FIELDS</code><attribute>N</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_TIMESTAMP_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>USE_POOLING</code><attribute>N</attribute></attribute>
    </attributes>
  </connection>
  <connection>
    <name>obo_db</name>
    <server>&#x24;&#x7b;QF_OBO_DB_HOST&#x7d;</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>&#x24;&#x7b;QF_OBO_DB_DATABASE&#x7d;</database>
    <port>&#x24;&#x7b;QF_OBO_DB_PORT&#x7d;</port>
    <username>&#x24;&#x7b;QF_OBO_DB_USERNAME&#x7d;</username>
    <password>&#x24;&#x7b;QF_OBO_DB_PASSWORD&#x7d;</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute><code>FORCE_IDENTIFIERS_TO_LOWERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_UPPERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>IS_CLUSTERED</code><attribute>N</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>&#x24;&#x7b;QF_OBO_DB_PORT&#x7d;</attribute></attribute>
      <attribute><code>PRESERVE_RESERVED_WORD_CASE</code><attribute>N</attribute></attribute>
      <attribute><code>QUOTE_ALL_FIELDS</code><attribute>N</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_TIMESTAMP_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>USE_POOLING</code><attribute>N</attribute></attribute>
    </attributes>
  </connection>
  <order>
  <hop> <from>Get max ID for CDC&#x3a; DWH.schema.table</from><to>Write to log&#x3a; parameters, max_id</to><enabled>Y</enabled> </hop>
  <hop> <from>Table input -  TDP.schema.table</from><to>Get System Info - transformation batch ID</to><enabled>Y</enabled> </hop>
  <hop> <from>Get System Info - transformation batch ID</from><to>Table output - DWH.schema.table</to><enabled>Y</enabled> </hop>
  <hop> <from>Write to log&#x3a; parameters, max_id</from><to>Table input -  TDP.schema.table</to><enabled>Y</enabled> </hop>
  <hop> <from>Set max ID &#x3d; -1</from><to>Write to log&#x3a; parameters, max_id</to><enabled>N</enabled> </hop>
  </order>
  <step>
    <name>Get System Info - transformation batch ID</name>
    <type>SystemInfo</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <fields>
      <field>
        <name>etl_batch_id_insert</name>
        <type>batch ID</type>
        </field>
      </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>144</xloc>
      <yloc>672</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Get max ID for CDC&#x3a; DWH.schema.table</name>
    <type>TableInput</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <connection>dwh_db</connection>
    <sql>SELECT&#xa;    COALESCE&#x28;MAX&#x28;archive_id&#x29;, &#x24;&#x7b;QF_ARCHIVE_ID_LOWER_BOUND&#x7d;&#x29; AS max_id&#xa;FROM&#xa;    &#x24;&#x7b;PARAM_SOURCE_SCHEMA&#x7d;.&#x24;&#x7b;PARAM_SOURCE_TABLE&#x7d;&#xa;</sql>
    <limit>0</limit>
    <lookup/>
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>144</xloc>
      <yloc>192</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Set max ID &#x3d; -1</name>
    <type>TableInput</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <connection>dma_db</connection>
    <sql>SELECT&#xa;    &#x24;&#x7b;QF_ARCHIVE_ID_LOWER_BOUND&#x7d; AS max_id&#xa;</sql>
    <limit>0</limit>
    <lookup/>
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>256</xloc>
      <yloc>288</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Table input -  TDP.schema.table</name>
    <type>TableInput</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <connection>obo_db</connection>
    <sql>SELECT&#xa;    &#x2a;&#xa;FROM&#xa;    &#x24;&#x7b;PARAM_SOURCE_SCHEMA&#x7d;.&#x24;&#x7b;PARAM_SOURCE_TABLE&#x7d;&#xa;WHERE&#xa;    archive_id &#x3e; &#x3f; AND&#xa;    --archive_date &#x3e;  &#x27;&#x24;&#x7b;PARAM_CDC_LAST_LOAD&#x7d;&#x27; AND &#xa;	archive_date &#x3c;&#x3d; &#x27;&#x24;&#x7b;PARAM_CDC_CURRENT_LOAD&#x7d;&#x27;&#xa;ORDER BY&#xa;    archive_id</sql>
    <limit>0</limit>
    <lookup>Write to log&#x3a; parameters, max_id</lookup>
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>144</xloc>
      <yloc>576</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Table output - DWH.schema.table</name>
    <type>TableOutput</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <connection>dwh_db</connection>
    <schema>&#x24;&#x7b;PARAM_SOURCE_SCHEMA&#x7d;</schema>
    <table>&#x24;&#x7b;PARAM_SOURCE_TABLE&#x7d;</table>
    <commit>1000</commit>
    <truncate>N</truncate>
    <ignore_errors>N</ignore_errors>
    <use_batch>Y</use_batch>
    <specify_fields>N</specify_fields>
    <partitioning_enabled>N</partitioning_enabled>
    <partitioning_field/>
    <partitioning_daily>N</partitioning_daily>
    <partitioning_monthly>Y</partitioning_monthly>
    <tablename_in_field>N</tablename_in_field>
    <tablename_field/>
    <tablename_in_table>Y</tablename_in_table>
    <return_keys>N</return_keys>
    <return_field/>
    <fields>
    </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>144</xloc>
      <yloc>752</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Write to log&#x3a; parameters, max_id</name>
    <type>WriteToLog</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
      <loglevel>log_level_basic</loglevel>
      <displayHeader>Y</displayHeader>
      <limitRows>N</limitRows>
      <limitRowsNumber>0</limitRowsNumber>
      <logmessage>PARAM_CDC_LAST_LOAD    &#x3d; &#x24;&#x7b;PARAM_CDC_LAST_LOAD&#x7d;&#xa;PARAM_CDC_CURRENT_LOAD &#x3d; &#x24;&#x7b;PARAM_CDC_CURRENT_LOAD&#x7d;&#xa;PARAM_SOURCE_SCHEMA           &#x3d; &#x24;&#x7b;PARAM_SOURCE_SCHEMA&#x7d;&#xa;PARAM_SOURCE_TABLE            &#x3d; &#x24;&#x7b;PARAM_SOURCE_TABLE&#x7d;</logmessage>
    <fields>
      <field>
        <name>max_id</name>
        </field>
      </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>144</xloc>
      <yloc>464</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step_error_handling>
  </step_error_handling>
   <slave-step-copy-partition-distribution>
</slave-step-copy-partition-distribution>
   <slave_transformation>N</slave_transformation>

</transformation>
