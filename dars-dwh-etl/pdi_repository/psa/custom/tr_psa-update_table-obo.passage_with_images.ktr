<transformation>
  <info>
    <name>tr_psa-update_table-obo.passage_with_images</name>
    <description />
    <extended_description />
    <trans_version />
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>/psa/custom</directory>
    <parameters>
      <parameter>
        <name>PARAM_CDC_CURRENT_LOAD_UTC</name>
        <default_value>2100.01.01 00:00:00</default_value>
        <description>Timestamp of the current load (no rows after this timestamp will be loaded)</description>
      </parameter>
      <parameter>
        <name>PARAM_CDC_LAST_LOAD_UTC</name>
        <default_value>1900.01.01 00:00:00</default_value>
        <description>Timestamp of last successful load from the source database</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_SCHEMA</name>
        <default_value>passage</default_value>
        <description>Name of schema containing the "main" source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_TABLE</name>
        <default_value>passage</default_value>
        <description>Name of the "main" source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_TABLE_MAX_INSERT_ID</name>
        <default_value>10</default_value>
        <description>Maximum value of the "insert_id" column for rows to load from the source DB table</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_SCHEMA</name>
        <default_value>obo</default_value>
        <description>Name of schema containing target table to update</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_TABLE</name>
        <default_value>passage_with_images</default_value>
        <description>Name of target table to update</description>
      </parameter>
    </parameters>
    <log>
      <trans-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANS_SCHEMA}</schema>
        <table>${QF_LOG_TRANS_TABLE}</table>
        <size_limit_lines />
        <interval />
        <timeout_days>${QF_LOG_TRANS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STATUS</id>
          <enabled>Y</enabled>
          <name>STATUS</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
          <subject>Table output - PSA.schema.table</subject>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
          <subject>Table output - PSA.schema.table</subject>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
          <subject>Table output - PSA.schema.table</subject>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
          <subject>Table input - Source DB: obo_opr</subject>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
          <subject>Table output - PSA.schema.table</subject>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
          <subject>Table output - PSA.schema.table</subject>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>STARTDATE</id>
          <enabled>Y</enabled>
          <name>STARTDATE</name>
        </field>
        <field>
          <id>ENDDATE</id>
          <enabled>Y</enabled>
          <name>ENDDATE</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>DEPDATE</id>
          <enabled>Y</enabled>
          <name>DEPDATE</name>
        </field>
        <field>
          <id>REPLAYDATE</id>
          <enabled>Y</enabled>
          <name>REPLAYDATE</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>Y</enabled>
          <name>LOG_FIELD</name>
        </field>
        <field>
          <id>EXECUTING_SERVER</id>
          <enabled>N</enabled>
          <name>EXECUTING_SERVER</name>
        </field>
        <field>
          <id>EXECUTING_USER</id>
          <enabled>N</enabled>
          <name>EXECUTING_USER</name>
        </field>
        <field>
          <id>CLIENT</id>
          <enabled>N</enabled>
          <name>CLIENT</name>
        </field>
      </trans-log-table>
      <perf-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSPERF_SCHEMA}</schema>
        <table>${QF_LOG_TRANSPERF_TABLE}</table>
        <interval />
        <timeout_days>${QF_LOG_TRANSPERF_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>SEQ_NR</id>
          <enabled>Y</enabled>
          <name>SEQ_NR</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>INPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>INPUT_BUFFER_ROWS</name>
        </field>
        <field>
          <id>OUTPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>OUTPUT_BUFFER_ROWS</name>
        </field>
      </perf-log-table>
      <channel-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_CHANNEL_SCHEMA}</schema>
        <table>${QF_LOG_CHANNEL_TABLE}</table>
        <timeout_days>${QF_LOG_CHANNEL_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>LOGGING_OBJECT_TYPE</id>
          <enabled>Y</enabled>
          <name>LOGGING_OBJECT_TYPE</name>
        </field>
        <field>
          <id>OBJECT_NAME</id>
          <enabled>Y</enabled>
          <name>OBJECT_NAME</name>
        </field>
        <field>
          <id>OBJECT_COPY</id>
          <enabled>Y</enabled>
          <name>OBJECT_COPY</name>
        </field>
        <field>
          <id>REPOSITORY_DIRECTORY</id>
          <enabled>Y</enabled>
          <name>REPOSITORY_DIRECTORY</name>
        </field>
        <field>
          <id>FILENAME</id>
          <enabled>Y</enabled>
          <name>FILENAME</name>
        </field>
        <field>
          <id>OBJECT_ID</id>
          <enabled>Y</enabled>
          <name>OBJECT_ID</name>
        </field>
        <field>
          <id>OBJECT_REVISION</id>
          <enabled>Y</enabled>
          <name>OBJECT_REVISION</name>
        </field>
        <field>
          <id>PARENT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>PARENT_CHANNEL_ID</name>
        </field>
        <field>
          <id>ROOT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>ROOT_CHANNEL_ID</name>
        </field>
      </channel-log-table>
      <step-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSSTEP_SCHEMA}</schema>
        <table>${QF_LOG_TRANSSTEP_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSSTEP_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>N</enabled>
          <name>LOG_FIELD</name>
        </field>
      </step-log-table>
      <metrics-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSMETRICS_SCHEMA}</schema>
        <table>${QF_LOG_TRANSMETRICS_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSMETRICS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>METRICS_DATE</id>
          <enabled>Y</enabled>
          <name>METRICS_DATE</name>
        </field>
        <field>
          <id>METRICS_CODE</id>
          <enabled>Y</enabled>
          <name>METRICS_CODE</name>
        </field>
        <field>
          <id>METRICS_DESCRIPTION</id>
          <enabled>Y</enabled>
          <name>METRICS_DESCRIPTION</name>
        </field>
        <field>
          <id>METRICS_SUBJECT</id>
          <enabled>Y</enabled>
          <name>METRICS_SUBJECT</name>
        </field>
        <field>
          <id>METRICS_TYPE</id>
          <enabled>Y</enabled>
          <name>METRICS_TYPE</name>
        </field>
        <field>
          <id>METRICS_VALUE</id>
          <enabled>Y</enabled>
          <name>METRICS_VALUE</name>
        </field>
      </metrics-log-table>
    </log>
    <maxdate>
      <connection />
      <table />
      <field />
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file />
    <capture_step_performance>Y</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
    <created_user>-</created_user>
    <created_date>2016/04/03 09:57:16.279</created_date>
    <modified_user>-</modified_user>
    <modified_date>2018/04/19 15:10:51.941</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA=</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
    <notepad>
      <note>Load the data from the source tables that will be moved to the target PSA table.

It is important to sort these rows chronologically (by either the "insert_id" or "inserted_on" columns) so that if this transformation
fails in the middle somewhere and if this transaction does not run in a single transaction, then next time this transformation is 
executed, we can start again where we left off (by computing, e.g., by making use of MAX(insert_id) for the PSA table).</note>
      <xloc>304</xloc>
      <yloc>512</yloc>
      <width>723</width>
      <heigth>75</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Insert new rows into the DWH using a "Table output" step. Error handing is enabled for this step so that if a rows already exists,
the rows are passed to an "Update" step.

IMPORTANT:	A primary key constraint (or at least a "unique" constraint on the primary key column(s)) for the target table is 
				*required*; otherwise, error handling will not be triggered when attempting to insert a row with a duplicate key.

PDI does not fully support error handling when using "batch processing" with the PostgreSQL JDBC driver (a message to this 
effect is displayed when accepting the transformation settings dialog), so make sure "Use batch update for inserts" is *not* 
selected here!

See:

	/development/jeffreyz/tests/cdc_timestamps/tr_TEST_mirror_update-passage.passage-table_output

for tests  benchmark results I obtained testing the speed of various INSERT/UPDATE algorithms. Using a "Table output" step with 
an error handling hop to an "Update" step provides an approximately 2x speedup over an "Insert/Update" step for inserts *and* 
it does not exhibit (for inserts only) the behaviour where a "java"and "postgres" process continue to run with a high CPU load long 
after the transformation is finished. Hence, it should be favoured.

An odd behaviour is observed when the error handling sends rows to the "Update" step. After processing a large number of rows, 
it takes a long time for this transformation to end. During this period the "Pause" and "Stop" buttons remain enabled. Furthermore,
running" top" shows that both "postgres"and "java" processes are actively using a 25-75% of the CPU. When this CPU usage stops, 
the  "Pause" and "Stop" buttons become disabled, showing that the transformation is finally finished. Strange.</note>
      <xloc>304</xloc>
      <yloc>784</yloc>
      <width>730</width>
      <heigth>309</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Get batch ID for current transformation. This will be stored in the PSA table for auditing/logging.</note>
      <xloc>304</xloc>
      <yloc>736</yloc>
      <width>542</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This transformation implements a custom algorithm to update the PSA table:

	obo.passage_with_images .

This is only a TEST implementation for try out ideas for creating a custom archive/mirror algorithm. It makes the follwoing assumptions:

	"insert_id" column:				passage.passage_id
	"last_updated_on" column:		passage.last_updated_on	This column did not exist. I had to create it for this test with:
									ALTER TABLE passage.passage ADD COLUMN last_updated_on timestamp;

This transformation has parameters:

	PARAM_CDC_LAST_LOAD_UTC			Timestamp for when *all* tables of the PSA were most recently updated successfully
	PARAM_CDC_CURRENT_LOAD_UTC		Used so that a consistent max timestamp is used for all ETL
	PARAM_SOURCE_TABLE_MAX_INSERT_ID	Maximum value of the "insert_id" column for rows to load from the source DB table
	PARAM_SOURCE_SCHEMA				Name of schema containing the "main" source table to archive/mirror to target table
	PARAM_SOURCE_TABLE					Name of the "main" source table to archive/mirror to target table
	PARAM_TARGET_SCHEMA				Name of schema containing target table to update
	PARAM_TARGET_TABLE					Name of target table to update</note>
      <xloc>0</xloc>
      <yloc>0</yloc>
      <width>750</width>
      <heigth>257</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Get the maximum values stored in the "insert_id" &amp; "last_upated_on" columns of the target obo.passage_with_images table that will
be updated by this transformation. This will be used to the select data from the source passage.passage table that was inserted or
modified since the last update to the PSA DB.</note>
      <xloc>304</xloc>
      <yloc>272</yloc>
      <width>732</width>
      <heigth>49</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Select, delete and map/rename fields (table column names), as appropriate.</note>
      <xloc>304</xloc>
      <yloc>608</yloc>
      <width>423</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This step is only for generating the SQL for creating a new table using the "SQL" button of the "Table output" step below. To do this:
	1.	Disable the hop from the "Get max "insert_id" &amp; ..." step and enable the hop from the "Set max ID &amp; ..." step.
	2.	Disable the hop to the "Table output" step below, as well as all following downstream hops.
	3.	Preview the "Set etl_batch_id_last_update..." step, providing appropriate values for all parameters. Ensure that the expected  
		rows are displayed.
	4.	Re-enable the hop to the "Table output" step below.
	5.	Double-click the "Table output" step and then click the "SQL" button to generate the appropriete SQL to create the table. 
		The schema and table names that you specified in step 3 above will be used to generate the SQL DDL commands for that table.
		Before executing the SQL, modify it where appropriate. For example, replace "UNKNOWN" for timestamp columns with 
		"timestamp without time zone" or "bytea", add declaration for column "etl_batch_id_last_update", primary key constraint, ...
	6.	Re-enable the hop from the "Get max "insert_id" step and disable the hop from the "Set max ID &amp; ..." step.</note>
      <xloc>304</xloc>
      <yloc>336</yloc>
      <width>753</width>
      <heigth>153</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>A primary key 
constraint or a
unique constraint
on primary key
column(s) is 



*required* in 
order for error 
handling to be 
triggered here!</note>
      <xloc>16</xloc>
      <yloc>784</yloc>
      <width>105</width>
      <heigth>166</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>Y</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>255</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Denormalize the stream data by introducing new passage columns to hold details for up to 4 images linked to each passage.</note>
      <xloc>304</xloc>
      <yloc>672</yloc>
      <width>686</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <connection>
    <name>etl_db</name>
    <server>${QF_ETL_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_ETL_DB_DATABASE}</database>
    <port>${QF_ETL_DB_PORT}</port>
    <username>${QF_ETL_DB_USERNAME}</username>
    <password>${QF_ETL_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_ETL_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>logging_db</name>
    <server>${QF_LOGGING_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_LOGGING_DB_DATABASE}</database>
    <port>${QF_LOGGING_DB_PORT}</port>
    <username>${QF_LOGGING_DB_USERNAME}</username>
    <password>${QF_LOGGING_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_LOGGING_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>obo_opr_db</name>
    <server>${QF_OBO_OPR_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_OBO_OPR_DB_DATABASE}</database>
    <port>${QF_OBO_OPR_DB_PORT}</port>
    <username>${QF_OBO_OPR_DB_USERNAME}</username>
    <password>${QF_OBO_OPR_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_OBO_OPR_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>psa_db</name>
    <server>${QF_PSA_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_PSA_DB_DATABASE}</database>
    <port>${QF_PSA_DB_PORT}</port>
    <username>${QF_PSA_DB_USERNAME}</username>
    <password>${QF_PSA_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_PSA_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <order>
    <hop>
      <from>Get max id &amp; date for: PSA.obo.passage_with_images</from>
      <to>Write to log: parameters, max id &amp; date</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Write to log: parameters, max id &amp; date</from>
      <to>Table input - Source DB: obo_opr</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Table output - PSA.schema.table</from>
      <to>Set etl_batch_id_last_update = Xform batch ID</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Set etl_batch_id_last_update = Xform batch ID</from>
      <to>Update - PSA.schema.table</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Set etl_batch_id_insert = Xform batch ID</from>
      <to>Table output - PSA.schema.table</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Table input - Source DB: obo_opr</from>
      <to>Map column names</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Set max id &amp; date</from>
      <to>Write to log: parameters, max id &amp; date</to>
      <enabled>N</enabled>
    </hop>
    <hop>
      <from>Map column names</from>
      <to>Row denormaliser</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Row denormaliser</from>
      <to>Set etl_batch_id_insert = Xform batch ID</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Compute number of rows processed</from>
      <to>Set QF_UPDATE_TABLE_NUM_ROWS</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Compute number of rows updated</from>
      <to>Set QF_UPDATE_TABLE_NUM_UPDATES</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Update - PSA.schema.table</from>
      <to>Compute number of rows updated</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Table input - Source DB: obo_opr</from>
      <to>Compute number of rows processed</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Set QF_UPDATE_TABLE_NUM_UPDATES</from>
      <to>Get transformation name</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Get transformation name</from>
      <to>Log number of rows updated</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Set QF_UPDATE_TABLE_NUM_ROWS</from>
      <to>Get transformation name 2</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Get transformation name 2</from>
      <to>Log number of rows processed</to>
      <enabled>Y</enabled>
    </hop>
  </order>
  <step>
    <name>Compute number of rows processed</name>
    <type>MemoryGroupBy</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <give_back_row>Y</give_back_row>
    <group>
      </group>
    <fields>
      <field>
        <aggregate>num_rows</aggregate>
        <subject />
        <type>COUNT_ANY</type>
        <valuefield />
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>384</xloc>
      <yloc>1120</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Compute number of rows updated</name>
    <type>MemoryGroupBy</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <give_back_row>Y</give_back_row>
    <group>
      </group>
    <fields>
      <field>
        <aggregate>num_rows_updated</aggregate>
        <subject />
        <type>COUNT_ANY</type>
        <valuefield />
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>1120</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Get max id &amp; date for: PSA.obo.passage_with_images</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>psa_db</connection>
    <sql>SELECT
    COALESCE(MAX(passage_with_images_id), ${QF_INSERT_ID_LOWER_BOUND}) AS max_target_insert_id, 
    COALESCE(MAX(last_updated_on) , '${QF_LAST_UPDATED_ON_LOWER_BOUND}')     AS max_target_last_updated_on, 
    -- Get the largest value in any of the columns: image_1_id, image_2_id, image_3_id, image_4_id:
    GREATEST(
        COALESCE(MAX(image_1_id) , ${QF_INSERT_ID_LOWER_BOUND}),
        COALESCE(MAX(image_2_id) , ${QF_INSERT_ID_LOWER_BOUND}),
        COALESCE(MAX(image_3_id) , ${QF_INSERT_ID_LOWER_BOUND}),
        COALESCE(MAX(image_4_id) , ${QF_INSERT_ID_LOWER_BOUND})
    ) AS max_target_image_id, 
    -- Get the largest value in any of the columns: image_1_date, image_2_date, image_3_date, image_4_date:
    GREATEST(
        COALESCE(MAX(image_1_date) , '${QF_LAST_UPDATED_ON_LOWER_BOUND}'),
        COALESCE(MAX(image_2_date) , '${QF_LAST_UPDATED_ON_LOWER_BOUND}'),
        COALESCE(MAX(image_3_date) , '${QF_LAST_UPDATED_ON_LOWER_BOUND}'),
        COALESCE(MAX(image_4_date) , '${QF_LAST_UPDATED_ON_LOWER_BOUND}')
    ) AS max_target_image_date 
FROM
    ${PARAM_TARGET_SCHEMA}.${PARAM_TARGET_TABLE}  -- obo.passage_with_images</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>288</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Get transformation name</name>
    <type>SystemInfo</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>current_transformation</name>
        <type>transformation name</type>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>1248</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Get transformation name 2</name>
    <type>SystemInfo</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>current_transformation</name>
        <type>transformation name</type>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>384</xloc>
      <yloc>1248</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Log number of rows processed</name>
    <type>WriteToLog</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <loglevel>log_level_minimal</loglevel>
    <displayHeader>Y</displayHeader>
    <limitRows>N</limitRows>
    <limitRowsNumber>0</limitRowsNumber>
    <logmessage>PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE   = ${PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE}
PARAM_DYN_DB_CONN_TARGET_DB_DATABASE   = ${PARAM_DYN_DB_CONN_TARGET_DB_DATABASE}
PARAM_SOURCE_SCHEMA                    = ${PARAM_SOURCE_SCHEMA}
PARAM_SOURCE_TABLE                     = ${PARAM_SOURCE_TABLE}
PARAM_TARGET_SCHEMA                    = ${PARAM_TARGET_SCHEMA}
PARAM_TARGET_TABLE                     = ${PARAM_TARGET_TABLE}</logmessage>
    <fields>
      <field>
        <name>current_transformation</name>
      </field>
      <field>
        <name>num_rows</name>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>384</xloc>
      <yloc>1312</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Log number of rows updated</name>
    <type>WriteToLog</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <loglevel>log_level_minimal</loglevel>
    <displayHeader>Y</displayHeader>
    <limitRows>N</limitRows>
    <limitRowsNumber>0</limitRowsNumber>
    <logmessage>PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE   = ${PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE}
PARAM_DYN_DB_CONN_TARGET_DB_DATABASE   = ${PARAM_DYN_DB_CONN_TARGET_DB_DATABASE}
PARAM_SOURCE_SCHEMA                    = ${PARAM_SOURCE_SCHEMA}
PARAM_SOURCE_TABLE                     = ${PARAM_SOURCE_TABLE}
PARAM_TARGET_SCHEMA                    = ${PARAM_TARGET_SCHEMA}
PARAM_TARGET_TABLE                     = ${PARAM_TARGET_TABLE}</logmessage>
    <fields>
      <field>
        <name>current_transformation</name>
      </field>
      <field>
        <name>num_rows_updated</name>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>1312</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Map column names</name>
    <type>SelectValues</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <select_unspecified>N</select_unspecified>
      <meta>
        <name>passage_id</name>
        <rename>passage_with_images_id</rename>
        <type>None</type>
        <length>-2</length>
        <precision>-2</precision>
        <conversion_mask />
        <date_format_lenient>false</date_format_lenient>
        <date_format_locale />
        <date_format_timezone />
        <lenient_string_to_number>false</lenient_string_to_number>
        <encoding />
        <decimal_symbol />
        <grouping_symbol />
        <currency_symbol />
        <storage_type />
      </meta>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>608</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Row denormaliser</name>
    <type>Denormaliser</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <key_field>image_index_for_passage</key_field>
    <group>
      <field>
        <name>passage_with_images_id</name>
      </field>
    </group>
    <fields>
      <field>
        <field_name>image_id</field_name>
        <key_value>1</key_value>
        <target_name>image_1_id</target_name>
        <target_type>Integer</target_type>
        <target_format />
        <target_length>15</target_length>
        <target_precision>0</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
      <field>
        <field_name>image_date</field_name>
        <key_value>1</key_value>
        <target_name>image_1_date</target_name>
        <target_type>Timestamp</target_type>
        <target_format />
        <target_length>6</target_length>
        <target_precision>-1</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
      <field>
        <field_name>camera_id</field_name>
        <key_value>1</key_value>
        <target_name>image_1_camera_id</target_name>
        <target_type>Integer</target_type>
        <target_format />
        <target_length>4</target_length>
        <target_precision>0</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
      <field>
        <field_name>file_id</field_name>
        <key_value>1</key_value>
        <target_name>image_1_file_id</target_name>
        <target_type>Integer</target_type>
        <target_format />
        <target_length>15</target_length>
        <target_precision>0</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
      <field>
        <field_name>image_id</field_name>
        <key_value>2</key_value>
        <target_name>image_2_id</target_name>
        <target_type>Integer</target_type>
        <target_format />
        <target_length>15</target_length>
        <target_precision>0</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
      <field>
        <field_name>image_date</field_name>
        <key_value>2</key_value>
        <target_name>image_2_date</target_name>
        <target_type>Timestamp</target_type>
        <target_format />
        <target_length>6</target_length>
        <target_precision>-1</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
      <field>
        <field_name>camera_id</field_name>
        <key_value>2</key_value>
        <target_name>image_2_camera_id</target_name>
        <target_type>Integer</target_type>
        <target_format />
        <target_length>4</target_length>
        <target_precision>0</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
      <field>
        <field_name>file_id</field_name>
        <key_value>2</key_value>
        <target_name>image_2_file_id</target_name>
        <target_type>Integer</target_type>
        <target_format />
        <target_length>15</target_length>
        <target_precision>0</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
      <field>
        <field_name>image_id</field_name>
        <key_value>3</key_value>
        <target_name>image_3_id</target_name>
        <target_type>Integer</target_type>
        <target_format />
        <target_length>15</target_length>
        <target_precision>0</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
      <field>
        <field_name>image_date</field_name>
        <key_value>3</key_value>
        <target_name>image_3_date</target_name>
        <target_type>Timestamp</target_type>
        <target_format />
        <target_length>6</target_length>
        <target_precision>-1</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
      <field>
        <field_name>camera_id</field_name>
        <key_value>3</key_value>
        <target_name>image_3_camera_id</target_name>
        <target_type>Integer</target_type>
        <target_format />
        <target_length>4</target_length>
        <target_precision>0</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
      <field>
        <field_name>file_id</field_name>
        <key_value>3</key_value>
        <target_name>image_3_file_id</target_name>
        <target_type>Integer</target_type>
        <target_format />
        <target_length>15</target_length>
        <target_precision>0</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
      <field>
        <field_name>image_id</field_name>
        <key_value>4</key_value>
        <target_name>image_4_id</target_name>
        <target_type>Integer</target_type>
        <target_format />
        <target_length>15</target_length>
        <target_precision>0</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
      <field>
        <field_name>image_date</field_name>
        <key_value>4</key_value>
        <target_name>image_4_date</target_name>
        <target_type>Timestamp</target_type>
        <target_format />
        <target_length>6</target_length>
        <target_precision>-1</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
      <field>
        <field_name>camera_id</field_name>
        <key_value>4</key_value>
        <target_name>image_4_camera_id</target_name>
        <target_type>Integer</target_type>
        <target_format />
        <target_length>4</target_length>
        <target_precision>0</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
      <field>
        <field_name>file_id</field_name>
        <key_value>4</key_value>
        <target_name>image_4_file_id</target_name>
        <target_type>Integer</target_type>
        <target_format />
        <target_length>15</target_length>
        <target_precision>0</target_precision>
        <target_decimal_symbol />
        <target_grouping_symbol />
        <target_currency_symbol />
        <target_null_string />
        <target_aggregation_type>-</target_aggregation_type>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>672</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Set QF_UPDATE_TABLE_NUM_ROWS</name>
    <type>SetVariable</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <field_name>num_rows</field_name>
        <variable_name>QF_UPDATE_TABLE_NUM_ROWS</variable_name>
        <variable_type>ROOT_JOB</variable_type>
        <default_value />
      </field>
    </fields>
    <use_formatting>Y</use_formatting>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>384</xloc>
      <yloc>1184</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Set QF_UPDATE_TABLE_NUM_UPDATES</name>
    <type>SetVariable</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <field_name>num_rows_updated</field_name>
        <variable_name>QF_UPDATE_TABLE_NUM_UPDATES</variable_name>
        <variable_type>ROOT_JOB</variable_type>
        <default_value />
      </field>
    </fields>
    <use_formatting>Y</use_formatting>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>1184</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Set etl_batch_id_insert = Xform batch ID</name>
    <type>SystemInfo</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>etl_batch_id_insert</name>
        <type>batch ID</type>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>736</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Set etl_batch_id_last_update = Xform batch ID</name>
    <type>SystemInfo</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>etl_batch_id_last_update</name>
        <type>batch ID</type>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>928</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Set max id &amp; date</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>etl_db</connection>
    <sql>SELECT
          ${QF_INSERT_ID_LOWER_BOUND}                      AS max_target_insert_id,
    CAST('${QF_LAST_UPDATED_ON_LOWER_BOUND}' AS timestamp) AS max_target_last_updated_on,
          ${QF_INSERT_ID_LOWER_BOUND}                      AS max_target_image_id, 
    CAST('${QF_LAST_UPDATED_ON_LOWER_BOUND}' AS timestamp) AS max_target_image_date 
</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>224</xloc>
      <yloc>384</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Table input - Source DB: obo_opr</name>
    <type>TableInput</type>
    <description />
    <distribute>N</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>obo_opr_db</connection>
    <sql>SELECT
    p.passage_id, 
    p.passage_date,
    --p.arrival_date,
    p.finished_date,
    p.row_can_be_deleted_from,
    p.last_updated_on,
    p.charging_point_id,
    i.image_id, 
    i.image_date, 
    i.camera_id,
    i.file_id, 
    -- This numbers the images for each passage: 1, 2, 3, ...
    -- It resets to 1 when the value of p.passage_id changes.
    row_number() OVER (PARTITION by p.passage_id ORDER BY i.image_id) as "image_index_for_passage" 
FROM 
    ${PARAM_SOURCE_SCHEMA}.${PARAM_SOURCE_TABLE} p  -- passage.passage
INNER JOIN 
    passage.image i ON i.passage_id = p.passage_id 
WHERE
    ( 
        p.passage_id > ?                                 -- Newly INSERTed passages, since the last run.
        OR p.last_updated_on > ?                               -- UPDATEd passages, since the last run.
        OR i.image_id > ?                                -- Passages that have new images linked to them. This will correctly
                                                         -- include such passages even if the "last_updated_on" column for
                                                         -- the passage table (in this case "last_updated_on") is *not* updated 
                                                         -- when this occurs. If the "last_updated_on" column *is* updated when
                                                         -- this happens, then this test here is not necessary.
        OR i.image_date > ?                              -- Images that have had "image_date" updated since the last run.
                                                         -- This treats the "image_date" column as a "last_updated-on" column
                                                         -- for the "image" table. If the "image" table is never updated, then
                                                         -- this test is not necessary. This will correctly include such passages 
                                                         -- even if the "last_updated_on" column for the passage table (in this 
                                                         -- case "last_updated_on") is *not* updated when this occurs. If the 
                                                         -- "last_updated_on" column *is* updated when this happens, then this 
                                                         -- test here is not necessary.
    )
    AND p.passage_id &lt;= ${PARAM_SOURCE_TABLE_MAX_INSERT_ID}           -- To avoid loading rows that are *inserted* after the job starts.

-- This condition is commented out because it is not needed and leads to problems if used.
-- For details, see the comments in the step that creates the SELECT statement for the source table
-- in transformation:
--
--   /generic/target_update/tr_target-update_table-updatable_table
--
--    AND (
--            p.last_updated_on IS NULL OR                          -- Rows that have been inserted but not modified.
--            p.last_updated_on &lt;= '${PARAM_CDC_CURRENT_LOAD_UTC}'  -- To avoid loading rows that are *modified* after the job starts.
--        ) 
ORDER BY 
    p.passage_id, 
    i.image_id</sql>
    <limit>0</limit>
    <lookup>Write to log: parameters, max id &amp; date</lookup>
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>544</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Table output - PSA.schema.table</name>
    <type>TableOutput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>psa_db</connection>
    <schema>${PARAM_TARGET_SCHEMA}</schema>
    <table>${PARAM_TARGET_TABLE}</table>
    <commit>1000</commit>
    <truncate>N</truncate>
    <ignore_errors>N</ignore_errors>
    <use_batch>N</use_batch>
    <specify_fields>N</specify_fields>
    <partitioning_enabled>N</partitioning_enabled>
    <partitioning_field />
    <partitioning_daily>N</partitioning_daily>
    <partitioning_monthly>Y</partitioning_monthly>
    <tablename_in_field>N</tablename_in_field>
    <tablename_field />
    <tablename_in_table>Y</tablename_in_table>
    <return_keys>N</return_keys>
    <return_field />
    <fields>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>832</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Update - PSA.schema.table</name>
    <type>Update</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>psa_db</connection>
    <skip_lookup>N</skip_lookup>
    <commit>100</commit>
    <use_batch>N</use_batch>
    <error_ignored>N</error_ignored>
    <ignore_flag_field />
    <lookup>
      <schema>${PARAM_TARGET_SCHEMA}</schema>
      <table>${PARAM_TARGET_TABLE}</table>
      <key>
        <name>passage_with_images_id</name>
        <field>passage_with_images_id</field>
        <condition>=</condition>
        <name2 />
      </key>
      <value>
        <name>passage_with_images_id</name>
        <rename>passage_with_images_id</rename>
      </value>
      <value>
        <name>charging_point_id</name>
        <rename>charging_point_id</rename>
      </value>
      <value>
        <name>passage_date</name>
        <rename>passage_date</rename>
      </value>
      <value>
        <name>finished_date</name>
        <rename>finished_date</rename>
      </value>
      <value>
        <name>row_can_be_deleted_from</name>
        <rename>row_can_be_deleted_from</rename>
      </value>
      <value>
        <name>last_updated_on</name>
        <rename>last_updated_on</rename>
      </value>
      <value>
        <name>image_1_id</name>
        <rename>image_1_id</rename>
      </value>
      <value>
        <name>image_1_date</name>
        <rename>image_1_date</rename>
      </value>
      <value>
        <name>image_1_camera_id</name>
        <rename>image_1_camera_id</rename>
      </value>
      <value>
        <name>image_1_file_id</name>
        <rename>image_1_file_id</rename>
      </value>
      <value>
        <name>image_2_id</name>
        <rename>image_2_id</rename>
      </value>
      <value>
        <name>image_2_date</name>
        <rename>image_2_date</rename>
      </value>
      <value>
        <name>image_2_camera_id</name>
        <rename>image_2_camera_id</rename>
      </value>
      <value>
        <name>image_2_file_id</name>
        <rename>image_2_file_id</rename>
      </value>
      <value>
        <name>image_3_id</name>
        <rename>image_3_id</rename>
      </value>
      <value>
        <name>image_3_date</name>
        <rename>image_3_date</rename>
      </value>
      <value>
        <name>image_3_camera_id</name>
        <rename>image_3_camera_id</rename>
      </value>
      <value>
        <name>image_3_file_id</name>
        <rename>image_3_file_id</rename>
      </value>
      <value>
        <name>image_4_id</name>
        <rename>image_4_id</rename>
      </value>
      <value>
        <name>image_4_date</name>
        <rename>image_4_date</rename>
      </value>
      <value>
        <name>image_4_camera_id</name>
        <rename>image_4_camera_id</rename>
      </value>
      <value>
        <name>image_4_file_id</name>
        <rename>image_4_file_id</rename>
      </value>
      <value>
        <name>etl_batch_id_insert</name>
        <rename>etl_batch_id_insert</rename>
      </value>
      <value>
        <name>etl_batch_id_last_update</name>
        <rename>etl_batch_id_last_update</rename>
      </value>
    </lookup>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>1008</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Write to log: parameters, max id &amp; date</name>
    <type>WriteToLog</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <loglevel>log_level_basic</loglevel>
    <displayHeader>Y</displayHeader>
    <limitRows>N</limitRows>
    <limitRowsNumber>0</limitRowsNumber>
    <logmessage>tr_psa-update_table-obo.passage_with_images:
PARAM_CDC_LAST_LOAD_UTC    = ${PARAM_CDC_LAST_LOAD_UTC}
PARAM_CDC_CURRENT_LOAD_UTC = ${PARAM_CDC_CURRENT_LOAD_UTC}
PARAM_SOURCE_TABLE_MAX_INSERT_ID        = ${PARAM_SOURCE_TABLE_MAX_INSERT_ID}</logmessage>
    <fields>
      <field>
        <name>max_target_insert_id</name>
      </field>
      <field>
        <name>max_target_last_updated_on</name>
      </field>
      <field>
        <name>max_target_image_id</name>
      </field>
      <field>
        <name>max_target_image_date</name>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>448</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step_error_handling>
    <error>
      <source_step>Table output - PSA.schema.table</source_step>
      <target_step>Set etl_batch_id_last_update = Xform batch ID</target_step>
      <is_enabled>Y</is_enabled>
      <nr_valuename />
      <descriptions_valuename />
      <fields_valuename />
      <codes_valuename />
      <max_errors />
      <max_pct_errors />
      <min_pct_rows />
    </error>
  </step_error_handling>
  <slave-step-copy-partition-distribution>
  </slave-step-copy-partition-distribution>
  <slave_transformation>N</slave_transformation>
</transformation>
