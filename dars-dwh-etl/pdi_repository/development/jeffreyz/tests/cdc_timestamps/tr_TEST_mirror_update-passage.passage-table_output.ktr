<transformation>
  <info>
    <name>tr_TEST_mirror_update-passage.passage-table_output</name>
    <description/>
    <extended_description/>
    <trans_version/>
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>&#x2f;development&#x2f;jeffreyz&#x2f;tests&#x2f;cdc_timestamps</directory>
    <parameters>
        <parameter>
            <name>PARAM_CDC_CURRENT_LOAD</name>
            <default_value>1900.01.01 00&#x3a;00&#x3a;00</default_value>
            <description>Timestamp of the current load &#x28;no rows after this timestamp will be loaded&#x29;</description>
        </parameter>
        <parameter>
            <name>PARAM_CDC_LAST_LOAD</name>
            <default_value>1900.01.01 00&#x3a;00&#x3a;00</default_value>
            <description>Timestamp of last successful load from the source database</description>
        </parameter>
    </parameters>
    <log>
<trans-log-table><connection>dwh_tdp_logging</connection>
<schema>&#x24;&#x7b;DWH_TDP_LOG_TRANS_SCHEMA&#x7d;</schema>
<table>&#x24;&#x7b;DWH_TDP_LOG_TRANS_TABLE&#x7d;</table>
<size_limit_lines/>
<interval/>
<timeout_days>&#x24;&#x7b;DWH_TDP_LOG_TRANS_TIMEOUT_IN_DAYS&#x7d;</timeout_days>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STATUS</id><enabled>Y</enabled><name>STATUS</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name><subject>Table output - DWH.passage.passage 2</subject></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name><subject>Table output - DWH.passage.passage 2</subject></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name><subject>Table output - DWH.passage.passage 2</subject></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name><subject>Table input -  TDP.passage.passage</subject></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name><subject>Table output - DWH.passage.passage 2</subject></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name><subject>Table output - DWH.passage.passage 2</subject></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>STARTDATE</id><enabled>Y</enabled><name>STARTDATE</name></field><field><id>ENDDATE</id><enabled>Y</enabled><name>ENDDATE</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>DEPDATE</id><enabled>Y</enabled><name>DEPDATE</name></field><field><id>REPLAYDATE</id><enabled>Y</enabled><name>REPLAYDATE</name></field><field><id>LOG_FIELD</id><enabled>Y</enabled><name>LOG_FIELD</name></field><field><id>EXECUTING_SERVER</id><enabled>N</enabled><name>EXECUTING_SERVER</name></field><field><id>EXECUTING_USER</id><enabled>N</enabled><name>EXECUTING_USER</name></field><field><id>CLIENT</id><enabled>N</enabled><name>CLIENT</name></field></trans-log-table>
<perf-log-table><connection>dwh_tdp_logging</connection>
<schema>&#x24;&#x7b;DWH_TDP_LOG_TRANSPERFORMANCE_SCHEMA&#x7d;</schema>
<table>&#x24;&#x7b;DWH_TDP_LOG_TRANSPERFORMANCE_TABLE&#x7d;</table>
<interval/>
<timeout_days>&#x24;&#x7b;DWH_TDP_LOG_TRANSPERFORMANCE_TIMEOUT_IN_DAYS&#x7d;</timeout_days>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>SEQ_NR</id><enabled>Y</enabled><name>SEQ_NR</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>INPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>INPUT_BUFFER_ROWS</name></field><field><id>OUTPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>OUTPUT_BUFFER_ROWS</name></field></perf-log-table>
<channel-log-table><connection>dwh_tdp_logging</connection>
<schema>&#x24;&#x7b;DWH_TDP_LOG_CHANNEL_SCHEMA&#x7d;</schema>
<table>&#x24;&#x7b;DWH_TDP_LOG_CHANNEL_TABLE&#x7d;</table>
<timeout_days>&#x24;&#x7b;DWH_TDP_LOG_CHANNEL_TIMEOUT_IN_DAYS&#x7d;</timeout_days>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>LOGGING_OBJECT_TYPE</id><enabled>Y</enabled><name>LOGGING_OBJECT_TYPE</name></field><field><id>OBJECT_NAME</id><enabled>Y</enabled><name>OBJECT_NAME</name></field><field><id>OBJECT_COPY</id><enabled>Y</enabled><name>OBJECT_COPY</name></field><field><id>REPOSITORY_DIRECTORY</id><enabled>Y</enabled><name>REPOSITORY_DIRECTORY</name></field><field><id>FILENAME</id><enabled>Y</enabled><name>FILENAME</name></field><field><id>OBJECT_ID</id><enabled>Y</enabled><name>OBJECT_ID</name></field><field><id>OBJECT_REVISION</id><enabled>Y</enabled><name>OBJECT_REVISION</name></field><field><id>PARENT_CHANNEL_ID</id><enabled>Y</enabled><name>PARENT_CHANNEL_ID</name></field><field><id>ROOT_CHANNEL_ID</id><enabled>Y</enabled><name>ROOT_CHANNEL_ID</name></field></channel-log-table>
<step-log-table><connection>dwh_tdp_logging</connection>
<schema>&#x24;&#x7b;DWH_TDP_LOG_TRANSSTEP_SCHEMA&#x7d;</schema>
<table>&#x24;&#x7b;DWH_TDP_LOG_TRANSSTEP_TABLE&#x7d;</table>
<timeout_days>&#x24;&#x7b;DWH_TDP_LOG_TRANSSTEP_TIMEOUT_IN_DAYS&#x7d;</timeout_days>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>LOG_FIELD</id><enabled>N</enabled><name>LOG_FIELD</name></field></step-log-table>
<metrics-log-table><connection>dwh_tdp_logging</connection>
<schema>&#x24;&#x7b;DWH_TDP_LOG_TRANSMETRICS_SCHEMA&#x7d;</schema>
<table>&#x24;&#x7b;DWH_TDP_LOG_TRANSMETRICS_TABLE&#x7d;</table>
<timeout_days>&#x24;&#x7b;DWH_TDP_LOG_TRANSMETRICS_TIMEOUT_IN_DAYS&#x7d;</timeout_days>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>METRICS_DATE</id><enabled>Y</enabled><name>METRICS_DATE</name></field><field><id>METRICS_CODE</id><enabled>Y</enabled><name>METRICS_CODE</name></field><field><id>METRICS_DESCRIPTION</id><enabled>Y</enabled><name>METRICS_DESCRIPTION</name></field><field><id>METRICS_SUBJECT</id><enabled>Y</enabled><name>METRICS_SUBJECT</name></field><field><id>METRICS_TYPE</id><enabled>Y</enabled><name>METRICS_TYPE</name></field><field><id>METRICS_VALUE</id><enabled>Y</enabled><name>METRICS_VALUE</name></field></metrics-log-table>
    </log>
    <maxdate>
      <connection/>
      <table/>
      <field/>
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file/>
    <capture_step_performance>Y</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
  <created_user>-</created_user>
  <created_date>2016&#x2f;04&#x2f;03 09&#x3a;57&#x3a;16.279</created_date>
  <modified_user>-</modified_user>
  <modified_date>2016&#x2f;05&#x2f;26 08&#x3a;42&#x3a;37.240</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA&#x3d;</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
    <notepad>
      <note>Load the data from the source database table that will be moved to the DWH table.&#xa;&#xa;It is important here to select &#x22;replace variables in script&#x3f;&#x22;so that the references &#x22;&#x3f;&#x22;,&#xa;&#x24;&#x7b;PARAM_CDC_LAST_LOAD&#x7d; and &#x24;&#x7b;PARAM_CDC_CURRENT_LOAD&#x7d; will be evaluated.&#xa;&#xa;It is also necessary to specify the step from which fields will  be used to supply values &#xa;for the &#x22;&#x3f;&#x22; replacement characters.  In this case, the previous step is specified.</note>
      <xloc>304</xloc>
      <yloc>384</yloc>
      <width>576</width>
      <heigth>129</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Insert new rows into the DWH using a &#x22;Table output&#x22; step. Updates are handled by the&#xa;&#x22;Update&#x22; step via an error handling hop. This requires &#x22;passage_id&#x22; to have a unique&#xa;constraint&#x3b; otherwise, error handling will not be triggered when attempted to insert a&#xa;new row with a duplicate key.&#xa;&#xa;PDI does not fully support error handling when using &#x22;batch processing&#x22; with the &#xa;PostgreSQL JDBC driver &#x28;a message to this effect is displayed when accepting the&#xa;transformation settings dialog&#x29;, so make sure &#x22;Use batch update for inserts&#x22; is &#x2a;not&#x2a; &#xa;selected for the &#x22;Table output&#x22; step&#x21;&#xa;&#xa;But this approach is definitely faster than using only an Insert&#x2f;Update step.</note>
      <xloc>864</xloc>
      <yloc>560</yloc>
      <width>579</width>
      <heigth>197</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Get batch ID for current transformation. This will be stored in the DWH table.</note>
      <xloc>304</xloc>
      <yloc>528</yloc>
      <width>522</width>
      <heigth>27</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This transformation updates the DWH mirror of the &#x22;dynamic&#x22; table passage.passage from the TDP archive database.&#xa;This transformation has parameters&#x3a;&#xa;&#xa;	PARAM_CDC_LAST_LOAD		&#x3c;- not used in this transformation - MAX&#x28;archive_id&#x29; is used instead&#xa;	PARAM_CDC_CURRENT_LOAD&#xa;&#xa;It is not necessary to declare these parameters in the transformation settings, although this can be useful for testing&#xa;purposes. Even if they are &#x2a;not&#x2a; explicitely declared, they can be passed via a &#x22;Transformation&#x22; job entry that has the &#xa;option &#x22;Pass all parameter values down to the sub-transformation&#x22; selected.</note>
      <xloc>16</xloc>
      <yloc>0</yloc>
      <width>793</width>
      <heigth>163</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>batch&#x3d;100, all inserts&#x3a;	700 -&#x3e; 140 rows&#x2f;s&#xa;batch&#x3d;1000, all inserts&#x3a;	700 -&#x3e; 145 rows&#x2f;s&#xa;batch&#x3d;100, all updates&#x3a;	80 rows&#x2f;s&#xa;batch&#x3d;1000, all updates&#x3a;	80 rows&#x2f;s&#xa;&#xa;After adding PRIMARY KEY constraint on &#xa;&#x22;passage_id&#x22;&#x3a;&#xa;&#xa;batch&#x3d;100, all inserts&#x3a;	1400 rows&#x2f;s&#xa;batch&#x3d;100, all updates&#x3a; 	3200 rows&#x2f;s&#xa;&#xa;batch&#x3d;1000, all inserts&#x3a;	1600 rows&#x2f;s&#xa;batch&#x3d;1000, all updates&#x3a;	3300 rows&#x2f;s	</note>
      <xloc>320</xloc>
      <yloc>672</yloc>
      <width>293</width>
      <heigth>231</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>With error handling enabled for the &#x22;Table output&#x22; step, with or without &#xa;error handling hop and using &#x2a;either&#x2a; an &#x22;Update&#x22; step or a &#x22;Dummy&#x22; &#xa;step for error handling&#x3a;&#xa;&#xa;All inserts&#x3a;	Update&#x3a;batch&#x3d;100,	Table output&#x3a;batch&#x3d;1000&#x3a;	3200 rows&#x2f;s&#xa;All updates&#x3a;	Update&#x3a;batch&#x3d;100,	Table output&#x3a;batch&#x3d;1000&#x3a;	2500 rows&#x2f;s&#xa;&#xa;All inserts&#x3a;	Update&#x3a;batch&#x3d;100,	Table output&#x3a;batch&#x3d;1000&#x3a;	3200 rows&#x2f;s&#xa;All updates&#x3a;	Update&#x3a;batch&#x3d;100,	Table output&#x3a;batch&#x3d;1000&#x3a;	2500 rows&#x2f;s&#xa;&#xa;All inserts&#x3a;	Update&#x3a;batch&#x3d;1000,	Table output&#x3a;batch&#x3d;1000&#x3a;	3200 rows&#x2f;s&#xa;All updates&#x3a;	Update&#x3a;batch&#x3d;1000,	Table output&#x3a;batch&#x3d;1000&#x3a;	2500 rows&#x2f;s&#xa;&#xa;All inserts&#x3a;	Update&#x3a;batch&#x3d;100,	Table output&#x3a;batch&#x3d;0&#x3a;		3200 rows&#x2f;s&#xa;All updates&#x3a;	Update&#x3a;batch&#x3d;100,	Table output&#x3a;batch&#x3d;0&#x3a;		2500 rows&#x2f;s&#xa;&#xa;All inserts&#x3a;	Update&#x3a;batch&#x3d;0,		Table output&#x3a;batch&#x3d;0&#x3a;		3200 rows&#x2f;s&#xa;All updates&#x3a;	Update&#x3a;batch&#x3d;0,		Table output&#x3a;batch&#x3d;0&#x3a;		2500 rows&#x2f;s&#xa;&#xa;This testing shows that we still get approximately the same throughput &#xa;regardless of &#x22;commit size&#x22; and whether or not  &#x22;batch updates&#x22; are enabled &#xa;in either the Table output or the Update step. THIS &#x2a;MAY&#x2a; MEAN THAT PDI &#xa;DOES NOT ACTUALLY USE BATCH UPDATES AT ALL FOR POSTGRESQL IF &#xa;ERROR HANDLING IS ENABLED, EVEN IF THE SETTINGS SPECIFY THAT BATCH &#xa;UPDATES SHOULD BE USED. Yes, this seems to be the case. See&#x3a;&#xa;&#xa;http&#x3a;&#x2f;&#x2f;forums.pentaho.com&#x2f;showthread.php&#x3f;71507-Batch-insert-mode-disabled-because-of-database-limitations-on-Postgres</note>
      <xloc>864</xloc>
      <yloc>784</yloc>
      <width>854</width>
      <heigth>469</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This step handles only inserts, so it is not &#xa;equivalent to the other approaches.For&#xa;this reason, its benchmark values are&#xa;higher.&#xa;&#xa;batch&#x3d;0		&#x28;inserts only&#x29;&#x3a;	4500 rows&#x2f;s&#xa;batch&#x3d;100	&#x28;inserts only&#x29;&#x3a;	5700 rows&#x2f;s&#xa;batch&#x3d;1000	&#x28;inserts only&#x29;&#x3a;	5800 rows&#x2f;s&#xa;batch&#x3d;5000	&#x28;inserts only&#x29;&#x3a;	6100 rows&#x2f;s</note>
      <xloc>16</xloc>
      <yloc>672</yloc>
      <width>284</width>
      <heigth>163</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>An odd behaviour is observed using &#x2a;either&#x22; the &#x22;Insert&#x2f;Update&#x22; step or the &#xa;&#x22;Table output&#x22; step with error handling &#x28;although in this second approach it&#xa;only happens when the error handling sends rows to the &#x22;Update&#x22; step&#x29;&#x3a;&#xa;&#xa;After processing a large number of rows, it takes a long time for this &#xa;transformation to end. During this period the &#x22;Pause&#x22; and &#x22;Stop&#x22; buttons  &#xa;remain enabled. Furthermore, running&#x22; top&#x22; shows that both &#x22;postgres&#x22;and &#xa;&#x22;java&#x22; processes are actively using a 25-75&#x25; of the CPU. When this CPU usage &#xa;stops, the  &#x22;Pause&#x22; and &#x22;Stop&#x22; buttons become disabled, showing that the&#xa;transformation is finally finished. Strange.&#xa;&#xa;This does &#x2a;not&#x2a; occur when the &#x22;Update&#x22; step is replaced with a Dummy step,&#xa;which currently is acceptable if we do not need to perform updates -  i.e., if we&#xa;only need to be able to handle re-running an ETL script that tries to re-process&#xa;a row that was processed earlier during a load that failed part-way through.</note>
      <xloc>320</xloc>
      <yloc>928</yloc>
      <width>528</width>
      <heigth>265</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>255</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Using a &#x22;Table output&#x22; step with an error handling hop to an &#x22;Update&#x22; step &#xa;provides an approximately 2x speedup over an &#x22;Insert&#x2f;Update&#x22; step for &#xa;inserts &#x2a;and&#x2a; it does not exhibit &#x28;for inserts only&#x29; the behaviour where a &#xa;&#x22;java&#x22;and &#x22;postgres&#x22; process continue to run with a high CPU load long after &#xa;the transformation is finished.</note>
      <xloc>320</xloc>
      <yloc>1216</yloc>
      <width>519</width>
      <heigth>95</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>173</backgroundcolorred>
      <backgroundcolorgreen>216</backgroundcolorgreen>
      <backgroundcolorblue>230</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Write parameters and max_id value to the log so it will be obvious which values &#xa;were used.</note>
      <xloc>304</xloc>
      <yloc>320</yloc>
      <width>538</width>
      <heigth>44</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Get the maximum value stored in column &#x22;archive_id&#x22; of the DWH table that will &#xa;be updated by this transformation. This will be used to the select data from the &#xa;source table in the TDP archive database that was inserted since the last update. &#xa;&#xa;IMPORTANT&#x3a;	We &#x2a;cannot&#x2a; use MAX&#x28;archive_date&#x29; for this purpose because the&#xa;				&#x22;archive_date&#x22; column will not, in general, be unique.</note>
      <xloc>304</xloc>
      <yloc>192</yloc>
      <width>547</width>
      <heigth>112</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>If we use &#x24;&#x7b;PARAM_CDC_LAST_LOAD&#x7d; instead of MAX&#x28;archive_date&#x29; in the &#x22;Table input&#x22; &#xa;query for loading rows from the TDP archive DB, then we need to replace the &#x22;Table output&#x22;&#xa;step without error handling that is currently used with &#x2a;either&#x2a; the &#x22;Insert&#x2f;Update&#x22; step &#xa;&#x2a;or&#x2a; the &#x22;Table output&#x22; step _with_ error handling.&#xa;&#xa;This is because we will need to be able to handle the processing of rows from the TDP&#xa;archive DB that have already been loaded into the DWH. This will occur if a load fails for&#xa;some reason after successfully loading some records. In this case, the column&#xa;cdc_timestamps.last_successful_load will not be updated&#x3b; hence, the next load will use&#xa;the same value for cdc_timestamps.last_successful_load, which will load rows that were&#xa;successfully processed during the previous load.&#xa;&#xa;If we use the &#x22;Table output&#x22; step with error handling, then it is ESSENTIAL that there is a&#xa;unique constraint on the column &#x22;passage_id&#x22;. This can be done by explicitly adding such&#xa;a constraint, or by making a primary key based on this column.</note>
      <xloc>864</xloc>
      <yloc>0</yloc>
      <width>617</width>
      <heigth>265</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>255</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>&#x3c;- More info&#x3a;	If we were to re-run a load because of an error during a previous load, &#xa;				we would likely either reload some of the same rows again that have &#xa;				the same value of MAX&#x28;archive_date&#x29;, or we would miss loading some &#xa;				rows that have the same value of MAX&#x28;archive_date&#x29; &#x28;they would never&#xa;				 be loaded&#x29;, depending on the comparator used with this value.</note>
      <xloc>864</xloc>
      <yloc>272</yloc>
      <width>576</width>
      <heigth>95</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>11</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>0</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <connection>
    <name>dwh_tdp_mirror</name>
    <server>&#x24;&#x7b;DWH_TDP_MIRROR_DB_HOST&#x7d;</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>&#x24;&#x7b;DWH_TDP_MIRROR_DB_DATABASE&#x7d;</database>
    <port>&#x24;&#x7b;DWH_TDP_MIRROR_DB_PORT&#x7d;</port>
    <username>&#x24;&#x7b;DWH_TDP_MIRROR_DB_USERNAME&#x7d;</username>
    <password>&#x24;&#x7b;DWH_TDP_MIRROR_DB_PASSWORD&#x7d;</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute><code>FORCE_IDENTIFIERS_TO_LOWERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_UPPERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>IS_CLUSTERED</code><attribute>N</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>&#x24;&#x7b;DWH_TDP_MIRROR_DB_PORT&#x7d;</attribute></attribute>
      <attribute><code>PRESERVE_RESERVED_WORD_CASE</code><attribute>N</attribute></attribute>
      <attribute><code>QUOTE_ALL_FIELDS</code><attribute>N</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_TIMESTAMP_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>USE_POOLING</code><attribute>N</attribute></attribute>
    </attributes>
  </connection>
  <connection>
    <name>dwh_tdp_logging</name>
    <server>&#x24;&#x7b;DWH_TDP_LOGGING_DB_HOST&#x7d;</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>&#x24;&#x7b;DWH_TDP_LOGGING_DB_DATABASE&#x7d;</database>
    <port>&#x24;&#x7b;DWH_TDP_LOGGING_DB_PORT&#x7d;</port>
    <username>&#x24;&#x7b;DWH_TDP_LOGGING_DB_USERNAME&#x7d;</username>
    <password>&#x24;&#x7b;DWH_TDP_LOGGING_DB_PASSWORD&#x7d;</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute><code>FORCE_IDENTIFIERS_TO_LOWERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_UPPERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>IS_CLUSTERED</code><attribute>N</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>&#x24;&#x7b;DWH_TDP_LOGGING_DB_PORT&#x7d;</attribute></attribute>
      <attribute><code>PRESERVE_RESERVED_WORD_CASE</code><attribute>N</attribute></attribute>
      <attribute><code>QUOTE_ALL_FIELDS</code><attribute>N</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_TIMESTAMP_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>USE_POOLING</code><attribute>N</attribute></attribute>
    </attributes>
  </connection>
  <connection>
    <name>tdp_archive</name>
    <server>&#x24;&#x7b;DWH_TDP_ARCHIVE_DB_HOST&#x7d;</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>&#x24;&#x7b;DWH_TDP_ARCHIVE_DB_DATABASE&#x7d;</database>
    <port>&#x24;&#x7b;DWH_TDP_ARCHIVE_DB_PORT&#x7d;</port>
    <username>&#x24;&#x7b;DWH_TDP_ARCHIVE_DB_USERNAME&#x7d;</username>
    <password>&#x24;&#x7b;DWH_TDP_ARCHIVE_DB_PASSWORD&#x7d;</password>
    <servername/>
    <data_tablespace/>
    <index_tablespace/>
    <attributes>
      <attribute><code>FORCE_IDENTIFIERS_TO_LOWERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>FORCE_IDENTIFIERS_TO_UPPERCASE</code><attribute>N</attribute></attribute>
      <attribute><code>IS_CLUSTERED</code><attribute>N</attribute></attribute>
      <attribute><code>PORT_NUMBER</code><attribute>&#x24;&#x7b;DWH_TDP_ARCHIVE_DB_PORT&#x7d;</attribute></attribute>
      <attribute><code>PRESERVE_RESERVED_WORD_CASE</code><attribute>N</attribute></attribute>
      <attribute><code>QUOTE_ALL_FIELDS</code><attribute>N</attribute></attribute>
      <attribute><code>SUPPORTS_BOOLEAN_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>SUPPORTS_TIMESTAMP_DATA_TYPE</code><attribute>Y</attribute></attribute>
      <attribute><code>USE_POOLING</code><attribute>N</attribute></attribute>
    </attributes>
  </connection>
  <order>
  <hop> <from>Table input -  TDP.passage.passage</from><to>Get System Info - transformation batch ID</to><enabled>Y</enabled> </hop>
  <hop> <from>Get System Info - transformation batch ID</from><to>Table output - DWH.passage.passage 2</to><enabled>N</enabled> </hop>
  <hop> <from>Get System Info - transformation batch ID</from><to>Insert &#x2f; Update - DWH.passage.passage</to><enabled>N</enabled> </hop>
  <hop> <from>Get System Info - transformation batch ID</from><to>Table output - DWH.passage.passage</to><enabled>Y</enabled> </hop>
  <hop> <from>Table output - DWH.passage.passage 2</from><to>Update - DWH.passage.passage</to><enabled>N</enabled> </hop>
  <hop> <from>Table output - DWH.passage.passage 2</from><to>Dummy</to><enabled>N</enabled> </hop>
  <hop> <from>Get max ID for CDC&#x3a; DWH.passage.passage</from><to>Write to log&#x3a; parameters, max_id</to><enabled>Y</enabled> </hop>
  <hop> <from>Write to log&#x3a; parameters, max_id</from><to>Table input -  TDP.passage.passage</to><enabled>Y</enabled> </hop>
  </order>
  <step>
    <name>Dummy</name>
    <type>Dummy</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>800</xloc>
      <yloc>768</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Get System Info - transformation batch ID</name>
    <type>SystemInfo</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <fields>
      <field>
        <name>etl_batch_id</name>
        <type>batch ID</type>
        </field>
      </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>128</xloc>
      <yloc>528</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Get max ID for CDC&#x3a; DWH.passage.passage</name>
    <type>TableInput</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <connection>dwh_tdp_mirror</connection>
    <sql>SELECT&#xa;    COALESCE&#x28;MAX&#x28;archive_id&#x29;, &#x24;&#x7b;DWH_ARCHIVE_ID_LOWER_BOUND&#x7d;&#x29; AS max_id&#xa;FROM&#xa;    passage.passage&#xa;</sql>
    <limit>0</limit>
    <lookup/>
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>128</xloc>
      <yloc>240</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Insert &#x2f; Update - DWH.passage.passage</name>
    <type>InsertUpdate</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <connection>dwh_tdp_mirror</connection>
    <commit>100</commit>
    <update_bypassed>N</update_bypassed>
    <lookup>
      <schema>passage</schema>
      <table>passage</table>
      <key>
        <name>passage_id</name>
        <field>passage_id</field>
        <condition>&#x3d;</condition>
        <name2/>
      </key>
      <value>
        <name>passage_id</name>
        <rename>passage_id</rename>
        <update>N</update>
      </value>
      <value>
        <name>passage_status_id</name>
        <rename>passage_status_id</rename>
        <update>Y</update>
      </value>
      <value>
        <name>component_id</name>
        <rename>component_id</rename>
        <update>Y</update>
      </value>
      <value>
        <name>passage_date</name>
        <rename>passage_date</rename>
        <update>Y</update>
      </value>
      <value>
        <name>arrival_date</name>
        <rename>arrival_date</rename>
        <update>Y</update>
      </value>
      <value>
        <name>finished_date</name>
        <rename>finished_date</rename>
        <update>Y</update>
      </value>
      <value>
        <name>sent_date</name>
        <rename>sent_date</rename>
        <update>Y</update>
      </value>
      <value>
        <name>service_provider_id</name>
        <rename>service_provider_id</rename>
        <update>Y</update>
      </value>
      <value>
        <name>charging_point_id</name>
        <rename>charging_point_id</rename>
        <update>Y</update>
      </value>
      <value>
        <name>lane_id</name>
        <rename>lane_id</rename>
        <update>Y</update>
      </value>
      <value>
        <name>vehicle_direction_id</name>
        <rename>vehicle_direction_id</rename>
        <update>Y</update>
      </value>
      <value>
        <name>image_count</name>
        <rename>image_count</rename>
        <update>Y</update>
      </value>
      <value>
        <name>obu_count</name>
        <rename>obu_count</rename>
        <update>Y</update>
      </value>
      <value>
        <name>pcs_rate</name>
        <rename>pcs_rate</rename>
        <update>Y</update>
      </value>
      <value>
        <name>avc_class_id</name>
        <rename>avc_class_id</rename>
        <update>Y</update>
      </value>
      <value>
        <name>passage_priority</name>
        <rename>passage_priority</rename>
        <update>Y</update>
      </value>
      <value>
        <name>passage_type_id</name>
        <rename>passage_type_id</rename>
        <update>Y</update>
      </value>
      <value>
        <name>external_passage_id</name>
        <rename>external_passage_id</rename>
        <update>Y</update>
      </value>
      <value>
        <name>passage_group_id</name>
        <rename>passage_group_id</rename>
        <update>Y</update>
      </value>
      <value>
        <name>propertybag</name>
        <rename>propertybag</rename>
        <update>Y</update>
      </value>
      <value>
        <name>completion_category_id</name>
        <rename>completion_category_id</rename>
        <update>Y</update>
      </value>
      <value>
        <name>completion_sub_category_id</name>
        <rename>completion_sub_category_id</rename>
        <update>Y</update>
      </value>
      <value>
        <name>archive_id</name>
        <rename>archive_id</rename>
        <update>N</update>
      </value>
      <value>
        <name>archive_date</name>
        <rename>archive_date</rename>
        <update>N</update>
      </value>
      <value>
        <name>etl_batch_id</name>
        <rename>etl_batch_id</rename>
        <update>N</update>
      </value>
    </lookup>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>432</xloc>
      <yloc>608</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Table input -  TDP.passage.passage</name>
    <type>TableInput</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <connection>tdp_archive</connection>
    <sql>SELECT&#xa;    &#x2a;&#xa;FROM&#xa;    passage.passage&#xa;WHERE&#xa;    archive_id &#x3e; &#x3f; AND&#xa;    --archive_date &#x3e;  &#x27;&#x24;&#x7b;PARAM_CDC_LAST_LOAD&#x7d;&#x27; AND &#xa;	archive_date &#x3c;&#x3d; &#x27;&#x24;&#x7b;PARAM_CDC_CURRENT_LOAD&#x7d;&#x27;&#xa;ORDER BY&#xa;    archive_id&#xa;--LIMIT 5000</sql>
    <limit>0</limit>
    <lookup>Write to log&#x3a; parameters, max_id</lookup>
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>128</xloc>
      <yloc>432</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Table output - DWH.passage.passage</name>
    <type>TableOutput</type>
    <description/>
    <distribute>N</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <connection>dwh_tdp_mirror</connection>
    <schema>passage</schema>
    <table>passage</table>
    <commit>1000</commit>
    <truncate>N</truncate>
    <ignore_errors>N</ignore_errors>
    <use_batch>Y</use_batch>
    <specify_fields>N</specify_fields>
    <partitioning_enabled>N</partitioning_enabled>
    <partitioning_field/>
    <partitioning_daily>N</partitioning_daily>
    <partitioning_monthly>Y</partitioning_monthly>
    <tablename_in_field>N</tablename_in_field>
    <tablename_field/>
    <tablename_in_table>Y</tablename_in_table>
    <return_keys>N</return_keys>
    <return_field/>
    <fields>
    </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>128</xloc>
      <yloc>608</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Table output - DWH.passage.passage 2</name>
    <type>TableOutput</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <connection>dwh_tdp_mirror</connection>
    <schema>passage</schema>
    <table>passage</table>
    <commit>1000</commit>
    <truncate>N</truncate>
    <ignore_errors>N</ignore_errors>
    <use_batch>N</use_batch>
    <specify_fields>N</specify_fields>
    <partitioning_enabled>N</partitioning_enabled>
    <partitioning_field/>
    <partitioning_daily>N</partitioning_daily>
    <partitioning_monthly>Y</partitioning_monthly>
    <tablename_in_field>N</tablename_in_field>
    <tablename_field/>
    <tablename_in_table>Y</tablename_in_table>
    <return_keys>N</return_keys>
    <return_field/>
    <fields>
    </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>720</xloc>
      <yloc>608</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Update - DWH.passage.passage</name>
    <type>Update</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <connection>dwh_tdp_mirror</connection>
    <skip_lookup>N</skip_lookup>
    <commit>100</commit>
    <use_batch>N</use_batch>
    <error_ignored>N</error_ignored>
    <ignore_flag_field/>
    <lookup>
      <schema>passage</schema>
      <table>passage</table>
      <key>
        <name>passage_id</name>
        <field>passage_id</field>
        <condition>&#x3d;</condition>
        <name2/>
        </key>
      <value>
        <name>passage_status_id</name>
        <rename>passage_status_id</rename>
        </value>
      <value>
        <name>component_id</name>
        <rename>component_id</rename>
        </value>
      <value>
        <name>passage_date</name>
        <rename>passage_date</rename>
        </value>
      <value>
        <name>arrival_date</name>
        <rename>arrival_date</rename>
        </value>
      <value>
        <name>finished_date</name>
        <rename>finished_date</rename>
        </value>
      <value>
        <name>sent_date</name>
        <rename>sent_date</rename>
        </value>
      <value>
        <name>service_provider_id</name>
        <rename>service_provider_id</rename>
        </value>
      <value>
        <name>charging_point_id</name>
        <rename>charging_point_id</rename>
        </value>
      <value>
        <name>lane_id</name>
        <rename>lane_id</rename>
        </value>
      <value>
        <name>vehicle_direction_id</name>
        <rename>vehicle_direction_id</rename>
        </value>
      <value>
        <name>image_count</name>
        <rename>image_count</rename>
        </value>
      <value>
        <name>obu_count</name>
        <rename>obu_count</rename>
        </value>
      <value>
        <name>pcs_rate</name>
        <rename>pcs_rate</rename>
        </value>
      <value>
        <name>avc_class_id</name>
        <rename>avc_class_id</rename>
        </value>
      <value>
        <name>passage_priority</name>
        <rename>passage_priority</rename>
        </value>
      <value>
        <name>passage_type_id</name>
        <rename>passage_type_id</rename>
        </value>
      <value>
        <name>external_passage_id</name>
        <rename>external_passage_id</rename>
        </value>
      <value>
        <name>passage_group_id</name>
        <rename>passage_group_id</rename>
        </value>
      <value>
        <name>propertybag</name>
        <rename>propertybag</rename>
        </value>
      <value>
        <name>completion_category_id</name>
        <rename>completion_category_id</rename>
        </value>
      <value>
        <name>completion_sub_category_id</name>
        <rename>completion_sub_category_id</rename>
        </value>
      </lookup>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>720</xloc>
      <yloc>800</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Write to log&#x3a; parameters, max_id</name>
    <type>WriteToLog</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
      <loglevel>log_level_basic</loglevel>
      <displayHeader>Y</displayHeader>
      <limitRows>N</limitRows>
      <limitRowsNumber>0</limitRowsNumber>
      <logmessage>PARAM_CDC_LAST_LOAD	&#x3d; &#x24;&#x7b;PARAM_CDC_LAST_LOAD&#x7d;&#xa;PARAM_CDC_CURRENT_LOAD	&#x3d; &#x24;&#x7b;PARAM_CDC_CURRENT_LOAD&#x7d;</logmessage>
    <fields>
      <field>
        <name>max_id</name>
        </field>
      </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>128</xloc>
      <yloc>320</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step_error_handling>
      <error>
        <source_step>Table output - DWH.passage.passage 2</source_step>
        <target_step>Dummy</target_step>
        <is_enabled>Y</is_enabled>
        <nr_valuename/>
        <descriptions_valuename/>
        <fields_valuename/>
        <codes_valuename/>
        <max_errors/>
        <max_pct_errors/>
        <min_pct_rows/>
      </error>
  </step_error_handling>
   <slave-step-copy-partition-distribution>
</slave-step-copy-partition-distribution>
   <slave_transformation>N</slave_transformation>

</transformation>
