<transformation>
  <info>
    <name>tr_tmplt_mirrored_updatable_table-update</name>
    <description />
    <extended_description />
    <trans_version />
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>/development/jeffreyz/tests</directory>
    <parameters>
      <parameter>
        <name>PARAM_CDC_CURRENT_LOAD</name>
        <default_value>2018.01.01 00:00:00</default_value>
        <description>Timestamp of the current load (no rows after this timestamp will be loaded)</description>
      </parameter>
      <parameter>
        <name>PARAM_CDC_LAST_LOAD</name>
        <default_value>1900.01.01 00:00:00</default_value>
        <description>Timestamp of last successful load from the source database</description>
      </parameter>
      <parameter>
        <name>PARAM_INSERTED_ON_COLNAME</name>
        <default_value>inserted_on</default_value>
        <description>Name of column acting as "inserted_on" timestamp column of source table</description>
      </parameter>
      <parameter>
        <name>PARAM_INSERT_ID_COLNAME</name>
        <default_value>insert_id</default_value>
        <description>Name of column acting as "insert_id" column of source table</description>
      </parameter>
      <parameter>
        <name>PARAM_LAST_UPDATED_ON_COLNAME</name>
        <default_value>last_updated_on</default_value>
        <description>Name of "last_updated_on" timestamp column of source table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_DB_ID</name>
        <default_value>1</default_value>
        <description>ID the "source" database containing tables will be mirrored to a "target" database</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_SCHEMA</name>
        <default_value>passage</default_value>
        <description>Name of schema containing source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_TABLE</name>
        <default_value>passage</default_value>
        <description>Name of source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_SCHEMA</name>
        <default_value>passage</default_value>
        <description>Name of schema containing target table to update</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_TABLE</name>
        <default_value>passage</default_value>
        <description>Name of target table to update</description>
      </parameter>
    </parameters>
    <log>
      <trans-log-table>
        <connection>logging_db</connection>
        <schema>${QF_LOG_TRANS_SCHEMA}</schema>
        <table>${QF_LOG_TRANS_TABLE}</table>
        <size_limit_lines />
        <interval />
        <timeout_days>${QF_LOG_TRANS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STATUS</id>
          <enabled>Y</enabled>
          <name>STATUS</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
          <subject>Table output - PSA.schema.table</subject>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
          <subject>Table output - PSA.schema.table</subject>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
          <subject>Table output - PSA.schema.table</subject>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
          <subject>Table input -  OBO.schema.table</subject>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
          <subject>Table output - PSA.schema.table</subject>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
          <subject>Table output - PSA.schema.table</subject>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>STARTDATE</id>
          <enabled>Y</enabled>
          <name>STARTDATE</name>
        </field>
        <field>
          <id>ENDDATE</id>
          <enabled>Y</enabled>
          <name>ENDDATE</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>DEPDATE</id>
          <enabled>Y</enabled>
          <name>DEPDATE</name>
        </field>
        <field>
          <id>REPLAYDATE</id>
          <enabled>Y</enabled>
          <name>REPLAYDATE</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>Y</enabled>
          <name>LOG_FIELD</name>
        </field>
        <field>
          <id>EXECUTING_SERVER</id>
          <enabled>N</enabled>
          <name>EXECUTING_SERVER</name>
        </field>
        <field>
          <id>EXECUTING_USER</id>
          <enabled>N</enabled>
          <name>EXECUTING_USER</name>
        </field>
        <field>
          <id>CLIENT</id>
          <enabled>N</enabled>
          <name>CLIENT</name>
        </field>
      </trans-log-table>
      <perf-log-table>
        <connection>logging_db</connection>
        <schema>${QF_LOG_TRANSPERFORMANCE_SCHEMA}</schema>
        <table>${QF_LOG_TRANSPERFORMANCE_TABLE}</table>
        <interval />
        <timeout_days>${QF_LOG_TRANSPERFORMANCE_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>SEQ_NR</id>
          <enabled>Y</enabled>
          <name>SEQ_NR</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>INPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>INPUT_BUFFER_ROWS</name>
        </field>
        <field>
          <id>OUTPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>OUTPUT_BUFFER_ROWS</name>
        </field>
      </perf-log-table>
      <channel-log-table>
        <connection>logging_db</connection>
        <schema>${QF_LOG_CHANNEL_SCHEMA}</schema>
        <table>${QF_LOG_CHANNEL_TABLE}</table>
        <timeout_days>${QF_LOG_CHANNEL_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>LOGGING_OBJECT_TYPE</id>
          <enabled>Y</enabled>
          <name>LOGGING_OBJECT_TYPE</name>
        </field>
        <field>
          <id>OBJECT_NAME</id>
          <enabled>Y</enabled>
          <name>OBJECT_NAME</name>
        </field>
        <field>
          <id>OBJECT_COPY</id>
          <enabled>Y</enabled>
          <name>OBJECT_COPY</name>
        </field>
        <field>
          <id>REPOSITORY_DIRECTORY</id>
          <enabled>Y</enabled>
          <name>REPOSITORY_DIRECTORY</name>
        </field>
        <field>
          <id>FILENAME</id>
          <enabled>Y</enabled>
          <name>FILENAME</name>
        </field>
        <field>
          <id>OBJECT_ID</id>
          <enabled>Y</enabled>
          <name>OBJECT_ID</name>
        </field>
        <field>
          <id>OBJECT_REVISION</id>
          <enabled>Y</enabled>
          <name>OBJECT_REVISION</name>
        </field>
        <field>
          <id>PARENT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>PARENT_CHANNEL_ID</name>
        </field>
        <field>
          <id>ROOT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>ROOT_CHANNEL_ID</name>
        </field>
      </channel-log-table>
      <step-log-table>
        <connection>logging_db</connection>
        <schema>${QF_LOG_TRANSSTEP_SCHEMA}</schema>
        <table>${QF_LOG_TRANSSTEP_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSSTEP_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>N</enabled>
          <name>LOG_FIELD</name>
        </field>
      </step-log-table>
      <metrics-log-table>
        <connection>logging_db</connection>
        <schema>${QF_LOG_TRANSMETRICS_SCHEMA}</schema>
        <table>${QF_LOG_TRANSMETRICS_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSMETRICS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>METRICS_DATE</id>
          <enabled>Y</enabled>
          <name>METRICS_DATE</name>
        </field>
        <field>
          <id>METRICS_CODE</id>
          <enabled>Y</enabled>
          <name>METRICS_CODE</name>
        </field>
        <field>
          <id>METRICS_DESCRIPTION</id>
          <enabled>Y</enabled>
          <name>METRICS_DESCRIPTION</name>
        </field>
        <field>
          <id>METRICS_SUBJECT</id>
          <enabled>Y</enabled>
          <name>METRICS_SUBJECT</name>
        </field>
        <field>
          <id>METRICS_TYPE</id>
          <enabled>Y</enabled>
          <name>METRICS_TYPE</name>
        </field>
        <field>
          <id>METRICS_VALUE</id>
          <enabled>Y</enabled>
          <name>METRICS_VALUE</name>
        </field>
      </metrics-log-table>
    </log>
    <maxdate>
      <connection />
      <table />
      <field />
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file />
    <capture_step_performance>Y</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
    <created_user>-</created_user>
    <created_date>2016/04/03 09:57:16.279</created_date>
    <modified_user>-</modified_user>
    <modified_date>2017/07/04 09:09:46.098</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA=</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
    <notepad>
      <note>Load the data from the source (OBO) table that will be moved to the target (PSA) table.

It is important to sort these rows chronologically (by either the "insert_id" or "inserted_on" columns) so that if this transformation
fails in the middle somewhere and if this transaction does not run in a single transaction, then next time this transformation is 
executed, we want to start again where we left off (by computing, e.g., MAX(insert_id) for the PSA table).</note>
      <xloc>272</xloc>
      <yloc>432</yloc>
      <width>765</width>
      <heigth>80</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Insert new rows into the DWH using a "Table output" step. Error handing is enabled for this step so that if a rows already exists,
the rows are passed to an "Update" step.

IMPORTANT:	A primary key constraint (or at least a "unique" constraint on the primary key column(s)) for the target table is 
				*required*; otherwise, error handling will not be triggered when attempting to insert a row with a duplicate key.

PDI does not fully support error handling when using "batch processing" with the PostgreSQL JDBC driver (a message to this 
effect is displayed when accepting the transformation settings dialog), so make sure "Use batch update for inserts" is *not* 
selected here!

See:

	/development/jeffreyz/tests/cdc_timestamps/tr_TEST_mirror_update-passage.passage-table_output

for tests  benchmark results I obtained to test the speed of varrious INSERT/UPDATE algorithms. Using a "Table output" step with 
an error handling hop to an "Update" step provides an approximately 2x speedup over an "Insert/Update" step for inserts *and* 
it does not exhibit (for inserts only) the behaviour where a "java"and "postgres" process continue to run with a high CPU load long 
after the transformation is finished.

An odd behaviour is observed when the error handling sends rows to the "Update" step. After processing a large number of rows, 
it takes a long time for this transformation to end. During this period the "Pause" and "Stop" buttons remain enabled. Furthermore,
running" top" shows that both "postgres"and "java" processes are actively using a 25-75% of the CPU. When this CPU usage stops, 
the  "Pause" and "Stop" buttons become disabled, showing that the transformation is finally finished. Strange.</note>
      <xloc>272</xloc>
      <yloc>688</yloc>
      <width>773</width>
      <heigth>332</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Get batch ID for current transformation. This will be stored in the PSA table for auditing/logging.</note>
      <xloc>272</xloc>
      <yloc>544</yloc>
      <width>576</width>
      <heigth>24</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This transformation updates the PSA mirror of a table from the source database that can receive INSERTs or UPDATES. This is a generic
algorithm that can work with *any* table,  as long as rows cannot be deleted from the source or target table, and it has the necessary 
"insert_id", "inserted_on" &amp; "last_updated_on" columns. This transformation has parameters:

	PARAM_CDC_LAST_LOAD				Timestamp for when *all* tables of the PSA were most recently updated successfully
	PARAM_CDC_CURRENT_LOAD			Used so that a consistent max timestamp is used for all ETL
	PARAM_SOURCE_SCHEMA				Schema of mirrored table
	PARAM_SOURCE_TABLE				Name of mirrored table to update
	PARAM_TARGET_SCHEMA				Name of schema containing target table to update (not currently used)
	PARAM_TARGET_TABLE					Name of target table to update (not currently used)
	PARAM_INSERT_ID_COLNAME			Name of column acting as "insert_id"  timestamp column of source table
	PARAM_INSERTED_ON_COLNAME		Name of column acting as "inserted_on" column of source table
	PARAM_LAST_UPDATED_ON_COLNAME	Name of "last_updated_on" timestamp column of source table</note>
      <xloc>0</xloc>
      <yloc>0</yloc>
      <width>795</width>
      <heigth>192</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Get the maximum value stored in the "insert_id"column of the target (PSA) DB table that will be updated by this transformation. 
This will be used to the select data from the source (OBO) DB table that was inserted since the last update. 

We could, instead, treat this by getting the maximum value the "inserted_on" column and then loading all rows from the source
table whose value of "inserted_on" is >= to this timestamp. We need to include "=" here because of the finite resolutiuon of 
timestamp values. If we used only ">", we could miss rows that were inserted *after* the last update if they received exactly the
same value as MAX(inserted_on) that was obtained here. However, this approach may process a small number of rows from 
the source table that were migrated to the target table during the last successful update (again, because timestamp values are 
not unique), but that is OK here because the algorithm used in this transformation can handle attempts to insert rows that already
exist in the target table.

Alternatively, we could eliminate this step entirely and load source (OBO) rows for: inserted_on >= PARAM_CDC_LAST_LOAD,
but this will not be as efficient for the case when we need to re-start the mirroring process after it fails for some reason. In that
case we would re-process all of the rows that were successfully mirrored during the previous run.</note>
      <xloc>272</xloc>
      <yloc>208</yloc>
      <width>766</width>
      <heigth>206</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Although this transformation has parameters whose values are used in its steps, these parameters are not passed values from
the parent transformation in the usual way this is normally done in PDI. This is because the "ETL Metadata Injection" step (which
is responsible for executing this template transformation) does not support parameter passing. Nevertheless, it appears
that the parameters that are defined for this template transformation can be used as expected. The explanation for this
behaviour *MAY* be that the references to these parameters, e.g., ${PARAM_SOURCE_TABLE}, in this transformation are
simply using the values defined for these variables in the parent transformation that contains the "ETL Metadata Injection" 
step that references this  template transformation. Fortunately, all of the parameters that are used by this transformation
are defined with the correct values in the parent transforation. I have tested this by removing the parameters entirely in 
transformation"tmplt_mirrored_insert_only_table-update-NO_PARAMS". The result was that the transformation ran as 
expected, even though it made use of the parameters that were removed.</note>
      <xloc>816</xloc>
      <yloc>0</yloc>
      <width>749</width>
      <heigth>150</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>255</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Uses "SELECT *" -></note>
      <xloc>0</xloc>
      <yloc>448</yloc>
      <width>117</width>
      <heigth>24</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>255</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Select and possibly map/rename fields (table column names), as appropriate.</note>
      <xloc>272</xloc>
      <yloc>624</yloc>
      <width>462</width>
      <heigth>24</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Metadata injected -></note>
      <xloc>0</xloc>
      <yloc>624</yloc>
      <width>130</width>
      <heigth>24</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>255</fontcolorred>
      <fontcolorgreen>255</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>0</backgroundcolorred>
      <backgroundcolorgreen>0</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Metadata injected -></note>
      <xloc>0</xloc>
      <yloc>912</yloc>
      <width>130</width>
      <heigth>24</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>255</fontcolorred>
      <fontcolorgreen>255</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>0</backgroundcolorred>
      <backgroundcolorgreen>0</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <connection>
    <name>logging_db</name>
    <server>${QF_LOGGING_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_LOGGING_DB_DATABASE}</database>
    <port>${QF_LOGGING_DB_PORT}</port>
    <username>${QF_LOGGING_DB_USERNAME}</username>
    <password>${QF_LOGGING_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_LOGGING_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>obo_db</name>
    <server>${QF_OBO_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_OBO_DB_DATABASE}</database>
    <port>${QF_OBO_DB_PORT}</port>
    <username>${QF_OBO_DB_USERNAME}</username>
    <password>${QF_OBO_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_OBO_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>psa_db</name>
    <server>${QF_PSA_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_PSA_DB_DATABASE}</database>
    <port>${QF_PSA_DB_PORT}</port>
    <username>${QF_PSA_DB_USERNAME}</username>
    <password>${QF_DWH_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_PSA_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <order>
    <hop>
      <from>Table input -  OBO.schema.table</from>
      <to>Set etl_batch_id_insert = Xform batch ID</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Get max "insert_id" for: PSA.schema.table</from>
      <to>Write to log: parameters, max_id</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Write to log: parameters, max_id</from>
      <to>Table input -  OBO.schema.table</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Set etl_batch_id_insert = Xform batch ID</from>
      <to>Map column names</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Map column names</from>
      <to>Table output - PSA.schema.table</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Table output - PSA.schema.table</from>
      <to>Set etl_batch_id_last_update = Xform batch ID</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Set etl_batch_id_last_update = Xform batch ID</from>
      <to>Update - PSA.schema.table</to>
      <enabled>Y</enabled>
    </hop>
  </order>
  <step>
    <name>Get max "insert_id" for: PSA.schema.table</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>psa_db</connection>
    <sql>SELECT
    COALESCE(MAX(${PARAM_INSERT_ID_COLNAME}), ${QF_ARCHIVE_ID_LOWER_BOUND}) AS max_id
FROM
    ${PARAM_TARGET_SCHEMA}.${PARAM_TARGET_TABLE}
</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>272</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Map column names</name>
    <type>SelectValues</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>archive_date</name>
        <rename>archive_date</rename>
      </field>
      <field>
        <name>archive_id</name>
        <rename>archive_id</rename>
      </field>
      <field>
        <name>arrival_date</name>
        <rename>arrival_date</rename>
      </field>
      <field>
        <name>avc_class_id</name>
        <rename>avc_class_id</rename>
      </field>
      <field>
        <name>charging_point_id</name>
        <rename>charging_point_id</rename>
      </field>
      <field>
        <name>completion_category_id</name>
        <rename>completion_category_id</rename>
      </field>
      <field>
        <name>completion_sub_category_id</name>
        <rename>completion_sub_category_id</rename>
      </field>
      <field>
        <name>component_id</name>
        <rename>component_id</rename>
      </field>
      <field>
        <name>etl_batch_id_insert</name>
        <rename>etl_batch_id_insert</rename>
      </field>
      <field>
        <name>etl_batch_id_last_update</name>
        <rename>etl_batch_id_last_update</rename>
      </field>
      <field>
        <name>external_passage_id</name>
        <rename>external_passage_id</rename>
      </field>
      <field>
        <name>finished_date</name>
        <rename>finished_date</rename>
      </field>
      <field>
        <name>lane_id</name>
        <rename>lane_id</rename>
      </field>
      <field>
        <name>passage_date</name>
        <rename>passage_date</rename>
      </field>
      <field>
        <name>passage_group_id</name>
        <rename>passage_group_id</rename>
      </field>
      <field>
        <name>passage_id</name>
        <rename>passage_id</rename>
      </field>
      <field>
        <name>passage_priority</name>
        <rename>passage_priority</rename>
      </field>
      <field>
        <name>passage_status_id</name>
        <rename>passage_status_id</rename>
      </field>
      <field>
        <name>passage_type_id</name>
        <rename>passage_type_id</rename>
      </field>
      <field>
        <name>pcs_rate</name>
        <rename>pcs_rate</rename>
      </field>
      <field>
        <name>propertybag</name>
        <rename>propertybag</rename>
      </field>
      <field>
        <name>sent_date</name>
        <rename>sent_date</rename>
      </field>
      <field>
        <name>service_provider_id</name>
        <rename>service_provider_id</rename>
      </field>
      <field>
        <name>vehicle_direction_id</name>
        <rename>vehicle_direction_id</rename>
      </field>
      <field>
        <name>wf_version_id</name>
        <rename>wf_version_id</rename>
      </field>
      <select_unspecified>N</select_unspecified>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>624</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Set etl_batch_id_insert = Xform batch ID</name>
    <type>SystemInfo</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>etl_batch_id_insert</name>
        <type>batch ID</type>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>544</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Set etl_batch_id_last_update = Xform batch ID</name>
    <type>SystemInfo</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>etl_batch_id_last_update</name>
        <type>batch ID</type>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>832</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Table input -  OBO.schema.table</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>obo_db</connection>
    <sql>SELECT
    *
FROM
    ${PARAM_SOURCE_SCHEMA}.${PARAM_SOURCE_TABLE}
WHERE
    (
        ${PARAM_INSERT_ID_COLNAME} > ?                                  -- newly INSERTed rows
        --${PARAM_INSERTED_ON_COLNAME} >  '${PARAM_CDC_LAST_LOAD}' AND  -- alternate possibility, instead of the previous line
        OR ${PARAM_LAST_UPDATED_ON_COLNAME} >= '${PARAM_CDC_LAST_LOAD}' -- updated rows
    )
	AND ${PARAM_INSERTED_ON_COLNAME} &lt;= '${PARAM_CDC_CURRENT_LOAD}'     -- to avoid loading rows that are inserted after the job starts
ORDER BY
    ${PARAM_INSERT_ID_COLNAME}</sql>
    <limit>0</limit>
    <lookup>Write to log: parameters, max_id</lookup>
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>448</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Table output - PSA.schema.table</name>
    <type>TableOutput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>psa_db</connection>
    <schema>${PARAM_TARGET_SCHEMA}</schema>
    <table>${PARAM_TARGET_TABLE}</table>
    <commit>1000</commit>
    <truncate>N</truncate>
    <ignore_errors>N</ignore_errors>
    <use_batch>N</use_batch>
    <specify_fields>N</specify_fields>
    <partitioning_enabled>N</partitioning_enabled>
    <partitioning_field />
    <partitioning_daily>N</partitioning_daily>
    <partitioning_monthly>Y</partitioning_monthly>
    <tablename_in_field>N</tablename_in_field>
    <tablename_field />
    <tablename_in_table>Y</tablename_in_table>
    <return_keys>N</return_keys>
    <return_field />
    <fields>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>736</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Update - PSA.schema.table</name>
    <type>Update</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>psa_db</connection>
    <skip_lookup>N</skip_lookup>
    <commit>100</commit>
    <use_batch>N</use_batch>
    <error_ignored>N</error_ignored>
    <ignore_flag_field />
    <lookup>
      <schema>${PARAM_TARGET_SCHEMA}</schema>
      <table>${PARAM_TARGET_TABLE}</table>
      <key>
        <name>passage_id</name>
        <field>passage_id</field>
        <condition>=</condition>
        <name2 />
      </key>
      <value>
        <name>arrival_date</name>
        <rename>arrival_date</rename>
      </value>
      <value>
        <name>avc_class_id</name>
        <rename>avc_class_id</rename>
      </value>
      <value>
        <name>charging_point_id</name>
        <rename>charging_point_id</rename>
      </value>
      <value>
        <name>completion_category_id</name>
        <rename>completion_category_id</rename>
      </value>
      <value>
        <name>completion_sub_category_id</name>
        <rename>completion_sub_category_id</rename>
      </value>
      <value>
        <name>component_id</name>
        <rename>component_id</rename>
      </value>
      <value>
        <name>etl_batch_id_last_update</name>
        <rename>etl_batch_id_last_update</rename>
      </value>
      <value>
        <name>external_passage_id</name>
        <rename>external_passage_id</rename>
      </value>
      <value>
        <name>finished_date</name>
        <rename>finished_date</rename>
      </value>
      <value>
        <name>lane_id</name>
        <rename>lane_id</rename>
      </value>
      <value>
        <name>passage_date</name>
        <rename>passage_date</rename>
      </value>
      <value>
        <name>passage_group_id</name>
        <rename>passage_group_id</rename>
      </value>
      <value>
        <name>passage_priority</name>
        <rename>passage_priority</rename>
      </value>
      <value>
        <name>passage_status_id</name>
        <rename>passage_status_id</rename>
      </value>
      <value>
        <name>passage_type_id</name>
        <rename>passage_type_id</rename>
      </value>
      <value>
        <name>pcs_rate</name>
        <rename>pcs_rate</rename>
      </value>
      <value>
        <name>propertybag</name>
        <rename>propertybag</rename>
      </value>
      <value>
        <name>sent_date</name>
        <rename>sent_date</rename>
      </value>
      <value>
        <name>service_provider_id</name>
        <rename>service_provider_id</rename>
      </value>
      <value>
        <name>vehicle_direction_id</name>
        <rename>vehicle_direction_id</rename>
      </value>
      <value>
        <name>wf_version_id</name>
        <rename>wf_version_id</rename>
      </value>
    </lookup>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>912</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Write to log: parameters, max_id</name>
    <type>WriteToLog</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <loglevel>log_level_basic</loglevel>
    <displayHeader>Y</displayHeader>
    <limitRows>N</limitRows>
    <limitRowsNumber>0</limitRowsNumber>
    <logmessage>tmplt_mirrored_updatable_table-update:
PARAM_CDC_LAST_LOAD    = ${PARAM_CDC_LAST_LOAD}
PARAM_CDC_CURRENT_LOAD = ${PARAM_CDC_CURRENT_LOAD}
PARAM_SOURCE_SCHEMA    = ${PARAM_SOURCE_SCHEMA}
PARAM_SOURCE_TABLE     = ${PARAM_SOURCE_TABLE}
PARAM_TARGET_SCHEMA    = ${PARAM_TARGET_SCHEMA}
PARAM_TARGET_TABLE     = ${PARAM_TARGET_TABLE}</logmessage>
    <fields>
      <field>
        <name>max_id</name>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>352</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step_error_handling>
    <error>
      <source_step>Table output - PSA.schema.table</source_step>
      <target_step>Set etl_batch_id_last_update = Xform batch ID</target_step>
      <is_enabled>Y</is_enabled>
      <nr_valuename />
      <descriptions_valuename />
      <fields_valuename />
      <codes_valuename />
      <max_errors />
      <max_pct_errors />
      <min_pct_rows />
    </error>
  </step_error_handling>
  <slave-step-copy-partition-distribution>
  </slave-step-copy-partition-distribution>
  <slave_transformation>N</slave_transformation>
</transformation>
