<job>
  <name>jb_target-populate_metadata_tables</name>
  <description />
  <extended_description />
  <job_version />
  <job_status>0</job_status>
  <directory>/generic/populate_etl_metadata_tables</directory>
  <created_user>-</created_user>
  <created_date>2016/04/03 14:57:58.609</created_date>
  <modified_user>-</modified_user>
  <modified_date>2018/03/19 14:16:11.185</modified_date>
  <parameters>
    <parameter>
      <name>PARAM_FILENAME</name>
      <default_value />
      <description>Absolute path to CSV file that will be used to populate the metadata tables</description>
    </parameter>
  </parameters>
  <connection>
    <name>logging_db</name>
    <server>${QF_LOGGING_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_LOGGING_DB_DATABASE}</database>
    <port>${QF_LOGGING_DB_PORT}</port>
    <username>${QF_LOGGING_DB_USERNAME}</username>
    <password>${QF_LOGGING_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_LOGGING_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <slaveservers>
    </slaveservers>
  <job-log-table>
    <connection>${QF_LOGGING_DB_CONNECTION}</connection>
    <schema>${QF_LOG_JOB_SCHEMA}</schema>
    <table>${QF_LOG_JOB_TABLE}</table>
    <size_limit_lines />
    <interval />
    <timeout_days>${QF_LOG_JOB_TIMEOUT_IN_DAYS}</timeout_days>
    <field>
      <id>ID_JOB</id>
      <enabled>Y</enabled>
      <name>ID_JOB</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>JOBNAME</name>
    </field>
    <field>
      <id>STATUS</id>
      <enabled>Y</enabled>
      <name>STATUS</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>STARTDATE</id>
      <enabled>Y</enabled>
      <name>STARTDATE</name>
    </field>
    <field>
      <id>ENDDATE</id>
      <enabled>Y</enabled>
      <name>ENDDATE</name>
    </field>
    <field>
      <id>LOGDATE</id>
      <enabled>Y</enabled>
      <name>LOGDATE</name>
    </field>
    <field>
      <id>DEPDATE</id>
      <enabled>Y</enabled>
      <name>DEPDATE</name>
    </field>
    <field>
      <id>REPLAYDATE</id>
      <enabled>Y</enabled>
      <name>REPLAYDATE</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>Y</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>EXECUTING_SERVER</id>
      <enabled>N</enabled>
      <name>EXECUTING_SERVER</name>
    </field>
    <field>
      <id>EXECUTING_USER</id>
      <enabled>N</enabled>
      <name>EXECUTING_USER</name>
    </field>
    <field>
      <id>START_JOB_ENTRY</id>
      <enabled>N</enabled>
      <name>START_JOB_ENTRY</name>
    </field>
    <field>
      <id>CLIENT</id>
      <enabled>N</enabled>
      <name>CLIENT</name>
    </field>
  </job-log-table>
  <jobentry-log-table>
    <connection>${QF_LOGGING_DB_CONNECTION}</connection>
    <schema>${QF_LOG_JOBENTRY_SCHEMA}</schema>
    <table>${QF_LOG_JOBENTRY_TABLE}</table>
    <timeout_days>${QF_LOG_JOBENTRY_TIMEOUT_IN_DAYS}</timeout_days>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>TRANSNAME</name>
    </field>
    <field>
      <id>JOBENTRYNAME</id>
      <enabled>Y</enabled>
      <name>STEPNAME</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>RESULT</id>
      <enabled>Y</enabled>
      <name>RESULT</name>
    </field>
    <field>
      <id>NR_RESULT_ROWS</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_ROWS</name>
    </field>
    <field>
      <id>NR_RESULT_FILES</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_FILES</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>N</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>COPY_NR</id>
      <enabled>N</enabled>
      <name>COPY_NR</name>
    </field>
  </jobentry-log-table>
  <channel-log-table>
    <connection>${QF_LOGGING_DB_CONNECTION}</connection>
    <schema>${QF_LOG_CHANNEL_SCHEMA}</schema>
    <table>${QF_LOG_CHANNEL_TABLE}</table>
    <timeout_days>${QF_LOG_CHANNEL_TIMEOUT_IN_DAYS}</timeout_days>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>LOGGING_OBJECT_TYPE</id>
      <enabled>Y</enabled>
      <name>LOGGING_OBJECT_TYPE</name>
    </field>
    <field>
      <id>OBJECT_NAME</id>
      <enabled>Y</enabled>
      <name>OBJECT_NAME</name>
    </field>
    <field>
      <id>OBJECT_COPY</id>
      <enabled>Y</enabled>
      <name>OBJECT_COPY</name>
    </field>
    <field>
      <id>REPOSITORY_DIRECTORY</id>
      <enabled>Y</enabled>
      <name>REPOSITORY_DIRECTORY</name>
    </field>
    <field>
      <id>FILENAME</id>
      <enabled>Y</enabled>
      <name>FILENAME</name>
    </field>
    <field>
      <id>OBJECT_ID</id>
      <enabled>Y</enabled>
      <name>OBJECT_ID</name>
    </field>
    <field>
      <id>OBJECT_REVISION</id>
      <enabled>Y</enabled>
      <name>OBJECT_REVISION</name>
    </field>
    <field>
      <id>PARENT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>PARENT_CHANNEL_ID</name>
    </field>
    <field>
      <id>ROOT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>ROOT_CHANNEL_ID</name>
    </field>
  </channel-log-table>
  <pass_batchid>Y</pass_batchid>
  <shared_objects_file />
  <entries>
    <entry>
      <name>START</name>
      <description />
      <type>SPECIAL</type>
      <start>Y</start>
      <dummy>N</dummy>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>144</xloc>
      <yloc>192</yloc>
    </entry>
    <entry>
      <name>jb_populate_table_meta-one_table</name>
      <description />
      <type>JOB</type>
      <specification_method>rep_name</specification_method>
      <job_object_id />
      <filename />
      <jobname>jb_populate_table_meta-one_table</jobname>
      <directory>/generic/populate_etl_metadata_tables</directory>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>Y</params_from_previous>
      <exec_per_row>Y</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name />
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
        <parameter>
          <name>PARAM_SOURCE_DB_ID</name>
          <stream_name>source_db_id</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_SOURCE_SCHEMA</name>
          <stream_name>source_schema_name</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_SOURCE_TABLE</name>
          <stream_name>source_table_name</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_TARGET_DB_ID</name>
          <stream_name>target_db_id</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_TARGET_SCHEMA</name>
          <stream_name>target_schema_name</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_TARGET_TABLE</name>
          <stream_name>target_table_name</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_SOURCE_INSERT_ID_COLNAME</name>
          <stream_name>source_insert_id_colname</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_SOURCE_LAST_UPDATED_ON_COLNAME</name>
          <stream_name>source_last_updated_on_colname</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_IS_STATIC_SUPPORT_TABLE</name>
          <stream_name>is_static_support_table</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_CAN_INSERT_ROWS</name>
          <stream_name>can_insert_rows</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_CAN_UPDATE_ROWS</name>
          <stream_name>can_update_rows</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_CAN_DELETE_ROWS</name>
          <stream_name>can_delete_rows</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_MIRROR_ALGORITHM_ID</name>
          <stream_name>mirror_algorithm_id</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_MIRROR_TABLES</name>
          <stream_name>mirror_tables</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_COMPARE_TABLES</name>
          <stream_name>compare_tables</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_MARK_ROWS_FOR_DELETION_ALGORITHM_ID</name>
          <stream_name>mark_rows_for_deletion_algorithm_id</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_DELETE_MARKED_ROWS_ALGORITHM_ID</name>
          <stream_name>delete_marked_rows_algorithm_id</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_MARK_ROWS_FOR_DELETION</name>
          <stream_name>mark_rows_for_deletion</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_DELETE_MARKED_ROWS</name>
          <stream_name>delete_marked_rows</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_ROW_CAN_BE_DELETED_FROM_SECONDS</name>
          <stream_name>row_can_be_deleted_from_seconds</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_CAN_DELETE_ROW_SCHEMA_NAME</name>
          <stream_name>can_delete_row_schema_name</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_CAN_DELETE_ROW_TABLE_NAME</name>
          <stream_name>can_delete_row_table_name</stream_name>
          <value />
        </parameter>
        <parameter>
          <name>PARAM_DELETE_MARKED_ROWS_TABLE_ORDER</name>
          <stream_name>delete_marked_rows_table_order</stream_name>
          <value />
        </parameter>
      </parameters>
      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>144</xloc>
      <yloc>416</yloc>
    </entry>
    <entry>
      <name>tr_populate_metadata_tables-get_list_of_tables</name>
      <description />
      <type>TRANS</type>
      <specification_method>rep_name</specification_method>
      <trans_object_id />
      <filename />
      <transname>tr_populate_metadata_tables-get_list_of_tables</transname>
      <directory>/generic/populate_etl_metadata_tables</directory>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>Y</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name />
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration>Pentaho local</run_configuration>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>144</xloc>
      <yloc>288</yloc>
    </entry>
  </entries>
  <hops>
    <hop>
      <from>START</from>
      <to>tr_populate_metadata_tables-get_list_of_tables</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>tr_populate_metadata_tables-get_list_of_tables</from>
      <to>jb_populate_table_meta-one_table</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>N</unconditional>
    </hop>
  </hops>
  <notepads>
    <notepad>
      <note>This job writes default rows to the tables:

	${QF_ETL_DB_SCHEMA}.table_meta
	${QF_ETL_DB_SCHEMA}.table_state
	${QF_ETL_DB_SCHEMA}.column_meta

using the initial metadata supplied by the tr_populate_metadata_tables-get_list_of_tables transformation.

This job has one parameter:

	PARAM_FILENAME	Absolute path to CSV file that will be used to populate the metadata tables</note>
      <xloc>0</xloc>
      <yloc>0</yloc>
      <width>635</width>
      <heigth>164</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Obtain a list of tables for which the table metadata will be generated, i.e.,
written to the following tables of the ETL DB:

	${QF_ETL_DB_SCHEMA}.table_meta
	${QF_ETL_DB_SCHEMA}.table_state
	${QF_ETL_DB_SCHEMA}.column_meta .

This reads the list of tables from a CSV file, but a "Data Grid" step can
also be used for custom tests or for debigging during development.</note>
      <xloc>304</xloc>
      <yloc>256</yloc>
      <width>441</width>
      <heigth>136</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This sub-job is run once for each table that is specified in
tr_populate_table_meta-list_of_hardwired_tables.</note>
      <xloc>304</xloc>
      <yloc>416</yloc>
      <width>338</width>
      <heigth>38</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>TODO?:	Consider adding parameter for an option to first delete rows from the tables:

			${QF_ETL_DB_SCHEMA}.column_meta
			${QF_ETL_DB_SCHEMA}.table_state
			${QF_ETL_DB_SCHEMA}.table_meta

		Do not use TRUNCATE". This is easier said than done. Perhaps, instead, 
		the optional behaviour can be to delete just the existing rows from these
		tables that are associated with the current table pair being treated (as we 
		iterate over all table pairs to treat). In other words, we delete:

		1.	All existing ${QF_ETL_DB_SCHEMA}.column_meta rows, if any, associate with the table pair to be treated.
		2.	One existing ${QF_ETL_DB_SCHEMA}.table_state row, if there is one, associated  with the table pair to be treated.
		3.	One existing ${QF_ETL_DB_SCHEMA}.table_meta row, if there is one, associated  with the table pair to be treated.</note>
      <xloc>672</xloc>
      <yloc>0</yloc>
      <width>707</width>
      <heigth>192</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>255</fontcolorred>
      <fontcolorgreen>255</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>0</backgroundcolorred>
      <backgroundcolorgreen>0</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <attributes>
    <group>
      <name>METASTORE.pentaho</name>
      <attribute>
        <key>Default Run Configuration</key>
        <value>{"namespace":"pentaho","id":"Default Run Configuration","name":"Default Run Configuration","description":"Defines a default run configuration","metaStoreName":null}</value>
      </attribute>
    </group>
    <group>
      <name>{"_":"Embedded MetaStore Elements","namespace":"pentaho","type":"Default Run Configuration"}</name>
      <attribute>
        <key>Pentaho local</key>
        <value>{"children":[{"children":[],"id":"server","value":null},{"children":[],"id":"clustered","value":"N"},{"children":[],"id":"name","value":"Pentaho local"},{"children":[],"id":"description","value":null},{"children":[],"id":"readOnly","value":"Y"},{"children":[],"id":"sendResources","value":"N"},{"children":[],"id":"logRemoteExecutionLocally","value":"N"},{"children":[],"id":"remote","value":"N"},{"children":[],"id":"local","value":"Y"},{"children":[],"id":"showTransformations","value":"N"}],"id":"Pentaho local","value":null,"name":"Pentaho local","owner":null,"ownerPermissionsList":[]}</value>
      </attribute>
    </group>
  </attributes>
</job>
