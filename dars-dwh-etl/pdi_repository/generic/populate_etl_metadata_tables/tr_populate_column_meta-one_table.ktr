<transformation>
  <info>
    <name>tr_populate_column_meta-one_table</name>
    <description />
    <extended_description />
    <trans_version />
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>/generic/populate_etl_metadata_tables</directory>
    <parameters>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE</name>
        <default_value>dars_dsa_db</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER</name>
        <default_value />
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_HOST</name>
        <default_value>localhost</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD</name>
        <default_value>dsa_password</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_PORT</name>
        <default_value>5432</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_URL</name>
        <default_value />
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME</name>
        <default_value>dsa_username</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_MIRROR_ALGORITHM_ID</name>
        <default_value>4</default_value>
        <description>ID of the "mirror" algorithm for archiving/mirroring rows from the source table to the target table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_DB_ID</name>
        <default_value>110</default_value>
        <description>ID the "source" database containing tables will be mirrored to a "target" database</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_INSERT_ID_COLNAME</name>
        <default_value />
        <description>Name of the source table column that acts as the "insert_id" column</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_LAST_UPDATED_ON_COLNAME</name>
        <default_value />
        <description>Name of the source table column that acts as the "last_updated_on" column</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_SCHEMA</name>
        <default_value>obo</default_value>
        <description>Name of schema containing source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_TABLE</name>
        <default_value>country</default_value>
        <description>Name of source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_TABLE_META_ID</name>
        <default_value>-666</default_value>
        <description>ID of the ${QF_ETL_DB_SCHEMA}.table_meta row that the new ${QF_ETL_DB_SCHEMA}.column_meta rows will be linked to</description>
      </parameter>
    </parameters>
    <log>
      <trans-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANS_SCHEMA}</schema>
        <table>${QF_LOG_TRANS_TABLE}</table>
        <size_limit_lines />
        <interval />
        <timeout_days>${QF_LOG_TRANS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STATUS</id>
          <enabled>Y</enabled>
          <name>STATUS</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
          <subject />
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
          <subject />
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
          <subject />
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
          <subject />
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
          <subject />
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
          <subject />
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>STARTDATE</id>
          <enabled>Y</enabled>
          <name>STARTDATE</name>
        </field>
        <field>
          <id>ENDDATE</id>
          <enabled>Y</enabled>
          <name>ENDDATE</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>DEPDATE</id>
          <enabled>Y</enabled>
          <name>DEPDATE</name>
        </field>
        <field>
          <id>REPLAYDATE</id>
          <enabled>Y</enabled>
          <name>REPLAYDATE</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>Y</enabled>
          <name>LOG_FIELD</name>
        </field>
        <field>
          <id>EXECUTING_SERVER</id>
          <enabled>N</enabled>
          <name>EXECUTING_SERVER</name>
        </field>
        <field>
          <id>EXECUTING_USER</id>
          <enabled>N</enabled>
          <name>EXECUTING_USER</name>
        </field>
        <field>
          <id>CLIENT</id>
          <enabled>N</enabled>
          <name>CLIENT</name>
        </field>
      </trans-log-table>
      <perf-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSPERF_SCHEMA}</schema>
        <table>${QF_LOG_TRANSPERF_TABLE}</table>
        <interval />
        <timeout_days>${QF_LOG_TRANSPERF_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>SEQ_NR</id>
          <enabled>Y</enabled>
          <name>SEQ_NR</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>INPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>INPUT_BUFFER_ROWS</name>
        </field>
        <field>
          <id>OUTPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>OUTPUT_BUFFER_ROWS</name>
        </field>
      </perf-log-table>
      <channel-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_CHANNEL_SCHEMA}</schema>
        <table>${QF_LOG_CHANNEL_TABLE}</table>
        <timeout_days>${QF_LOG_CHANNEL_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>LOGGING_OBJECT_TYPE</id>
          <enabled>Y</enabled>
          <name>LOGGING_OBJECT_TYPE</name>
        </field>
        <field>
          <id>OBJECT_NAME</id>
          <enabled>Y</enabled>
          <name>OBJECT_NAME</name>
        </field>
        <field>
          <id>OBJECT_COPY</id>
          <enabled>Y</enabled>
          <name>OBJECT_COPY</name>
        </field>
        <field>
          <id>REPOSITORY_DIRECTORY</id>
          <enabled>Y</enabled>
          <name>REPOSITORY_DIRECTORY</name>
        </field>
        <field>
          <id>FILENAME</id>
          <enabled>Y</enabled>
          <name>FILENAME</name>
        </field>
        <field>
          <id>OBJECT_ID</id>
          <enabled>Y</enabled>
          <name>OBJECT_ID</name>
        </field>
        <field>
          <id>OBJECT_REVISION</id>
          <enabled>Y</enabled>
          <name>OBJECT_REVISION</name>
        </field>
        <field>
          <id>PARENT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>PARENT_CHANNEL_ID</name>
        </field>
        <field>
          <id>ROOT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>ROOT_CHANNEL_ID</name>
        </field>
      </channel-log-table>
      <step-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSSTEP_SCHEMA}</schema>
        <table>${QF_LOG_TRANSSTEP_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSSTEP_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>N</enabled>
          <name>LOG_FIELD</name>
        </field>
      </step-log-table>
      <metrics-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSMETRICS_SCHEMA}</schema>
        <table>${QF_LOG_TRANSMETRICS_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSMETRICS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>METRICS_DATE</id>
          <enabled>Y</enabled>
          <name>METRICS_DATE</name>
        </field>
        <field>
          <id>METRICS_CODE</id>
          <enabled>Y</enabled>
          <name>METRICS_CODE</name>
        </field>
        <field>
          <id>METRICS_DESCRIPTION</id>
          <enabled>Y</enabled>
          <name>METRICS_DESCRIPTION</name>
        </field>
        <field>
          <id>METRICS_SUBJECT</id>
          <enabled>Y</enabled>
          <name>METRICS_SUBJECT</name>
        </field>
        <field>
          <id>METRICS_TYPE</id>
          <enabled>Y</enabled>
          <name>METRICS_TYPE</name>
        </field>
        <field>
          <id>METRICS_VALUE</id>
          <enabled>Y</enabled>
          <name>METRICS_VALUE</name>
        </field>
      </metrics-log-table>
    </log>
    <maxdate>
      <connection />
      <table />
      <field />
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file />
    <capture_step_performance>Y</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
    <created_user>-</created_user>
    <created_date>2016/04/03 09:57:16.279</created_date>
    <modified_user>-</modified_user>
    <modified_date>2018/04/12 09:01:15.919</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA=</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
    <notepad>
      <note>This transformation writes default rows to the ${QF_ETL_DB_SCHEMA}.column_meta table for a single specified table from the source database.
It is assumed that the column names in the target database will be identical to the column names in the source database. 

Therefore, this transformation writes one row to the ${QF_ETL_DB_SCHEMA}.column_meta table for every column of the specified source table.

This transformation has parameters:

	PARAM_DYN_DB_CONN_SOURCE_DB_HOST			for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_PORT			for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER		for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_URL			for source DB "dynamic" database connections
	PARAM_TABLE_META_ID							ID of the ${QF_ETL_DB_SCHEMA}.table_meta row that the new ${QF_ETL_DB_SCHEMA}.column_meta rows will be linked to
	PARAM_SOURCE_DB_ID								ID the "source" database containing the table for generating column metadata
	PARAM_SOURCE_SCHEMA							Name of schema containing source table for generating column metadata
	PARAM_SOURCE_TABLE							Name of source table for generating column metadata
	PARAM_SOURCE_INSERT_ID_COLNAME				Name of the source table column that acts as the "insert_id" column
	PARAM_SOURCE_LAST_UPDATED_ON_COLNAME	Name of the source table column that acts as the "last_updated_on" column
	PARAM_MIRROR_ALGORITHM_ID					ID of the "mirror" algorithm for archiving/mirroring rows from the source table to the target table</note>
      <xloc>16</xloc>
      <yloc>0</yloc>
      <width>1064</width>
      <heigth>304</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Append a field to the stream that contains the value of ${PARAM_TABLE_META_ID}. This is the
value of the foreign key that will link the new column_meta rows to its parent table_meta row.</note>
      <xloc>288</xloc>
      <yloc>784</yloc>
      <width>528</width>
      <heigth>36</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Get names of all columns from the specified table.</note>
      <xloc>288</xloc>
      <yloc>320</yloc>
      <width>285</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Duplicate field "source_column_name" to "target_column_name". This assumes that the column
names in the target database are identical to the column names in the source database.</note>
      <xloc>288</xloc>
      <yloc>576</yloc>
      <width>535</width>
      <heigth>36</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Add sequence field "column_meta_id_1" to the stream. This sequence starts at 1. Below, we create
a new field "column_meta_id" by adding MAX(column_meta_id) to these values.  "column_meta_id"
will hold primary key values for the new ${QF_ETL_DB_SCHEMA}.column_meta rows to insert.</note>
      <xloc>288</xloc>
      <yloc>832</yloc>
      <width>553</width>
      <heigth>49</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Add a constant field to the stream named "max_column_meta_id"
that contains the value MAX(column_meta_id). This is so that we
can compute column_meta_id values that are not  yet used for
new rows to insert into table ${QF_ETL_DB_SCHEMA}.column_meta.</note>
      <xloc>528</xloc>
      <yloc>896</yloc>
      <width>382</width>
      <heigth>62</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Add constant field "column_meta_id" to "column_meta_id_1" to create a new field "column_meta_id"
to hold primary key values for the new ${QF_ETL_DB_SCHEMA}.column_meta rows to insert.</note>
      <xloc>288</xloc>
      <yloc>976</yloc>
      <width>565</width>
      <heigth>36</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>mirror_column=Y						This assumes that all columns will be archived/mirrored
										(can be set  to N below, depending on column name)
compare_column=Y						This assumes that all columns will be compared
										(can be set  to N below, depending on column name)
is_updatable_column=N					(can be set  to Y below, depending on PARAM_MIRROR_ALGORITHM_ID)
is_insert_id_column=N					(can be set  to Y below, depending on column name)
is_inserted_on_column=N				(can be set  to Y below, depending on column name)
is_last_updated_on_column=N			(can be set  to Y below, depending on column name)
is_row_can_be_deleted_from_column=N	(can be set  to Y below, depending on column name)
is_can_delete_row_column=N				(can be set  to Y below, depending on column name)</note>
      <xloc>288</xloc>
      <yloc>624</yloc>
      <width>645</width>
      <heigth>140</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>For example:

	is_insert_id_column 			= (source_column_name = ${PARAM_SOURCE_INSERT_ID_COLNAME})
	is_last_updated_on_column	= (source_column_name = ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME})
	is_updatable_column			= ...
	...</note>
      <xloc>288</xloc>
      <yloc>1072</yloc>
      <width>637</width>
      <heigth>88</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Discard rows for source columns named:

	"etl_batch_id_insert"			and 
	"etl_batch_id_last_update" . 

"column_meta" rows should not be created for such target columns. Such target columns will be assigned *new* 
values associated with the execution of the PDI transformation when the target table is updated, i.e., the values will
*not* be copied from the source table.</note>
      <xloc>288</xloc>
      <yloc>384</yloc>
      <width>645</width>
      <heigth>114</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <connection>
    <name>etl_db</name>
    <server>${QF_ETL_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_ETL_DB_DATABASE}</database>
    <port>${QF_ETL_DB_PORT}</port>
    <username>${QF_ETL_DB_USERNAME}</username>
    <password>${QF_ETL_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_ETL_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>generic_source_db</name>
    <server>${PARAM_DYN_DB_CONN_SOURCE_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE}</database>
    <port>${PARAM_DYN_DB_CONN_SOURCE_DB_PORT}</port>
    <username>${PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME}</username>
    <password>${PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${PARAM_DYN_DB_CONN_SOURCE_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>logging_db</name>
    <server>${QF_LOGGING_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_LOGGING_DB_DATABASE}</database>
    <port>${QF_LOGGING_DB_PORT}</port>
    <username>${QF_LOGGING_DB_USERNAME}</username>
    <password>${QF_LOGGING_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_LOGGING_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <order>
    <hop>
      <from>Get Variables</from>
      <to>Add sequence - column_meta_id</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Get MAX(column_meta_id) from column_meta</from>
      <to>Join Rows (cartesian product)</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Add sequence - column_meta_id</from>
      <to>Join Rows (cartesian product)</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Join Rows (cartesian product)</from>
      <to>Create column_meta_id sequence for new rows</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Create column_meta_id sequence for new rows</from>
      <to>Remove fields no longer needed</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Add fields with constant values</from>
      <to>Get Variables</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Remove fields no longer needed</from>
      <to>Adjust column attributes based on ...</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Adjust column attributes based on ...</from>
      <to>Insert new column_meta rows</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Duplicate column name field</from>
      <to>Add fields with constant values</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Table input - Column mapping metadata</from>
      <to>etl_batch_id_insert ?</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>etl_batch_id_insert ?</from>
      <to>Dummy</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>etl_batch_id_insert ?</from>
      <to>etl_batch_id_last_update ?</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>etl_batch_id_last_update ?</from>
      <to>Duplicate column name field</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>etl_batch_id_last_update ?</from>
      <to>Dummy</to>
      <enabled>Y</enabled>
    </hop>
  </order>
  <step>
    <name>Add fields with constant values</name>
    <type>Constant</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>mirror_column</name>
        <type>Boolean</type>
        <format />
        <currency />
        <decimal />
        <group />
        <nullif>Y</nullif>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
      <field>
        <name>compare_column</name>
        <type>Boolean</type>
        <format />
        <currency />
        <decimal />
        <group />
        <nullif>Y</nullif>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
      <field>
        <name>is_updatable_column</name>
        <type>Boolean</type>
        <format />
        <currency />
        <decimal />
        <group />
        <nullif>N</nullif>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
      <field>
        <name>is_last_updated_on_column</name>
        <type>Boolean</type>
        <format />
        <currency />
        <decimal />
        <group />
        <nullif>N</nullif>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
      <field>
        <name>is_insert_id_column</name>
        <type>Boolean</type>
        <format />
        <currency />
        <decimal />
        <group />
        <nullif>N</nullif>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
      <field>
        <name>is_inserted_on_column</name>
        <type>Boolean</type>
        <format />
        <currency />
        <decimal />
        <group />
        <nullif>N</nullif>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
      <field>
        <name>is_row_can_be_deleted_from_column</name>
        <type>Boolean</type>
        <format />
        <currency />
        <decimal />
        <group />
        <nullif>N</nullif>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
      <field>
        <name>is_can_delete_row_column</name>
        <type>Boolean</type>
        <format />
        <currency />
        <decimal />
        <group />
        <nullif>N</nullif>
        <length>-1</length>
        <precision>-1</precision>
        <set_empty_string>N</set_empty_string>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>672</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Add sequence - column_meta_id</name>
    <type>Sequence</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <valuename>column_meta_id_1</valuename>
    <use_database>N</use_database>
    <connection>etl_db</connection>
    <schema>${QF_ETL_DB_SCHEMA}</schema>
    <seqname>column_meta_column_meta_id_seq</seqname>
    <use_counter>Y</use_counter>
    <counter_name />
    <start_at>1</start_at>
    <increment_by>1</increment_by>
    <max_value>999999999</max_value>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>848</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Adjust column attributes based on ...</name>
    <type>ScriptValueMod</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <compatible>N</compatible>
    <optimizationLevel>9</optimizationLevel>
    <jsScripts>
      <jsScript>
        <jsScript_type>0</jsScript_type>
        <jsScript_name>Script 1</jsScript_name>
        <jsScript_script>/*
  This script is run once for each row in the stream, i.e., once
  per ${QF_ETL_DB_SCHEMA}.column_meta row to create.

  Author:  Jeffrey Zelt
  Date:    2017.08.10
  Changes: Initial version
*/

var source_table_name = getVariable("PARAM_SOURCE_TABLE", "");
var mirror_algorithm_id = getVariable("PARAM_MIRROR_ALGORITHM_ID", 0);

//Alert("PARAM_SOURCE_TABLE, PARAM_MIRROR_ALGORITHM_ID = " + source_table_name + ", " + mirror_algorithm_id);

/*
  Since all of the fields that are set here have:
      "Replace value 'Fieldname' or 'Rename to'" = Y
  below, it is necessary to explicitly set each field here;
  otherwise, it will be set to &lt;null> even if the field 
  currently has a non-null value.

  First, we set default values for cases not treated below.
  These assignments cannot simply be moved to the "else" block
  because then not all of the fields will get set for the cases
  explicitly treated here.
*/
mirror_column = true;
is_updatable_column = false;
compare_column = true;
is_insert_id_column = false;
is_inserted_on_column = false;
is_last_updated_on_column = false;
is_row_can_be_deleted_from_column = false;
is_can_delete_row_column = false;

/*
  It should not matter if we test the value of source_columnn_name or
  target_column_name, since at this point, they will necessarily be
  identical. It is conceivable that this could change in the future.
*/
if(getVariable("PARAM_SOURCE_INSERT_ID_COLNAME", "").equals(source_column_name)) {
    is_insert_id_column = true;
} else if(getVariable("PARAM_SOURCE_LAST_UPDATED_ON_COLNAME", "").equals(source_column_name)) {
    is_last_updated_on_column = true;
}

/*
  Set is_updatable_column=true if any of the "updateable" mirror/update
  algorithms have been specified for the table. Currently, these are algorithms
  2 &amp; 5. This is done for all columns of the table *except" for primary key 
  columns, because it/they can never be updateable.
*/
if(getVariable("QF_MIRROR_ALG_INSERT_OR_UPDATE_GENERIC_1", 0).equals(mirror_algorithm_id) || 
   getVariable("QF_MIRROR_ALG_INSERT_OR_UPDATE_GENERIC_2", 0).equals(mirror_algorithm_id) || 
   getVariable("QF_MIRROR_ALG_INSERT_OR_UPDATE_GENERIC_3", 0).equals(mirror_algorithm_id) || 
   getVariable("QF_MIRROR_ALG_COMPARE_GENERIC", 0).equals(mirror_algorithm_id)) {
    if(is_primary_key_column == false) {
        is_updatable_column = true;
    }
}

/*
  Adjustments for columns that have "special" names. Most of this should
  eventually be eliminated and replaced with code that cehcks for special
  column names that are specified in the metadata loaded at the start of 
  the root job.
*/
//if(source_column_name == "etl_batch_id_insert" || source_column_name == "etl_batch_id_last_update") {
//	/*
//      This case occurs when a source table is itself a target table, e.g.,
//      an "obo" table of the PSA, which is a target table for a table in the
//      "obo_opr" database, and at the same time it is a source table for a
//      table in the DSA database. In this case the target columns will be 
//      assigned *new* values associated with the execution of the PDI 
//      transformation when the target table is updated, i.e., the values will 
//      *not* be copied from the source table. In addition, although the target 
//      table may have an 'etl_batch_id_insert'  or 'etl_batch_id_last_update' 
//      column, no column_meta rows should be created for them. Hence, perhaps 
//      an even better way to treat this case is to never create column_meta 
//      rows for them in the first place. This can be done by introducing a
//      "Filter Rows" step into this trnasformation. If this is doen, this "if"
//      block can be removed.
//    */
//    mirror_column = false;
//    is_updatable_column = false;
//    compare_column = false;
//} else if(target_column_name == "inserted_on" || target_column_name == "archive_date") {     // We could also test for other names here
//    is_inserted_on_column = true;
//} else 
if(target_column_name == "row_can_be_deleted_from") { // We could also test for other names here
    is_row_can_be_deleted_from_column = true;
} else if(target_column_name == "can_delete_row") { // We could also test for other names here
    is_can_delete_row_column = true;
    mirror_column = false;
    compare_column = false;
} else { 
    //Alert("Default case: target_column_name = " + target_column_name);
}
</jsScript_script>
      </jsScript>
    </jsScripts>
    <fields>
      <field>
        <name>mirror_column</name>
        <rename>mirror_column</rename>
        <type>Boolean</type>
        <length>-1</length>
        <precision>-1</precision>
        <replace>Y</replace>
      </field>
      <field>
        <name>is_updatable_column</name>
        <rename>is_updatable_column</rename>
        <type>Boolean</type>
        <length>-1</length>
        <precision>-1</precision>
        <replace>Y</replace>
      </field>
      <field>
        <name>compare_column</name>
        <rename>compare_column</rename>
        <type>Boolean</type>
        <length>-1</length>
        <precision>-1</precision>
        <replace>Y</replace>
      </field>
      <field>
        <name>is_insert_id_column</name>
        <rename>is_insert_id_column</rename>
        <type>Boolean</type>
        <length>-1</length>
        <precision>-1</precision>
        <replace>Y</replace>
      </field>
      <field>
        <name>is_inserted_on_column</name>
        <rename>is_inserted_on_column</rename>
        <type>Boolean</type>
        <length>-1</length>
        <precision>-1</precision>
        <replace>Y</replace>
      </field>
      <field>
        <name>is_last_updated_on_column</name>
        <rename>is_last_updated_on_column</rename>
        <type>Boolean</type>
        <length>-1</length>
        <precision>-1</precision>
        <replace>Y</replace>
      </field>
      <field>
        <name>is_row_can_be_deleted_from_column</name>
        <rename>is_row_can_be_deleted_from_column</rename>
        <type>Boolean</type>
        <length>-1</length>
        <precision>-1</precision>
        <replace>Y</replace>
      </field>
      <field>
        <name>is_can_delete_row_column</name>
        <rename>is_can_delete_row_column</rename>
        <type>Boolean</type>
        <length>-1</length>
        <precision>-1</precision>
        <replace>Y</replace>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>1104</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Create column_meta_id sequence for new rows</name>
    <type>Calculator</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <calculation>
      <field_name>column_meta_id</field_name>
      <calc_type>ADD</calc_type>
      <field_a>column_meta_id_1</field_a>
      <field_b>max_column_meta_id</field_b>
      <field_c />
      <value_type>Integer</value_type>
      <value_length>-1</value_length>
      <value_precision>-1</value_precision>
      <remove>N</remove>
      <conversion_mask />
      <decimal_symbol />
      <grouping_symbol />
      <currency_symbol />
    </calculation>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>976</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Dummy</name>
    <type>Dummy</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>16</xloc>
      <yloc>384</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Duplicate column name field</name>
    <type>SelectValues</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>source_column_name</name>
      </field>
      <field>
        <name>source_column_name</name>
        <rename>target_column_name</rename>
      </field>
      <field>
        <name>is_primary_key_column</name>
      </field>
      <field>
        <name>primary_key_column_order</name>
      </field>
      <select_unspecified>N</select_unspecified>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>576</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Get MAX(column_meta_id) from column_meta</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>etl_db</connection>
    <sql>SELECT 
    -- COALESCE used in case the table is empty.
    COALESCE(MAX(column_meta_id), 0) AS "max_column_meta_id" 
FROM 
    ${QF_ETL_DB_SCHEMA}.column_meta</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>368</xloc>
      <yloc>912</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Get Variables</name>
    <type>GetVariable</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>table_meta_id</name>
        <variable>${PARAM_TABLE_META_ID}</variable>
        <type>Integer</type>
        <format />
        <currency />
        <decimal />
        <group />
        <length>-1</length>
        <precision>-1</precision>
        <trim_type>none</trim_type>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>784</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Insert new column_meta rows</name>
    <type>TableOutput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>etl_db</connection>
    <schema>${QF_ETL_DB_SCHEMA}</schema>
    <table>column_meta</table>
    <commit>1000</commit>
    <truncate>N</truncate>
    <ignore_errors>N</ignore_errors>
    <use_batch>Y</use_batch>
    <specify_fields>N</specify_fields>
    <partitioning_enabled>N</partitioning_enabled>
    <partitioning_field />
    <partitioning_daily>N</partitioning_daily>
    <partitioning_monthly>Y</partitioning_monthly>
    <tablename_in_field>N</tablename_in_field>
    <tablename_field />
    <tablename_in_table>Y</tablename_in_table>
    <return_keys>N</return_keys>
    <return_field />
    <fields>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>1168</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Join Rows (cartesian product)</name>
    <type>JoinRows</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <directory>%%java.io.tmpdir%%</directory>
    <prefix>out</prefix>
    <cache_size>500</cache_size>
    <main>Add sequence - column_meta_id</main>
    <compare>
      <condition>
        <negated>N</negated>
        <leftvalue />
        <function>=</function>
        <rightvalue />
      </condition>
    </compare>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>912</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Remove fields no longer needed</name>
    <type>SelectValues</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <select_unspecified>N</select_unspecified>
      <remove>
        <name>column_meta_id_1</name>
      </remove>
      <remove>
        <name>max_column_meta_id</name>
      </remove>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>1040</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Table input - Column mapping metadata</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>generic_source_db</connection>
    <sql>SELECT 
    c.column_name                    AS "source_column_name",
    kcu.ordinal_position IS NOT NULL AS "is_primary_key_column",
    kcu.ordinal_position             AS "primary_key_column_order"
--    -- This column will be "true" if the specified table has a column
--    -- named "xxxxxxxx".
--    EXISTS (
--        SELECT * FROM information_schema.columns 
--        WHERE table_schema='ssssssss' AND table_name='tttttttt' AND column_name='xxxxxxxx'
--    ) AS "exists_xxxxxxxx_column"
FROM 
    information_schema.columns c
-- These two left outer joins are for determining which column(s) make up the 
-- primary key for the table as well as their order, which is an issue if the
-- primary key is a composite key that consists of more than a single column.
LEFT OUTER JOIN
    information_schema.table_constraints AS tc ON 
        tc.table_schema    = c.table_schema  AND 
        tc.table_name      = c.table_name    AND
        tc.constraint_type = 'PRIMARY KEY'
LEFT OUTER JOIN
    information_schema.key_column_usage AS kcu ON 
        kcu.table_schema    = c.table_schema AND 
        kcu.table_name      = c.table_name   AND
        kcu.column_name     = c.column_name  AND
        kcu.constraint_name = tc.constraint_name 
WHERE
	c.table_schema = '${PARAM_SOURCE_SCHEMA}' AND 
    c.table_name = '${PARAM_SOURCE_TABLE}'
ORDER BY 
    c.ordinal_position</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>320</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>etl_batch_id_insert ?</name>
    <type>FilterRows</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <send_true_to>Dummy</send_true_to>
    <send_false_to>etl_batch_id_last_update ?</send_false_to>
    <compare>
      <condition>
        <negated>N</negated>
        <leftvalue>source_column_name</leftvalue>
        <function>=</function>
        <rightvalue />
        <value>
          <name>constant</name>
          <type>String</type>
          <text>etl_batch_id_insert</text>
          <length>-1</length>
          <precision>-1</precision>
          <isnull>N</isnull>
          <mask />
        </value>
      </condition>
    </compare>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>384</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>etl_batch_id_last_update ?</name>
    <type>FilterRows</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <send_true_to>Dummy</send_true_to>
    <send_false_to>Duplicate column name field</send_false_to>
    <compare>
      <condition>
        <negated>N</negated>
        <leftvalue>source_column_name</leftvalue>
        <function>=</function>
        <rightvalue />
        <value>
          <name>constant</name>
          <type>String</type>
          <text>etl_batch_id_last_update</text>
          <length>-1</length>
          <precision>-1</precision>
          <isnull>N</isnull>
          <mask />
        </value>
      </condition>
    </compare>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>128</xloc>
      <yloc>480</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step_error_handling>
  </step_error_handling>
  <slave-step-copy-partition-distribution>
  </slave-step-copy-partition-distribution>
  <slave_transformation>N</slave_transformation>
</transformation>
