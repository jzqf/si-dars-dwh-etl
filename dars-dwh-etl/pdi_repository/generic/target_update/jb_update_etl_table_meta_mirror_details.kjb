<job>
  <name>jb_update_etl_table_meta_mirror_details</name>
  <description />
  <extended_description />
  <job_version />
  <job_status>0</job_status>
  <directory>/generic/target_update</directory>
  <created_user>-</created_user>
  <created_date>2016/04/03 14:57:58.609</created_date>
  <modified_user>-</modified_user>
  <modified_date>2018/05/28 13:17:00.703</modified_date>
  <parameters>
    <parameter>
      <name>PARAM_DYN_DB_CONN_TARGET_DB_DATABASE</name>
      <default_value />
      <description>for target DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_TARGET_DB_DRIVER</name>
      <default_value />
      <description>for target DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_TARGET_DB_HOST</name>
      <default_value />
      <description>for target DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD</name>
      <default_value />
      <description>for target DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_TARGET_DB_PORT</name>
      <default_value />
      <description>for target DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_TARGET_DB_URL</name>
      <default_value />
      <description>for target DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_DYN_DB_CONN_TARGET_DB_USERNAME</name>
      <default_value />
      <description>for target DB "dynamic" database connections</description>
    </parameter>
    <parameter>
      <name>PARAM_TABLE_META_ID</name>
      <default_value>0</default_value>
      <description>Primary key of ${QF_ETL_DB_SCHEMA}.table_meta row for "source" table archived/mirrored to "target" table</description>
    </parameter>
    <parameter>
      <name>PARAM_TABLE_MIRROR_ALGORITHM_ID</name>
      <default_value>0</default_value>
      <description>ID that specifies the algorithm to use for mirroring the table</description>
    </parameter>
    <parameter>
      <name>PARAM_TARGET_SCHEMA</name>
      <default_value>passage</default_value>
      <description>Name of schema containing target table to update</description>
    </parameter>
    <parameter>
      <name>PARAM_TARGET_TABLE</name>
      <default_value>passage</default_value>
      <description>Name of target table to update</description>
    </parameter>
    <parameter>
      <name>PARAM_UPDATE_TABLE_NUM_INSERTS</name>
      <default_value />
      <description>Number of rows inserted into the target table by the ETL job</description>
    </parameter>
    <parameter>
      <name>PARAM_UPDATE_TABLE_NUM_ROWS</name>
      <default_value />
      <description>Number of rows processed by the ETL job (in case this number cannot be broken down into inserts &amp; updates)</description>
    </parameter>
    <parameter>
      <name>PARAM_UPDATE_TABLE_NUM_UPDATES</name>
      <default_value />
      <description>Number of rows of the target table updated by the ETL job</description>
    </parameter>
    <parameter>
      <name>PARAM_UPDATE_TABLE_START_MILLISECONDS</name>
      <default_value />
      <description>Timer start value for updating a table</description>
    </parameter>
  </parameters>
  <connection>
    <name>etl_db</name>
    <server>${QF_ETL_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_ETL_DB_DATABASE}</database>
    <port>${QF_ETL_DB_PORT}</port>
    <username>${QF_ETL_DB_USERNAME}</username>
    <password>${QF_ETL_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_ETL_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>logging_db</name>
    <server>${QF_LOGGING_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_LOGGING_DB_DATABASE}</database>
    <port>${QF_LOGGING_DB_PORT}</port>
    <username>${QF_LOGGING_DB_USERNAME}</username>
    <password>${QF_LOGGING_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_LOGGING_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <slaveservers>
    </slaveservers>
  <job-log-table>
    <connection>${QF_LOGGING_DB_CONNECTION}</connection>
    <schema>${QF_LOG_JOB_SCHEMA}</schema>
    <table>${QF_LOG_JOB_TABLE}</table>
    <size_limit_lines />
    <interval />
    <timeout_days>${QF_LOG_JOB_TIMEOUT_IN_DAYS}</timeout_days>
    <field>
      <id>ID_JOB</id>
      <enabled>Y</enabled>
      <name>ID_JOB</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>JOBNAME</name>
    </field>
    <field>
      <id>STATUS</id>
      <enabled>Y</enabled>
      <name>STATUS</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>STARTDATE</id>
      <enabled>Y</enabled>
      <name>STARTDATE</name>
    </field>
    <field>
      <id>ENDDATE</id>
      <enabled>Y</enabled>
      <name>ENDDATE</name>
    </field>
    <field>
      <id>LOGDATE</id>
      <enabled>Y</enabled>
      <name>LOGDATE</name>
    </field>
    <field>
      <id>DEPDATE</id>
      <enabled>Y</enabled>
      <name>DEPDATE</name>
    </field>
    <field>
      <id>REPLAYDATE</id>
      <enabled>Y</enabled>
      <name>REPLAYDATE</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>Y</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>EXECUTING_SERVER</id>
      <enabled>N</enabled>
      <name>EXECUTING_SERVER</name>
    </field>
    <field>
      <id>EXECUTING_USER</id>
      <enabled>N</enabled>
      <name>EXECUTING_USER</name>
    </field>
    <field>
      <id>START_JOB_ENTRY</id>
      <enabled>N</enabled>
      <name>START_JOB_ENTRY</name>
    </field>
    <field>
      <id>CLIENT</id>
      <enabled>N</enabled>
      <name>CLIENT</name>
    </field>
  </job-log-table>
  <jobentry-log-table>
    <connection>${QF_LOGGING_DB_CONNECTION}</connection>
    <schema>${QF_LOG_JOBENTRY_SCHEMA}</schema>
    <table>${QF_LOG_JOBENTRY_TABLE}</table>
    <timeout_days>${QF_LOG_JOBENTRY_TIMEOUT_IN_DAYS}</timeout_days>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>JOBNAME</id>
      <enabled>Y</enabled>
      <name>TRANSNAME</name>
    </field>
    <field>
      <id>JOBENTRYNAME</id>
      <enabled>Y</enabled>
      <name>STEPNAME</name>
    </field>
    <field>
      <id>LINES_READ</id>
      <enabled>Y</enabled>
      <name>LINES_READ</name>
    </field>
    <field>
      <id>LINES_WRITTEN</id>
      <enabled>Y</enabled>
      <name>LINES_WRITTEN</name>
    </field>
    <field>
      <id>LINES_UPDATED</id>
      <enabled>Y</enabled>
      <name>LINES_UPDATED</name>
    </field>
    <field>
      <id>LINES_INPUT</id>
      <enabled>Y</enabled>
      <name>LINES_INPUT</name>
    </field>
    <field>
      <id>LINES_OUTPUT</id>
      <enabled>Y</enabled>
      <name>LINES_OUTPUT</name>
    </field>
    <field>
      <id>LINES_REJECTED</id>
      <enabled>Y</enabled>
      <name>LINES_REJECTED</name>
    </field>
    <field>
      <id>ERRORS</id>
      <enabled>Y</enabled>
      <name>ERRORS</name>
    </field>
    <field>
      <id>RESULT</id>
      <enabled>Y</enabled>
      <name>RESULT</name>
    </field>
    <field>
      <id>NR_RESULT_ROWS</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_ROWS</name>
    </field>
    <field>
      <id>NR_RESULT_FILES</id>
      <enabled>Y</enabled>
      <name>NR_RESULT_FILES</name>
    </field>
    <field>
      <id>LOG_FIELD</id>
      <enabled>N</enabled>
      <name>LOG_FIELD</name>
    </field>
    <field>
      <id>COPY_NR</id>
      <enabled>N</enabled>
      <name>COPY_NR</name>
    </field>
  </jobentry-log-table>
  <channel-log-table>
    <connection>${QF_LOGGING_DB_CONNECTION}</connection>
    <schema>${QF_LOG_CHANNEL_SCHEMA}</schema>
    <table>${QF_LOG_CHANNEL_TABLE}</table>
    <timeout_days>${QF_LOG_CHANNEL_TIMEOUT_IN_DAYS}</timeout_days>
    <field>
      <id>ID_BATCH</id>
      <enabled>Y</enabled>
      <name>ID_BATCH</name>
    </field>
    <field>
      <id>CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>CHANNEL_ID</name>
    </field>
    <field>
      <id>LOG_DATE</id>
      <enabled>Y</enabled>
      <name>LOG_DATE</name>
    </field>
    <field>
      <id>LOGGING_OBJECT_TYPE</id>
      <enabled>Y</enabled>
      <name>LOGGING_OBJECT_TYPE</name>
    </field>
    <field>
      <id>OBJECT_NAME</id>
      <enabled>Y</enabled>
      <name>OBJECT_NAME</name>
    </field>
    <field>
      <id>OBJECT_COPY</id>
      <enabled>Y</enabled>
      <name>OBJECT_COPY</name>
    </field>
    <field>
      <id>REPOSITORY_DIRECTORY</id>
      <enabled>Y</enabled>
      <name>REPOSITORY_DIRECTORY</name>
    </field>
    <field>
      <id>FILENAME</id>
      <enabled>Y</enabled>
      <name>FILENAME</name>
    </field>
    <field>
      <id>OBJECT_ID</id>
      <enabled>Y</enabled>
      <name>OBJECT_ID</name>
    </field>
    <field>
      <id>OBJECT_REVISION</id>
      <enabled>Y</enabled>
      <name>OBJECT_REVISION</name>
    </field>
    <field>
      <id>PARENT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>PARENT_CHANNEL_ID</name>
    </field>
    <field>
      <id>ROOT_CHANNEL_ID</id>
      <enabled>Y</enabled>
      <name>ROOT_CHANNEL_ID</name>
    </field>
  </channel-log-table>
  <pass_batchid>Y</pass_batchid>
  <shared_objects_file />
  <entries>
    <entry>
      <name>START</name>
      <description />
      <type>SPECIAL</type>
      <start>Y</start>
      <dummy>N</dummy>
      <repeat>N</repeat>
      <schedulerType>0</schedulerType>
      <intervalSeconds>0</intervalSeconds>
      <intervalMinutes>60</intervalMinutes>
      <hour>12</hour>
      <minutes>0</minutes>
      <weekDay>1</weekDay>
      <DayOfMonth>1</DayOfMonth>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>32</xloc>
      <yloc>272</yloc>
    </entry>
    <entry>
      <name>Update details stored in table_state row</name>
      <description />
      <type>SQL</type>
      <sql>UPDATE
    ${QF_ETL_DB_SCHEMA}.table_state
SET
    mirror_last_updated_algorithm_id = ${PARAM_TABLE_MIRROR_ALGORITHM_ID},
    mirror_last_updated_on           = LOCALTIMESTAMP,    -- TODO: Shall I use UTC/GMT here?
    -- Values that are not set here should be SQL NULL, but it is possible that this is not so. If this occurs,
    -- I may have to check for a guard value and then use NULLIF(&lt;update value>, &lt;guard value>).
    mirror_last_updated_elapsed_time_millis        = ${QF_UPDATE_TABLE_ELAPSED_MILLISECONDS},
    mirror_last_updated_num_rows_processed         = ${PARAM_UPDATE_TABLE_NUM_ROWS},
    mirror_last_updated_num_inserts                = ${PARAM_UPDATE_TABLE_NUM_INSERTS},
    mirror_last_updated_num_updates                = ${PARAM_UPDATE_TABLE_NUM_UPDATES},
    mirror_last_updated_num_rows_processed_per_sec = ${QF_UPDATE_TABLE_ROWS_PER_SEC}

WHERE
    table_state_id = ${PARAM_TABLE_META_ID}</sql>
      <useVariableSubstitution>T</useVariableSubstitution>
      <sqlfromfile>F</sqlfromfile>
      <sqlfilename />
      <sendOneStatement>F</sendOneStatement>
      <connection>etl_db</connection>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>128</xloc>
      <yloc>560</yloc>
    </entry>
    <entry>
      <name>Log - Parameters</name>
      <description />
      <type>WRITE_TO_LOG</type>
      <logmessage>jb_update_etl_table_meta_mirror_details:
PARAM_TABLE_META_ID                   = ${PARAM_TABLE_META_ID}
PARAM_TARGET_SCHEMA                   = ${PARAM_TARGET_SCHEMA}
PARAM_TARGET_TABLE                    = ${PARAM_TARGET_TABLE}
PARAM_TABLE_MIRROR_ALGORITHM_ID       = ${PARAM_TABLE_MIRROR_ALGORITHM_ID}
PARAM_UPDATE_TABLE_START_MILLISECONDS = ${PARAM_UPDATE_TABLE_START_MILLISECONDS}
PARAM_UPDATE_TABLE_NUM_ROWS           = ${PARAM_UPDATE_TABLE_NUM_ROWS}
PARAM_UPDATE_TABLE_NUM_INSERTS        = ${PARAM_UPDATE_TABLE_NUM_INSERTS}
PARAM_UPDATE_TABLE_NUM_UPDATES        = ${PARAM_UPDATE_TABLE_NUM_UPDATES}</logmessage>
      <loglevel>Basic</loglevel>
      <logsubject>jb_update_etl_table_meta_mirror_details parameters</logsubject>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>128</xloc>
      <yloc>272</yloc>
    </entry>
    <entry>
      <name>jb_log_error</name>
      <description />
      <type>JOB</type>
      <specification_method>rep_name</specification_method>
      <job_object_id />
      <filename />
      <jobname>jb_log_error</jobname>
      <directory>/generic</directory>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Nothing</loglevel>
      <slave_server_name />
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <expand_remote_job>N</expand_remote_job>
      <create_parent_folder>N</create_parent_folder>
      <pass_export>N</pass_export>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
        <parameter>
          <name>PARAM_ERROR_MESSAGE</name>
          <stream_name />
          <value>Error updating table_meta details in ${Internal.Job.Name} for target table: ${PARAM_TARGET_SCHEMA}.${PARAM_TARGET_TABLE}</value>
        </parameter>
      </parameters>
      <set_append_logfile>N</set_append_logfile>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>1</nr>
      <xloc>128</xloc>
      <yloc>656</yloc>
    </entry>
    <entry>
      <name>Abort job</name>
      <description />
      <type>ABORT</type>
      <message>Aborting ${Internal.Job.Name}</message>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>128</xloc>
      <yloc>752</yloc>
    </entry>
    <entry>
      <name>tr_table_update_statistics_compute</name>
      <description />
      <type>TRANS</type>
      <specification_method>rep_name</specification_method>
      <trans_object_id />
      <filename />
      <transname>tr_table_update_statistics_compute</transname>
      <directory>${Internal.Entry.Current.Directory}</directory>
      <arg_from_previous>N</arg_from_previous>
      <params_from_previous>N</params_from_previous>
      <exec_per_row>N</exec_per_row>
      <clear_rows>N</clear_rows>
      <clear_files>N</clear_files>
      <set_logfile>N</set_logfile>
      <logfile />
      <logext />
      <add_date>N</add_date>
      <add_time>N</add_time>
      <loglevel>Basic</loglevel>
      <cluster>N</cluster>
      <slave_server_name />
      <set_append_logfile>N</set_append_logfile>
      <wait_until_finished>Y</wait_until_finished>
      <follow_abort_remote>N</follow_abort_remote>
      <create_parent_folder>N</create_parent_folder>
      <logging_remote_work>N</logging_remote_work>
      <run_configuration>Pentaho local</run_configuration>
      <parameters>
        <pass_all_parameters>Y</pass_all_parameters>
      </parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>128</xloc>
      <yloc>368</yloc>
    </entry>
    <entry>
      <name>Write To Log</name>
      <description />
      <type>WRITE_TO_LOG</type>
      <logmessage>${Internal.Job.Name}:
PARAM_TABLE_META_ID                   = ${PARAM_TABLE_META_ID}
PARAM_TARGET_SCHEMA                   = ${PARAM_TARGET_SCHEMA}
PARAM_TARGET_TABLE                    = ${PARAM_TARGET_TABLE}
PARAM_TABLE_MIRROR_ALGORITHM_ID       = ${PARAM_TABLE_MIRROR_ALGORITHM_ID}
PARAM_UPDATE_TABLE_START_MILLISECONDS = ${PARAM_UPDATE_TABLE_START_MILLISECONDS}
PARAM_UPDATE_TABLE_NUM_ROWS           = ${PARAM_UPDATE_TABLE_NUM_ROWS}
PARAM_UPDATE_TABLE_NUM_INSERTS        = ${PARAM_UPDATE_TABLE_NUM_INSERTS}
PARAM_UPDATE_TABLE_NUM_UPDATES        = ${PARAM_UPDATE_TABLE_NUM_UPDATES}
QF_UPDATE_TABLE_ELAPSED_MILLISECONDS  = ${QF_UPDATE_TABLE_ELAPSED_MILLISECONDS}
QF_UPDATE_TABLE_ROWS_PER_SEC          = ${QF_UPDATE_TABLE_ROWS_PER_SEC}</logmessage>
      <loglevel>Minimal</loglevel>
      <logsubject />
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>128</xloc>
      <yloc>464</yloc>
    </entry>
  </entries>
  <hops>
    <hop>
      <from>Update details stored in table_state row</from>
      <to>jb_log_error</to>
      <from_nr>0</from_nr>
      <to_nr>1</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>N</unconditional>
    </hop>
    <hop>
      <from>jb_log_error</from>
      <to>Abort job</to>
      <from_nr>1</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>START</from>
      <to>Log - Parameters</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Log - Parameters</from>
      <to>tr_table_update_statistics_compute</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>tr_table_update_statistics_compute</from>
      <to>Write To Log</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>Y</evaluation>
      <unconditional>Y</unconditional>
    </hop>
    <hop>
      <from>Write To Log</from>
      <to>Update details stored in table_state row</to>
      <from_nr>0</from_nr>
      <to_nr>0</to_nr>
      <enabled>Y</enabled>
      <evaluation>N</evaluation>
      <unconditional>Y</unconditional>
    </hop>
  </hops>
  <notepads>
    <notepad>
      <note>This job updates a row of the ${QF_ETL_DB_SCHEMA}.table_state table after a table has been updated in the target DB from a table in
a source database. This job has parameters:

	PARAM_DYN_DB_CONN_TARGET_DB_HOST		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_PORT		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_DATABASE	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_USERNAME	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_DRIVER		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_URL			for target DB "dynamic" database connections
	PARAM_TABLE_META_ID							Primary key of ${QF_ETL_DB_SCHEMA}.table_meta/state row for "source" table archived/mirrored to "target" table
	PARAM_TARGET_SCHEMA						Name of schema containing target table to update (not currently used)
	PARAM_TARGET_TABLE							Name of target table to update (not currently used)
	PARAM_TABLE_MIRROR_ALGORITHM_ID			ID that specifies the algorithm to use for archiving/mirroring the table
	PARAM_UPDATE_TABLE_START_MILLISECONDS		Timer start value for updating a table
	PARAM_UPDATE_TABLE_NUM_ROWS				Number of rows processed by the ETL job (in case this number cannot be broken down into inserts &amp; updates)
	PARAM_UPDATE_TABLE_NUM_INSERTS			Number of rows inserted into the target table by the ETL job
	PARAM_UPDATE_TABLE_NUM_UPDATES			Number of rows of the target table updated by the ETL job</note>
      <xloc>0</xloc>
      <yloc>0</yloc>
      <width>956</width>
      <heigth>244</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This "Abort" is needed so that the the 
root calling job will know that 
execution has failed. It will then direct
the execution flow to the job that 
sends out failure e-mails.</note>
      <xloc>256</xloc>
      <yloc>720</yloc>
      <width>232</width>
      <heigth>80</heigth>
      <fontname />
      <fontsize>-1</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Compute the "update statistics" for the specified table that was just updated. This transformation sets the PDI variables:

	QF_UPDATE_TABLE_ELAPSED_MILLISECONDS
	QF_UPDATE_TABLE_ROWS_PER_SEC
	QF_UPDATE_TABLE_INSERTS_PER_SEC		&lt;- No, I do not compute this
	QF_UPDATE_TABLE_UPDATES_PER_SEC	&lt;- No, I do not compute this</note>
      <xloc>256</xloc>
      <yloc>336</yloc>
      <width>669</width>
      <heigth>88</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Log the values assigned to the PDI variables:

	QF_UPDATE_TABLE_ELAPSED_MILLISECONDS
	QF_UPDATE_TABLE_ROWS_PER_SEC
	QF_UPDATE_TABLE_INSERTS_PER_SEC		&lt;- No
	QF_UPDATE_TABLE_UPDATES_PER_SEC	&lt;- No</note>
      <xloc>256</xloc>
      <yloc>448</yloc>
      <width>304</width>
      <heigth>88</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <attributes>
    <group>
      <name>METASTORE.pentaho</name>
      <attribute>
        <key>Default Run Configuration</key>
        <value>{"namespace":"pentaho","id":"Default Run Configuration","name":"Default Run Configuration","description":"Defines a default run configuration","metaStoreName":null}</value>
      </attribute>
    </group>
    <group>
      <name>{"_":"Embedded MetaStore Elements","namespace":"pentaho","type":"Default Run Configuration"}</name>
      <attribute>
        <key>Pentaho local</key>
        <value>{"children":[{"children":[],"id":"server","value":null},{"children":[],"id":"clustered","value":"N"},{"children":[],"id":"name","value":"Pentaho local"},{"children":[],"id":"description","value":null},{"children":[],"id":"readOnly","value":"Y"},{"children":[],"id":"sendResources","value":"N"},{"children":[],"id":"logRemoteExecutionLocally","value":"N"},{"children":[],"id":"remote","value":"N"},{"children":[],"id":"local","value":"Y"},{"children":[],"id":"showTransformations","value":"N"}],"id":"Pentaho local","value":null,"name":"Pentaho local","owner":null,"ownerPermissionsList":[]}</value>
      </attribute>
    </group>
  </attributes>
</job>
