<transformation>
  <info>
    <name>tr_target-update_table-compare</name>
    <description />
    <extended_description />
    <trans_version />
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>/generic/target_update</directory>
    <parameters>
      <parameter>
        <name>PARAM_CDC_CURRENT_LOAD_UTC</name>
        <default_value>2017.06.15 00:00:00</default_value>
        <description>Timestamp of the current load (no rows after this timestamp will be loaded)</description>
      </parameter>
      <parameter>
        <name>PARAM_CDC_LAST_LOAD_UTC</name>
        <default_value>1900.01.01 00:00:00</default_value>
        <description>Timestamp for when the target DB was most recently updated successfully</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE</name>
        <default_value>dwh_psa_obo</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER</name>
        <default_value />
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_HOST</name>
        <default_value>localhost</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD</name>
        <default_value>src_db_password</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_PORT</name>
        <default_value>5432</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_URL</name>
        <default_value />
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME</name>
        <default_value>src_db_username</default_value>
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_DATABASE</name>
        <default_value>dwh_dsa_obo</default_value>
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_DRIVER</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_HOST</name>
        <default_value>localhost</default_value>
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD</name>
        <default_value>tgt_db_password</default_value>
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_PORT</name>
        <default_value>5432</default_value>
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_URL</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_USERNAME</name>
        <default_value>tgt_db_username</default_value>
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_DB_ID</name>
        <default_value>10</default_value>
        <description>ID the "source" database containing the table that has been mirrored to a "target" database</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_SCHEMA</name>
        <default_value>obo</default_value>
        <description>Name of schema containing source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_TABLE</name>
        <default_value>country</default_value>
        <description>Name of source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_TABLE_META_ID</name>
        <default_value>310</default_value>
        <description>Primary key of ${QF_ETL_DB_SCHEMA}.table_meta row for the table pair being compared</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_DB_ID</name>
        <default_value>20</default_value>
        <description>ID of the "target" database to which the "source" DB table has been archived/mirrored</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_SCHEMA</name>
        <default_value>obo</default_value>
        <description>Name of schema containing target table to update (not currently used)</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_TABLE</name>
        <default_value>country</default_value>
        <description>Name of target table to update (not currently used)</description>
      </parameter>
    </parameters>
    <log>
      <trans-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANS_SCHEMA}</schema>
        <table>${QF_LOG_TRANS_TABLE}</table>
        <size_limit_lines />
        <interval />
        <timeout_days>${QF_LOG_TRANS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STATUS</id>
          <enabled>Y</enabled>
          <name>STATUS</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
          <subject />
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
          <subject />
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
          <subject />
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
          <subject />
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
          <subject />
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
          <subject />
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>STARTDATE</id>
          <enabled>Y</enabled>
          <name>STARTDATE</name>
        </field>
        <field>
          <id>ENDDATE</id>
          <enabled>Y</enabled>
          <name>ENDDATE</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>DEPDATE</id>
          <enabled>Y</enabled>
          <name>DEPDATE</name>
        </field>
        <field>
          <id>REPLAYDATE</id>
          <enabled>Y</enabled>
          <name>REPLAYDATE</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>Y</enabled>
          <name>LOG_FIELD</name>
        </field>
        <field>
          <id>EXECUTING_SERVER</id>
          <enabled>N</enabled>
          <name>EXECUTING_SERVER</name>
        </field>
        <field>
          <id>EXECUTING_USER</id>
          <enabled>N</enabled>
          <name>EXECUTING_USER</name>
        </field>
        <field>
          <id>CLIENT</id>
          <enabled>N</enabled>
          <name>CLIENT</name>
        </field>
      </trans-log-table>
      <perf-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSPERF_SCHEMA}</schema>
        <table>${QF_LOG_TRANSPERF_TABLE}</table>
        <interval />
        <timeout_days>${QF_LOG_TRANSPERF_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>SEQ_NR</id>
          <enabled>Y</enabled>
          <name>SEQ_NR</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>INPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>INPUT_BUFFER_ROWS</name>
        </field>
        <field>
          <id>OUTPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>OUTPUT_BUFFER_ROWS</name>
        </field>
      </perf-log-table>
      <channel-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_CHANNEL_SCHEMA}</schema>
        <table>${QF_LOG_CHANNEL_TABLE}</table>
        <timeout_days>${QF_LOG_CHANNEL_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>LOGGING_OBJECT_TYPE</id>
          <enabled>Y</enabled>
          <name>LOGGING_OBJECT_TYPE</name>
        </field>
        <field>
          <id>OBJECT_NAME</id>
          <enabled>Y</enabled>
          <name>OBJECT_NAME</name>
        </field>
        <field>
          <id>OBJECT_COPY</id>
          <enabled>Y</enabled>
          <name>OBJECT_COPY</name>
        </field>
        <field>
          <id>REPOSITORY_DIRECTORY</id>
          <enabled>Y</enabled>
          <name>REPOSITORY_DIRECTORY</name>
        </field>
        <field>
          <id>FILENAME</id>
          <enabled>Y</enabled>
          <name>FILENAME</name>
        </field>
        <field>
          <id>OBJECT_ID</id>
          <enabled>Y</enabled>
          <name>OBJECT_ID</name>
        </field>
        <field>
          <id>OBJECT_REVISION</id>
          <enabled>Y</enabled>
          <name>OBJECT_REVISION</name>
        </field>
        <field>
          <id>PARENT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>PARENT_CHANNEL_ID</name>
        </field>
        <field>
          <id>ROOT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>ROOT_CHANNEL_ID</name>
        </field>
      </channel-log-table>
      <step-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSSTEP_SCHEMA}</schema>
        <table>${QF_LOG_TRANSSTEP_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSSTEP_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>N</enabled>
          <name>LOG_FIELD</name>
        </field>
      </step-log-table>
      <metrics-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSMETRICS_SCHEMA}</schema>
        <table>${QF_LOG_TRANSMETRICS_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSMETRICS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>METRICS_DATE</id>
          <enabled>Y</enabled>
          <name>METRICS_DATE</name>
        </field>
        <field>
          <id>METRICS_CODE</id>
          <enabled>Y</enabled>
          <name>METRICS_CODE</name>
        </field>
        <field>
          <id>METRICS_DESCRIPTION</id>
          <enabled>Y</enabled>
          <name>METRICS_DESCRIPTION</name>
        </field>
        <field>
          <id>METRICS_SUBJECT</id>
          <enabled>Y</enabled>
          <name>METRICS_SUBJECT</name>
        </field>
        <field>
          <id>METRICS_TYPE</id>
          <enabled>Y</enabled>
          <name>METRICS_TYPE</name>
        </field>
        <field>
          <id>METRICS_VALUE</id>
          <enabled>Y</enabled>
          <name>METRICS_VALUE</name>
        </field>
      </metrics-log-table>
    </log>
    <maxdate>
      <connection />
      <table />
      <field />
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file />
    <capture_step_performance>Y</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
    <created_user>-</created_user>
    <created_date>2016/04/03 09:57:16.279</created_date>
    <modified_user>-</modified_user>
    <modified_date>2018/05/11 13:07:36.418</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA=</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
    <notepad>
      <note>This transformation uses ETL Metadata injection to update a "target" table by comparing all rows of the "target" tables with all rows of its "source" table .
This is a generic algorithm that can work with *any* table, as long as the necessary metadata is available to be injected. This transformation has parameters:

	PARAM_CDC_LAST_LOAD_UTC					Timestamp for when the target DB was most recently updated successfully
	PARAM_CDC_CURRENT_LOAD_UTC				Used so that a consistent max timestamp is used for all ETL
	PARAM_DYN_DB_CONN_SOURCE_DB_HOST		for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_PORT		for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER		for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_URL			for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_HOST		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_PORT		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_DATABASE	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_USERNAME	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_DRIVER		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_URL			for target DB "dynamic" database connections
	PARAM_TABLE_META_ID							Primary key of ${QF_ETL_DB_SCHEMA}.table_meta row for "source" table archived/mirrored to "target" table
	PARAM_SOURCE_DB_ID							ID the "source" database containing tables will be mirrored to a "target" database
	PARAM_SOURCE_SCHEMA						Name of schema containing source table to mirror to target table
	PARAM_SOURCE_TABLE							Name of source table to mirror to target table
	PARAM_TARGET_DB_ID							ID of the "target" database to which the "source" DB tables will be archived/mirrored
	PARAM_TARGET_SCHEMA						Name of schema containing target table to update
	PARAM_TARGET_TABLE							Name of target table to update</note>
      <xloc>0</xloc>
      <yloc>0</yloc>
      <width>923</width>
      <heigth>348</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>The query here (at least the WHERE clause) to
provide the source DB column names must 
match the query in "jb_target-update_table-compare"
from where this transformation is executed.
See the comments in that job for an explanation.</note>
      <xloc>480</xloc>
      <yloc>672</yloc>
      <width>307</width>
      <heigth>75</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>255</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>The query here (at least the WHERE clause) to
provide the source DB key column names must
match the query in "jb_target-update_table-compare"
 from where this transformation is executed.
See the comments in that job for an explanation.</note>
      <xloc>112</xloc>
      <yloc>672</yloc>
      <width>307</width>
      <heigth>75</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>255</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Compare stream (the new data)</note>
      <xloc>32</xloc>
      <yloc>400</yloc>
      <width>183</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Reference stream (the old data)</note>
      <xloc>656</xloc>
      <yloc>400</yloc>
      <width>187</width>
      <heigth>23</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <connection>
    <name>etl_db</name>
    <server>${QF_ETL_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_ETL_DB_DATABASE}</database>
    <port>${QF_ETL_DB_PORT}</port>
    <username>${QF_ETL_DB_USERNAME}</username>
    <password>${QF_ETL_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_ETL_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>logging_db</name>
    <server>${QF_LOGGING_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_LOGGING_DB_DATABASE}</database>
    <port>${QF_LOGGING_DB_PORT}</port>
    <username>${QF_LOGGING_DB_USERNAME}</username>
    <password>${QF_LOGGING_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_LOGGING_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <order>
    <hop>
      <from>SELECT statement for target DB</from>
      <to>ETL Metadata Injection: tmplt_target-update_table-compare</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Target DB primary key column names</from>
      <to>ETL Metadata Injection: tmplt_target-update_table-compare</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Source &amp; Target DB column names to mirror</from>
      <to>ETL Metadata Injection: tmplt_target-update_table-compare</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>SELECT statement for source DB</from>
      <to>ETL Metadata Injection: tmplt_target-update_table-compare</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Target DB table updatable column metadata</from>
      <to>ETL Metadata Injection: tmplt_target-update_table-compare</to>
      <enabled>Y</enabled>
    </hop>
  </order>
  <step>
    <name>ETL Metadata Injection: tmplt_target-update_table-compare</name>
    <type>MetaInject</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <specification_method>rep_name</specification_method>
    <trans_object_id />
    <trans_name>tmplt_target-update_table-compare</trans_name>
    <filename />
    <directory_path>${Internal.Entry.Current.Directory}</directory_path>
    <source_step />
    <source_output_fields>    </source_output_fields>
    <target_file />
    <no_execution>N</no_execution>
    <stream_source_step />
    <stream_target_step />
    <mappings>
      <mapping>
        <target_step_name>Update existing rows of target table</target_step_name>
        <target_attribute_key>KEY_CONDITION</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Target DB primary key column names</source_step>
        <source_field>key_field_value_comparator</source_field>
      </mapping>
      <mapping>
        <target_step_name>Merge Rows (diff)</target_step_name>
        <target_attribute_key>KEY_FIELDS</target_attribute_key>
        <target_detail>N</target_detail>
        <source_step>Target DB primary key column names</source_step>
        <source_field>target_key_col_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Update existing rows of target table</target_step_name>
        <target_attribute_key>UPDATE_STREAM</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Target DB table updatable column metadata</source_step>
        <source_field>target_col_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Get rows from target DB table</target_step_name>
        <target_attribute_key>SQL</target_attribute_key>
        <target_detail>N</target_detail>
        <source_step>SELECT statement for target DB</source_step>
        <source_field>select_target_rows_sql</source_field>
      </mapping>
      <mapping>
        <target_step_name>Merge Rows (diff)</target_step_name>
        <target_attribute_key>VALUE_FIELDS</target_attribute_key>
        <target_detail>N</target_detail>
        <source_step>Source &amp; Target DB column names to mirror</source_step>
        <source_field>target_col_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Update existing rows of target table</target_step_name>
        <target_attribute_key>KEY_STREAM</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Target DB primary key column names</source_step>
        <source_field>target_key_col_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Update existing rows of target table</target_step_name>
        <target_attribute_key>KEY_STREAM2</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Target DB primary key column names</source_step>
        <source_field>no_field</source_field>
      </mapping>
      <mapping>
        <target_step_name>Synchronize after merge</target_step_name>
        <target_attribute_key>COMPARATOR</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Target DB primary key column names</source_step>
        <source_field>key_field_value_comparator</source_field>
      </mapping>
      <mapping>
        <target_step_name>Rename source DB field names -> target DB field names</target_step_name>
        <target_attribute_key>FIELD_NAME</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Source &amp; Target DB column names to mirror</source_step>
        <source_field>source_col_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Synchronize after merge</target_step_name>
        <target_attribute_key>UPDATE_TABLE_FIELD</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Source &amp; Target DB column names to mirror</source_step>
        <source_field>target_col_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Update existing rows of target table</target_step_name>
        <target_attribute_key>UPDATE_LOOKUP</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Target DB table updatable column metadata</source_step>
        <source_field>target_col_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Synchronize after merge</target_step_name>
        <target_attribute_key>STREAM_FIELD2</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Target DB primary key column names</source_step>
        <source_field>no_field</source_field>
      </mapping>
      <mapping>
        <target_step_name>Synchronize after merge</target_step_name>
        <target_attribute_key>STREAM_FIELD1</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Target DB primary key column names</source_step>
        <source_field>target_key_col_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Rename source DB field names -> target DB field names</target_step_name>
        <target_attribute_key>FIELD_RENAME</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Source &amp; Target DB column names to mirror</source_step>
        <source_field>target_col_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Synchronize after merge</target_step_name>
        <target_attribute_key>TABLE_FIELD</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Target DB primary key column names</source_step>
        <source_field>target_key_col_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Rename source DB field names -> target DB field names</target_step_name>
        <target_attribute_key>FIELD_PRECISION</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Source &amp; Target DB column names to mirror</source_step>
        <source_field>target_col_precision</source_field>
      </mapping>
      <mapping>
        <target_step_name>Update existing rows of target table</target_step_name>
        <target_attribute_key>KEY_LOOKUP</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Target DB primary key column names</source_step>
        <source_field>target_key_col_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Synchronize after merge</target_step_name>
        <target_attribute_key>UPDATE</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Source &amp; Target DB column names to mirror</source_step>
        <source_field>is_updateable_column</source_field>
      </mapping>
      <mapping>
        <target_step_name>Synchronize after merge</target_step_name>
        <target_attribute_key>STREAM_FIELD</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Source &amp; Target DB column names to mirror</source_step>
        <source_field>target_col_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Rename source DB field names -> target DB field names</target_step_name>
        <target_attribute_key>FIELD_LENGTH</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Source &amp; Target DB column names to mirror</source_step>
        <source_field>target_col_length</source_field>
      </mapping>
      <mapping>
        <target_step_name>Get rows from source DB table</target_step_name>
        <target_attribute_key>SQL</target_attribute_key>
        <target_detail>N</target_detail>
        <source_step>SELECT statement for source DB</source_step>
        <source_field>select_source_rows_sql</source_field>
      </mapping>
    </mappings>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>416</xloc>
      <yloc>496</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>SELECT statement for source DB</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>etl_db</connection>
    <sql>WITH
    -- Create table with a string column that contains the columns from the 
    -- source DB table to compare with corresponding columns from the 
    -- target DB table:
    select_list AS (
        SELECT 
            -- POSTGRESQL-SPECIFIC
            array_to_string(array_agg(source_column_name ORDER BY column_meta_id ASC), ',') AS "str_value"
        FROM 
            ${QF_ETL_DB_SCHEMA}.column_meta 
        WHERE
            table_meta_id = ${PARAM_TABLE_META_ID} AND 
            -- This selects the columns from the source DB table that will be 
            -- compared with corresponding columns from the target DB table.
            -- Although the primary key columns don't need to be compared, they
            -- are needed by the "Merge Rows" step so they are included here.
            (compare_column=true OR is_primary_key_column=true)
    ),
    -- Create table with a string column that contains the "ORDER BY" clause. 
    -- This consists of the columns that make up the primary key for the 
    -- source DB table. This is needed by the "Merge Rows" step in the 
    -- template transformation.
    orderby_list AS (
        SELECT 
           -- POSTGRESQL-SPECIFIC
            array_to_string(array_agg(source_column_name ORDER BY primary_key_column_order ASC), ',') AS "str_value"
        FROM 
            ${QF_ETL_DB_SCHEMA}.column_meta 
        WHERE
            table_meta_id = ${PARAM_TABLE_META_ID} AND 
            -- This selects the columns that make up the primary key for the
            -- source DB table.
            is_primary_key_column=true
    )
SELECT
    -- Create SELECT statement:
    'SELECT ' || CAST(select_list.str_value AS VARCHAR) || 
    ' FROM ${PARAM_SOURCE_SCHEMA}.${PARAM_SOURCE_TABLE} ' || 
    'ORDER BY ' || CAST(orderby_list.str_value AS VARCHAR) 
    AS "select_source_rows_sql" 
FROM
    select_list
CROSS JOIN
    orderby_list</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>240</xloc>
      <yloc>400</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>SELECT statement for target DB</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>etl_db</connection>
    <sql>WITH
    -- Create table with a string column that contains the columns from the 
    -- target DB table to compare with corresponding columns from the 
    -- source DB table:
    select_list AS (
        SELECT 
           -- POSTGRESQL-SPECIFIC
            array_to_string(array_agg(target_column_name ORDER BY column_meta_id ASC), ',') AS "str_value"
        FROM 
            ${QF_ETL_DB_SCHEMA}.column_meta 
        WHERE
            table_meta_id = ${PARAM_TABLE_META_ID} AND 
            -- This selects the columns from the target DB table that will be 
            -- compared with corresponding columns from the source DB table.
            -- Although the primary key columns don't need to be compared, they
            -- are needed by the "Merge Rows" step so they are included here.
            (compare_column=true OR is_primary_key_column=true)
    ),
    -- Create table with a string column that contains the "ORDER BY" clause. 
    -- This consists of the columns that make up the primary key for the 
    -- target DB table. This is needed by the "Merge Rows" step in the 
    -- template transformation.
    orderby_list AS (
        SELECT 
           -- POSTGRESQL-SPECIFIC
            array_to_string(array_agg(target_column_name ORDER BY primary_key_column_order ASC), ',') AS "str_value"
        FROM 
            ${QF_ETL_DB_SCHEMA}.column_meta 
        WHERE
            table_meta_id = ${PARAM_TABLE_META_ID} AND 
            -- This selects the columns that make up the primary key for the
            -- target DB table.
            is_primary_key_column=true
    )
SELECT
    -- Create SELECT statement:
    'SELECT ' || CAST(select_list.str_value AS VARCHAR) || 
    ' FROM ${PARAM_TARGET_SCHEMA}.${PARAM_TARGET_TABLE} ' || 
    'ORDER BY ' || CAST(orderby_list.str_value AS VARCHAR) 
    AS "select_target_rows_sql" 
FROM
    select_list
CROSS JOIN
    orderby_list</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>608</xloc>
      <yloc>400</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Source &amp; Target DB column names to mirror</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>etl_db</connection>
    <sql>SELECT
    source_column_name AS "source_col_name", 
    target_column_name AS "target_col_name", 
    NULL AS "target_col_length", 
    -- The value "-1" is injected into the "Select values" step of the ETL metadata injection template transformation
    -- to specify the "precision" of the "source_col_name" &amp; "target_col_name" fields. If this is not done, a problem 
    -- was observed for fields created by loading data from database columns of PostgreSQL data type "double precison".
    -- For such fields, it was observed that the values written out to a "target" database via a "Table output" step 
    -- were truncated to integers. Ideally, the precision should probably be set to something like 15 or 16 for this 
    -- case (double precision columns), but this value may not be appropriate for other data types. It was only by 
    -- experimenting that I found that injecting "-1" solved the problem for double precision columns. I have decided 
    -- to specify this for *all* columns until/unless I encounter a problem by doing this. If a problem does arise one 
    -- day, it may be necessary to update the definition of the ${QF_ETL_DB_SCHEMA}.column_meta table of the "ETL" 
    -- database to include 
    -- a real column to store the column "precision" on a column-by-column basis. For columns that do not need a 
    -- "precision" to be specified, NULL can be stored in this column. This will also require updating the 
    -- "populate_etl_metadata_tables" ETL code that generates default metadata.
    -1 AS "target_col_precision", 
    -- "is_updateable_column" is injected into step "Synchronize after merge", which is currently not used.
    -- Hence, this column/field can be removed if I delete the step "Synchronize after merge":
    --(is_primary_key_column=false) AS "is_updateable_column"  -- If false, the column will not be updated
    -- Alternate possibility, if I want to be bothered with setting values for the ${QF_ETL_DB_SCHEMA}.column_meta.is_updatable_column:
    is_updatable_column AND (is_primary_key_column=false) AS "is_updateable_column"  -- If false, the column will not be updated
FROM 
    ${QF_ETL_DB_SCHEMA}.column_meta 
WHERE 
    table_meta_id = ${PARAM_TABLE_META_ID} AND 
    -- Although the primary key columns don't need to be compared, they
    -- are needed by the "Merge Rows" step so they are included here.
    (mirror_column=true OR is_primary_key_column=true) 
ORDER BY 
    column_meta_id ASC</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>608</xloc>
      <yloc>608</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Target DB primary key column names</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>etl_db</connection>
    <sql>SELECT
    target_column_name AS "target_key_col_name", 
    '=' AS "key_field_value_comparator",
    -- "Stream field2" is not used in the "Update" step. Nevertheless, we must set 
    -- it to something or an error is thrown during ETL metadata injection. The
    -- only solution I have found is to inject an empty string for this field.
    '' AS "no_field" 
FROM 
    ${QF_ETL_DB_SCHEMA}.column_meta 
WHERE 
    table_meta_id = ${PARAM_TABLE_META_ID} AND 
    is_primary_key_column = true
ORDER BY 
    primary_key_column_order</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>240</xloc>
      <yloc>608</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Target DB table updatable column metadata</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>etl_db</connection>
    <sql>-- A Common Table Expression is used here so that we can perform an "ORDER BY"
-- on the result of the UNION of two SELECT statements.
WITH updateable_columns AS 
(
    SELECT
        column_meta_id,
        target_column_name AS "target_col_name" 
    FROM 
        ${QF_ETL_DB_SCHEMA}.column_meta  
    WHERE 
        table_meta_id = ${PARAM_TABLE_META_ID} AND 
        mirror_column = true AND
        is_updatable_column = true 
    UNION
    -- The "etl_batch_id_last_update" column/field is added by the ETL code.
    SELECT
        1000000                    AS "column_meta_id",  -- order this column last
        'etl_batch_id_last_update' AS "target_col_name"
) 
SELECT
    target_col_name 
FROM
    updateable_columns 
ORDER BY 
    column_meta_id ASC</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>752</xloc>
      <yloc>496</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step_error_handling>
  </step_error_handling>
  <slave-step-copy-partition-distribution>
  </slave-step-copy-partition-distribution>
  <slave_transformation>N</slave_transformation>
</transformation>
