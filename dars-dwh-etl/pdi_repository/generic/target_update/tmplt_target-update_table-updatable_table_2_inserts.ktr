<transformation>
  <info>
    <name>tmplt_target-update_table-updatable_table_2_inserts</name>
    <description />
    <extended_description />
    <trans_version />
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>/generic/target_update</directory>
    <parameters>
      <parameter>
        <name>PARAM_CDC_CURRENT_LOAD_UTC</name>
        <default_value>1900.01.01 00:00:00</default_value>
        <description>Timestamp of the current load (no rows after this timestamp will be loaded)</description>
      </parameter>
      <parameter>
        <name>PARAM_CDC_LAST_LOAD_UTC</name>
        <default_value>1900.01.01 00:00:00</default_value>
        <description>Timestamp for when the target DB was most recently updated successfully</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE</name>
        <default_value />
        <description />
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER</name>
        <default_value />
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_HOST</name>
        <default_value />
        <description />
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD</name>
        <default_value />
        <description />
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_PORT</name>
        <default_value />
        <description />
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_URL</name>
        <default_value />
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME</name>
        <default_value />
        <description />
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_DATABASE</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_DRIVER</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_HOST</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_PORT</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_URL</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_USERNAME</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_MAX_INSERT_ID</name>
        <default_value>0</default_value>
        <description>Maximum value of the "insert_id" column for rows to load from the source DB table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_INSERTED_ON_COLNAME</name>
        <default_value>inserted_on</default_value>
        <description>Name of column acting as "inserted_on" timestamp column of source table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_INSERT_ID_COLNAME</name>
        <default_value>insert_id</default_value>
        <description>Name of column acting as "insert_id" column of source table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_LAST_UPDATED_ON_COLNAME</name>
        <default_value>last_updated_on</default_value>
        <description>Name of "last_updated_on" timestamp column of source table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_SCHEMA</name>
        <default_value>passage</default_value>
        <description>Name of schema containing source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_TABLE</name>
        <default_value>passage</default_value>
        <description>Name of source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_INSERTED_ON_COLNAME</name>
        <default_value>inserted_on</default_value>
        <description>Name of column acting as "inserted_on" timestamp column of target table</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_INSERT_ID_COLNAME</name>
        <default_value>insert_id</default_value>
        <description>Name of column acting as "insert_id" column of target table</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_LAST_UPDATED_ON_COLNAME</name>
        <default_value>last_updated_on</default_value>
        <description>Name of "last_updated_on" timestamp column of target table</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_SCHEMA</name>
        <default_value>passage</default_value>
        <description>Name of schema containing target table to update</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_TABLE</name>
        <default_value>passage</default_value>
        <description>Name of target table to update</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_TABLE_MAX_INSERT_ID</name>
        <default_value />
        <description>Maximum value for the "insert_id" integer column of the target table</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_TABLE_MAX_LAST_UPDATED_ON</name>
        <default_value />
        <description>Maximum value for the "last updated on" timestamp column of the target table</description>
      </parameter>
    </parameters>
    <log>
      <trans-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANS_SCHEMA}</schema>
        <table>${QF_LOG_TRANS_TABLE}</table>
        <size_limit_lines />
        <interval />
        <timeout_days>${QF_LOG_TRANS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STATUS</id>
          <enabled>Y</enabled>
          <name>STATUS</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
          <subject>Table output - target_db.schema.table</subject>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
          <subject>Table output - target_db.schema.table</subject>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
          <subject>Table output - target_db.schema.table</subject>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
          <subject>Table input -  source_db.schema.table</subject>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
          <subject>Table output - target_db.schema.table</subject>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
          <subject>Table output - target_db.schema.table</subject>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>STARTDATE</id>
          <enabled>Y</enabled>
          <name>STARTDATE</name>
        </field>
        <field>
          <id>ENDDATE</id>
          <enabled>Y</enabled>
          <name>ENDDATE</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>DEPDATE</id>
          <enabled>Y</enabled>
          <name>DEPDATE</name>
        </field>
        <field>
          <id>REPLAYDATE</id>
          <enabled>Y</enabled>
          <name>REPLAYDATE</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>Y</enabled>
          <name>LOG_FIELD</name>
        </field>
        <field>
          <id>EXECUTING_SERVER</id>
          <enabled>N</enabled>
          <name>EXECUTING_SERVER</name>
        </field>
        <field>
          <id>EXECUTING_USER</id>
          <enabled>N</enabled>
          <name>EXECUTING_USER</name>
        </field>
        <field>
          <id>CLIENT</id>
          <enabled>N</enabled>
          <name>CLIENT</name>
        </field>
      </trans-log-table>
      <perf-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSPERF_SCHEMA}</schema>
        <table>${QF_LOG_TRANSPERF_TABLE}</table>
        <interval />
        <timeout_days>${QF_LOG_TRANSPERF_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>SEQ_NR</id>
          <enabled>Y</enabled>
          <name>SEQ_NR</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>INPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>INPUT_BUFFER_ROWS</name>
        </field>
        <field>
          <id>OUTPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>OUTPUT_BUFFER_ROWS</name>
        </field>
      </perf-log-table>
      <channel-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_CHANNEL_SCHEMA}</schema>
        <table>${QF_LOG_CHANNEL_TABLE}</table>
        <timeout_days>${QF_LOG_CHANNEL_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>LOGGING_OBJECT_TYPE</id>
          <enabled>Y</enabled>
          <name>LOGGING_OBJECT_TYPE</name>
        </field>
        <field>
          <id>OBJECT_NAME</id>
          <enabled>Y</enabled>
          <name>OBJECT_NAME</name>
        </field>
        <field>
          <id>OBJECT_COPY</id>
          <enabled>Y</enabled>
          <name>OBJECT_COPY</name>
        </field>
        <field>
          <id>REPOSITORY_DIRECTORY</id>
          <enabled>Y</enabled>
          <name>REPOSITORY_DIRECTORY</name>
        </field>
        <field>
          <id>FILENAME</id>
          <enabled>Y</enabled>
          <name>FILENAME</name>
        </field>
        <field>
          <id>OBJECT_ID</id>
          <enabled>Y</enabled>
          <name>OBJECT_ID</name>
        </field>
        <field>
          <id>OBJECT_REVISION</id>
          <enabled>Y</enabled>
          <name>OBJECT_REVISION</name>
        </field>
        <field>
          <id>PARENT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>PARENT_CHANNEL_ID</name>
        </field>
        <field>
          <id>ROOT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>ROOT_CHANNEL_ID</name>
        </field>
      </channel-log-table>
      <step-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSSTEP_SCHEMA}</schema>
        <table>${QF_LOG_TRANSSTEP_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSSTEP_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>N</enabled>
          <name>LOG_FIELD</name>
        </field>
      </step-log-table>
      <metrics-log-table>
        <connection>${QF_LOGGING_DB_CONNECTION}</connection>
        <schema>${QF_LOG_TRANSMETRICS_SCHEMA}</schema>
        <table>${QF_LOG_TRANSMETRICS_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSMETRICS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>METRICS_DATE</id>
          <enabled>Y</enabled>
          <name>METRICS_DATE</name>
        </field>
        <field>
          <id>METRICS_CODE</id>
          <enabled>Y</enabled>
          <name>METRICS_CODE</name>
        </field>
        <field>
          <id>METRICS_DESCRIPTION</id>
          <enabled>Y</enabled>
          <name>METRICS_DESCRIPTION</name>
        </field>
        <field>
          <id>METRICS_SUBJECT</id>
          <enabled>Y</enabled>
          <name>METRICS_SUBJECT</name>
        </field>
        <field>
          <id>METRICS_TYPE</id>
          <enabled>Y</enabled>
          <name>METRICS_TYPE</name>
        </field>
        <field>
          <id>METRICS_VALUE</id>
          <enabled>Y</enabled>
          <name>METRICS_VALUE</name>
        </field>
      </metrics-log-table>
    </log>
    <maxdate>
      <connection />
      <table />
      <field />
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file />
    <capture_step_performance>Y</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
    <created_user>-</created_user>
    <created_date>2016/04/03 09:57:16.279</created_date>
    <modified_user>-</modified_user>
    <modified_date>2018/04/12 10:24:18.196</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA=</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
    <notepad>
      <note>Load the data from the source DB table that will be moved to the target DB table.

It is important to sort these rows chronologically (by either the "insert_id" or "inserted_on" columns) so that if this transformation
fails in the middle somewhere and if this transaction does not run in a single transaction, then next time this transformation is 
executed, we want to start again where we left off (by computing, e.g., MAX(insert_id) for the target DB table).</note>
      <xloc>288</xloc>
      <yloc>592</yloc>
      <width>765</width>
      <heigth>80</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Insert new rows into the target DB table using a "Table output" step. Error handing is enabled for this step so that if a rows already exists,
the rows are passed to an "Update" step.

IMPORTANT:	A primary key constraint (or at least a "unique" constraint on the primary key column(s)) for the target table is 
				*required*; otherwise, error handling will not be triggered when attempting to insert a row with a duplicate key.

PDI does not fully support error handling when using "batch processing" with the PostgreSQL JDBC driver (a message to this 
effect is displayed when accepting the transformation settings dialog), so make sure "Use batch update for inserts" is *not* 
selected here!

See:

	/development/jeffreyz/tests/cdc_timestamps/tr_TEST_mirror_update-passage.passage-table_output

for tests  benchmark results I obtained testing the speed of various INSERT/UPDATE algorithms. Using a "Table output" step with 
an error handling hop to an "Update" step provides an approximately 2x speedup over an "Insert/Update" step for inserts *and* 
it does not exhibit (for inserts only) the behaviour where a "java"and "postgres" process continue to run with a high CPU load long 
after the transformation is finished. Hence, it should be favoured.

An odd behaviour is observed when the error handling sends rows to the "Update" step. After processing a large number of rows, 
it takes a long time for this transformation to end. During this period the "Pause" and "Stop" buttons remain enabled. Furthermore,
running" top" shows that both "postgres"and "java" processes are actively using a 25-75% of the CPU. When this CPU usage stops, 
the  "Pause" and "Stop" buttons become disabled, showing that the transformation is finally finished. Strange.</note>
      <xloc>288</xloc>
      <yloc>816</yloc>
      <width>813</width>
      <heigth>332</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Get batch ID for current transformation. This will be stored in the target  table for auditing/logging. This step *must* come after the
"Map column names" step because the metadata injected into that step does not include this column/field.</note>
      <xloc>288</xloc>
      <yloc>752</yloc>
      <width>780</width>
      <heigth>38</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This transformation updates the target DB mirror of a table from the source DB that can receive INSERTs or UPDATES. This is a generic algorithm that
can work with *any* table,  as long as rows cannot be deleted from the source or target table, and it has the necessary "insert_id", "inserted_on" &amp; 
"last_updated_on" columns. The "updatable" table generic update algorithm #2 for INSERTs is used. This transformation has parameters:

	PARAM_CDC_LAST_LOAD_UTC						Timestamp for when the target DB was most recently updated successfully
	PARAM_CDC_CURRENT_LOAD_UTC					Used so that a consistent max timestamp is used for all ETL
	PARAM_DYN_DB_CONN_TARGET_DB_HOST			for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_PORT			for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_DATABASE		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_USERNAME	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD	for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_DRIVER		for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_URL			for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_HOST			for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_PORT			for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD	for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER		for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_URL			for source DB "dynamic" database connections
	PARAM_MAX_INSERT_ID							Maximum value of the "insert_id" column for rows to load from the source DB table
	PARAM_SOURCE_SCHEMA							Schema of mirrored table
	PARAM_SOURCE_TABLE							Name of mirrored table to update
	PARAM_SOURCE_INSERT_ID_COLNAME				Name of column acting as "insert_id"  timestamp column of source table
	PARAM_SOURCE_INSERTED_ON_COLNAME			Name of column acting as "inserted_on" column of source table
	PARAM_SOURCE_LAST_UPDATED_ON_COLNAME	Name of "last_updated_on" timestamp column of source table
	PARAM_TARGET_SCHEMA							Name of schema containing target table to update (not currently used)
	PARAM_TARGET_TABLE								Name of target table to update (not currently used)
	PARAM_TARGET_INSERT_ID_COLNAME				Name of column acting as "insert_id"  timestamp column of target table
	PARAM_TARGET_INSERTED_ON_COLNAME			Name of column acting as "inserted_on" column of target table
	PARAM_TARGET_LAST_UPDATED_ON_COLNAME	Name of "last_updated_on" timestamp column of target table
	PARAM_TARGET_TABLE_MAX_INSERT_ID			Maximum value for the "insert_id" integer column of the target table
	PARAM_TARGET_TABLE_MAX_LAST_UPDATED_ON	Maximum value for the "last updated on" timestamp column of the target table
</note>
      <xloc>0</xloc>
      <yloc>0</yloc>
      <width>878</width>
      <heigth>486</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Although this transformation has parameters whose values are used in its steps, these parameters are not 
passed values from the parent transformation in the usual way this is normally done in PDI. This is because 
the "ETL Metadata Injection" step (which is responsible for executing this template transformation) does not 
support parameter passing. Nevertheless, it appears that the parameters that are defined for this template 
transformation can be used as expected. The explanation for this behaviour *MAY* be that the references to 
these parameters, e.g., ${PARAM_SOURCE_TABLE}, in this transformation are simply using the values defined 
for these variables in the parent transformation that contains the "ETL Metadata Injection" step that 
references this template transformation. Fortunately, all of the parameters that are used by this transformation 
are defined with the correct values in the parent transformation. I have tested this by removing the parameters 
entirely. The result was that the transformation ran as expected, even though it made use of the parameters 
that were removed.

Note that if a target file is created by the "ETL metadata Injection" step, then that transformation *can* have 
its parameters passed to it in the normal fashion because it is a normal transformation (all metadata has been 
injected into it).</note>
      <xloc>912</xloc>
      <yloc>0</yloc>
      <width>665</width>
      <heigth>220</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>255</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Select and possibly map/rename fields (table column names), as appropriate.</note>
      <xloc>288</xloc>
      <yloc>688</yloc>
      <width>462</width>
      <heigth>24</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Metadata injected -></note>
      <xloc>16</xloc>
      <yloc>688</yloc>
      <width>130</width>
      <heigth>24</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>255</fontcolorred>
      <fontcolorgreen>255</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>0</backgroundcolorred>
      <backgroundcolorgreen>0</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Metadata injected -></note>
      <xloc>16</xloc>
      <yloc>1040</yloc>
      <width>130</width>
      <heigth>24</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>255</fontcolorred>
      <fontcolorgreen>255</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>0</backgroundcolorred>
      <backgroundcolorgreen>0</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>Metadata injected -></note>
      <xloc>16</xloc>
      <yloc>608</yloc>
      <width>130</width>
      <heigth>24</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>255</fontcolorred>
      <fontcolorgreen>255</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>0</backgroundcolorred>
      <backgroundcolorgreen>0</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <connection>
    <name>generic_source_db</name>
    <server>${PARAM_DYN_DB_CONN_SOURCE_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE}</database>
    <port>${PARAM_DYN_DB_CONN_SOURCE_DB_PORT}</port>
    <username>${PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME}</username>
    <password>${PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${PARAM_DYN_DB_CONN_SOURCE_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>generic_target_db</name>
    <server>${PARAM_DYN_DB_CONN_TARGET_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${PARAM_DYN_DB_CONN_TARGET_DB_DATABASE}</database>
    <port>${PARAM_DYN_DB_CONN_TARGET_DB_PORT}</port>
    <username>${PARAM_DYN_DB_CONN_TARGET_DB_USERNAME}</username>
    <password>${PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${PARAM_DYN_DB_CONN_TARGET_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>logging_db</name>
    <server>${QF_LOGGING_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_LOGGING_DB_DATABASE}</database>
    <port>${QF_LOGGING_DB_PORT}</port>
    <username>${QF_LOGGING_DB_USERNAME}</username>
    <password>${QF_LOGGING_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_LOGGING_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <order>
    <hop>
      <from>Log parameters</from>
      <to>Table input -  source_db.schema.table</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Table output - target_db.schema.table</from>
      <to>Set etl_batch_id_last_update = Xform batch ID</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Set etl_batch_id_last_update = Xform batch ID</from>
      <to>Update - target_db.schema.table</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Map column names</from>
      <to>Set etl_batch_id_insert = Xform batch ID</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Set etl_batch_id_insert = Xform batch ID</from>
      <to>Table output - target_db.schema.table</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Table input -  source_db.schema.table</from>
      <to>Map column names</to>
      <enabled>Y</enabled>
    </hop>
  </order>
  <step>
    <name>Map column names</name>
    <type>SelectValues</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <select_unspecified>N</select_unspecified>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>688</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Set etl_batch_id_insert = Xform batch ID</name>
    <type>SystemInfo</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>etl_batch_id_insert</name>
        <type>batch ID</type>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>752</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Set etl_batch_id_last_update = Xform batch ID</name>
    <type>SystemInfo</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <fields>
      <field>
        <name>etl_batch_id_last_update</name>
        <type>batch ID</type>
      </field>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>960</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Table input -  source_db.schema.table</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>generic_source_db</connection>
    <sql>-- This statement is commented out because the SQL statement is, 
-- instead, injected via ETL Metadata Injection:
--
--SELECT
--    *
--FROM
--    ${PARAM_SOURCE_SCHEMA}.${PARAM_SOURCE_TABLE}
--WHERE
--    (
--        ${PARAM_SOURCE_INSERT_ID_COLNAME}       >  ${PARAM_TARGET_TABLE_MAX_INSERT_ID}  -- newly INSERTed rows, since the last run
--      --${PARAM_SOURCE_INSERTED_ON_COLNAME}     > '${PARAM_CDC_LAST_LOAD_UTC}'          -- alternate condition, instead of the previous line
--     OR ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME} >= ${PARAM_TARGET_TABLE_MAX_LAST_UPDATED_ON}    -- UPDATEd rows, since the last run. 
--                                                                                 -- This condition is needed to be able to select rows that
--                                                                                 -- are modified during a period when the table is being treated as an insert-only
--                                                                                 -- table (not a likely scenario, but it is a possibility).
--                                                                                 -- Because ">=" is used here, not ">", this will include a least one row that was
--                                                                                 -- updated on the previous run (assuming that there was at least one row updated).
--                                                                                 -- This/these rows will have:
--                                                                                 --   ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME} = ${PARAM_TARGET_TABLE_MAX_LAST_UPDATED_ON}.
--                                                                                 -- The reason why ">=" is used is in case there were one or more rows that were *not* 
--                                                                                 -- updated on the previous run, but which have: 
--                                                                                 --   ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME} = ${PARAM_TARGET_TABLE_MAX_LAST_UPDATED_ON}.
--                                                                                 -- This can occur
--                                                                                 -- because of the finite resolution of timestamp values. As a result, more than one
--                                                                                 -- row can have the *same* value of ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME}, but not all of
--                                                                                 -- them were loaded and treated on the previous run, i.e., the cutoff imposed by
--                                                                                 -- the condition ${PARAM_SOURCE_INSERT_ID_COLNAME} &lt;= ${PARAM_MAX_INSERT_ID} or
--                                                                                 -- ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME} &lt;= '${PARAM_CDC_CURRENT_LOAD_UTC}' loaded some,
--                                                                                 -- but not all, of the rows with this value of ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME}.
--      --OR ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME} >= '${PARAM_CDC_LAST_LOAD_UTC}'   -- alternate condition, instead of the previous line
--    )
--    AND ${PARAM_SOURCE_INSERT_ID_COLNAME}   &lt;=  ${PARAM_MAX_INSERT_ID}           -- to avoid loading rows that are *inserted* after the job starts
--  --AND ${PARAM_SOURCE_INSERTED_ON_COLNAME} &lt;= '${PARAM_CDC_CURRENT_LOAD_UTC}'   -- alternate condition, instead of the previous line 
--    AND (
--            ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME} IS NULL OR                           -- rows that have been inserted but not modified
--            ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME} &lt;= '${PARAM_CDC_CURRENT_LOAD_UTC}'   -- to avoid loading rows that are *modified* after the job starts
--        )
--ORDER BY
--    ${PARAM_SOURCE_INSERT_ID_COLNAME}</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>608</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Table output - target_db.schema.table</name>
    <type>TableOutput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>generic_target_db</connection>
    <schema>${PARAM_TARGET_SCHEMA}</schema>
    <table>${PARAM_TARGET_TABLE}</table>
    <commit>1000</commit>
    <truncate>N</truncate>
    <ignore_errors>N</ignore_errors>
    <use_batch>N</use_batch>
    <specify_fields>N</specify_fields>
    <partitioning_enabled>N</partitioning_enabled>
    <partitioning_field />
    <partitioning_daily>N</partitioning_daily>
    <partitioning_monthly>Y</partitioning_monthly>
    <tablename_in_field>N</tablename_in_field>
    <tablename_field />
    <tablename_in_table>Y</tablename_in_table>
    <return_keys>N</return_keys>
    <return_field />
    <fields>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>864</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Update - target_db.schema.table</name>
    <type>Update</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>generic_target_db</connection>
    <skip_lookup>N</skip_lookup>
    <commit>100</commit>
    <use_batch>N</use_batch>
    <error_ignored>N</error_ignored>
    <ignore_flag_field />
    <lookup>
      <schema>${PARAM_TARGET_SCHEMA}</schema>
      <table>${PARAM_TARGET_TABLE}</table>
    </lookup>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>1040</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Log parameters</name>
    <type>WriteToLog</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <loglevel>log_level_basic</loglevel>
    <displayHeader>Y</displayHeader>
    <limitRows>N</limitRows>
    <limitRowsNumber>0</limitRowsNumber>
    <logmessage>tmplt_target-update_table-updatable_table_2_inserts:
PARAM_CDC_LAST_LOAD_UTC                = ${PARAM_CDC_LAST_LOAD_UTC}
PARAM_CDC_CURRENT_LOAD_UTC             = ${PARAM_CDC_CURRENT_LOAD_UTC}
PARAM_DYN_DB_CONN_SOURCE_DB_HOST       = ${PARAM_DYN_DB_CONN_SOURCE_DB_HOST}
PARAM_DYN_DB_CONN_SOURCE_DB_PORT       = ${PARAM_DYN_DB_CONN_SOURCE_DB_PORT}
PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE   = ${PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE}
PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD   = ${PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD}
PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME   = ${PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME}
PARAM_DYN_DB_CONN_SOURCE_DB_URL        = ${PARAM_DYN_DB_CONN_SOURCE_DB_URL}
PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER     = ${PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER}
PARAM_DYN_DB_CONN_TARGET_DB_HOST       = ${PARAM_DYN_DB_CONN_TARGET_DB_HOST}
PARAM_DYN_DB_CONN_TARGET_DB_PORT       = ${PARAM_DYN_DB_CONN_TARGET_DB_PORT}
PARAM_DYN_DB_CONN_TARGET_DB_DATABASE   = ${PARAM_DYN_DB_CONN_TARGET_DB_DATABASE}
PARAM_DYN_DB_CONN_TARGET_DB_USERNAME   = ${PARAM_DYN_DB_CONN_TARGET_DB_USERNAME}
PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD   = ${PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD}
PARAM_DYN_DB_CONN_TARGET_DB_URL        = ${PARAM_DYN_DB_CONN_TARGET_DB_URL}
PARAM_DYN_DB_CONN_TARGET_DB_DRIVER     = ${PARAM_DYN_DB_CONN_TARGET_DB_DRIVER}
PARAM_MAX_INSERT_ID                    = ${PARAM_MAX_INSERT_ID}
PARAM_SOURCE_SCHEMA                    = ${PARAM_SOURCE_SCHEMA}
PARAM_SOURCE_TABLE                     = ${PARAM_SOURCE_TABLE}
PARAM_SOURCE_INSERT_ID_COLNAME         = ${PARAM_SOURCE_INSERT_ID_COLNAME}   
PARAM_SOURCE_INSERTED_ON_COLNAME       = ${PARAM_SOURCE_INSERTED_ON_COLNAME}
PARAM_SOURCE_LAST_UPDATED_ON_COLNAME   = ${PARAM_SOURCE_LAST_UPDATED_ON_COLNAME}
PARAM_TARGET_SCHEMA                    = ${PARAM_TARGET_SCHEMA}
PARAM_TARGET_TABLE                     = ${PARAM_TARGET_TABLE}
PARAM_TARGET_INSERT_ID_COLNAME         = ${PARAM_TARGET_INSERT_ID_COLNAME}   
PARAM_TARGET_INSERTED_ON_COLNAME       = ${PARAM_TARGET_INSERTED_ON_COLNAME}
PARAM_TARGET_LAST_UPDATED_ON_COLNAME   = ${PARAM_TARGET_LAST_UPDATED_ON_COLNAME}
PARAM_TARGET_TABLE_MAX_INSERT_ID       = ${PARAM_TARGET_TABLE_MAX_INSERT_ID}
PARAM_TARGET_TABLE_MAX_LAST_UPDATED_ON = ${PARAM_TARGET_TABLE_MAX_LAST_UPDATED_ON}</logmessage>
    <fields>
      </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>144</xloc>
      <yloc>512</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step_error_handling>
    <error>
      <source_step>Table output - target_db.schema.table</source_step>
      <target_step>Set etl_batch_id_last_update = Xform batch ID</target_step>
      <is_enabled>Y</is_enabled>
      <nr_valuename />
      <descriptions_valuename />
      <fields_valuename />
      <codes_valuename />
      <max_errors />
      <max_pct_errors />
      <min_pct_rows />
    </error>
  </step_error_handling>
  <slave-step-copy-partition-distribution>
  </slave-step-copy-partition-distribution>
  <slave_transformation>N</slave_transformation>
</transformation>
