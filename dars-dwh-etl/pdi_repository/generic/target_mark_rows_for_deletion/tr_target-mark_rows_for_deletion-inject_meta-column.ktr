<transformation>
  <info>
    <name>tr_target-mark_rows_for_deletion-inject_meta-column</name>
    <description />
    <extended_description />
    <trans_version />
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>/generic/target_mark_rows_for_deletion</directory>
    <parameters>
      <parameter>
        <name>PARAM_CAN_DELETE_ROW_SOURCE_COLNAME</name>
        <default_value />
        <description>Column of source table that indicates if the row can be deleted immediately</description>
      </parameter>
      <parameter>
        <name>PARAM_CDC_LAST_LOAD_UTC</name>
        <default_value>1900.01.01 00:00:00</default_value>
        <description>Timestamp of last successful load from the source database</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE</name>
        <default_value />
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_DRIVER</name>
        <default_value />
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_HOST</name>
        <default_value />
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD</name>
        <default_value />
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_PORT</name>
        <default_value />
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_URL</name>
        <default_value />
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME</name>
        <default_value />
        <description>for source DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_DATABASE</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_DRIVER</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_HOST</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_PORT</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_URL</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_DYN_DB_CONN_TARGET_DB_USERNAME</name>
        <default_value />
        <description>for target DB "dynamic" database connections</description>
      </parameter>
      <parameter>
        <name>PARAM_LAST_UPDATED_ON_SOURCE_COLNAME</name>
        <default_value />
        <description>Column of source table that acts as a "last_updated_on" timestamp column</description>
      </parameter>
      <parameter>
        <name>PARAM_ROW_CAN_BE_DELETED_FROM_SECONDS</name>
        <default_value>2000000000</default_value>
        <description>Number of seconds after the "row_can_be_deleted_from" timestamp that an archived row can be deleted</description>
      </parameter>
      <parameter>
        <name>PARAM_ROW_CAN_BE_DELETED_FROM_SOURCE_COLNAME</name>
        <default_value />
        <description>Column of source table that acts as a "row_can_be_deleted_from" timestamp column</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_DB_ID</name>
        <default_value>-1</default_value>
        <description>ID the "source" database containing tables will be mirrored to a "target" database</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_SCHEMA</name>
        <default_value>passage</default_value>
        <description>Name of schema containing source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_SOURCE_TABLE</name>
        <default_value>passage_status</default_value>
        <description>Name of source table to mirror to target table</description>
      </parameter>
      <parameter>
        <name>PARAM_TABLE_META_ID</name>
        <default_value>623</default_value>
        <description>Primary key of etl.table_meta row for "source" table from which rows will be deleted</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_DB_ID</name>
        <default_value>-1</default_value>
        <description>ID of the target database for which rows of the source DB tables will be "marked for deletion"</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_SCHEMA</name>
        <default_value>passage</default_value>
        <description>Name of schema containing target table to update (not currently used)</description>
      </parameter>
      <parameter>
        <name>PARAM_TARGET_TABLE</name>
        <default_value>passage_status</default_value>
        <description>Name of target table to update (not currently used)</description>
      </parameter>
      <parameter>
        <name>PARAM_USE_CUSTOM_DELETE_ALGORITHM</name>
        <default_value>N</default_value>
        <description>"Y" if a custom DELETE algorithm shall be used for this table</description>
      </parameter>
    </parameters>
    <log>
      <trans-log-table>
        <connection>${QF_DB_CONNECTION_LOGGING}</connection>
        <schema>${QF_LOG_TRANS_SCHEMA}</schema>
        <table>${QF_LOG_TRANS_TABLE}</table>
        <size_limit_lines />
        <interval />
        <timeout_days>${QF_LOG_TRANS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STATUS</id>
          <enabled>Y</enabled>
          <name>STATUS</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
          <subject />
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
          <subject />
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
          <subject />
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
          <subject />
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
          <subject />
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
          <subject />
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>STARTDATE</id>
          <enabled>Y</enabled>
          <name>STARTDATE</name>
        </field>
        <field>
          <id>ENDDATE</id>
          <enabled>Y</enabled>
          <name>ENDDATE</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>DEPDATE</id>
          <enabled>Y</enabled>
          <name>DEPDATE</name>
        </field>
        <field>
          <id>REPLAYDATE</id>
          <enabled>Y</enabled>
          <name>REPLAYDATE</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>Y</enabled>
          <name>LOG_FIELD</name>
        </field>
        <field>
          <id>EXECUTING_SERVER</id>
          <enabled>N</enabled>
          <name>EXECUTING_SERVER</name>
        </field>
        <field>
          <id>EXECUTING_USER</id>
          <enabled>N</enabled>
          <name>EXECUTING_USER</name>
        </field>
        <field>
          <id>CLIENT</id>
          <enabled>N</enabled>
          <name>CLIENT</name>
        </field>
      </trans-log-table>
      <perf-log-table>
        <connection>${QF_DB_CONNECTION_LOGGING}</connection>
        <schema>${QF_LOG_TRANSPERF_SCHEMA}</schema>
        <table>${QF_LOG_TRANSPERF_TABLE}</table>
        <interval />
        <timeout_days>${QF_LOG_TRANSPERF_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>SEQ_NR</id>
          <enabled>Y</enabled>
          <name>SEQ_NR</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>INPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>INPUT_BUFFER_ROWS</name>
        </field>
        <field>
          <id>OUTPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>OUTPUT_BUFFER_ROWS</name>
        </field>
      </perf-log-table>
      <channel-log-table>
        <connection>${QF_DB_CONNECTION_LOGGING}</connection>
        <schema>${QF_LOG_CHANNEL_SCHEMA}</schema>
        <table>${QF_LOG_CHANNEL_TABLE}</table>
        <timeout_days>${QF_LOG_CHANNEL_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>LOGGING_OBJECT_TYPE</id>
          <enabled>Y</enabled>
          <name>LOGGING_OBJECT_TYPE</name>
        </field>
        <field>
          <id>OBJECT_NAME</id>
          <enabled>Y</enabled>
          <name>OBJECT_NAME</name>
        </field>
        <field>
          <id>OBJECT_COPY</id>
          <enabled>Y</enabled>
          <name>OBJECT_COPY</name>
        </field>
        <field>
          <id>REPOSITORY_DIRECTORY</id>
          <enabled>Y</enabled>
          <name>REPOSITORY_DIRECTORY</name>
        </field>
        <field>
          <id>FILENAME</id>
          <enabled>Y</enabled>
          <name>FILENAME</name>
        </field>
        <field>
          <id>OBJECT_ID</id>
          <enabled>Y</enabled>
          <name>OBJECT_ID</name>
        </field>
        <field>
          <id>OBJECT_REVISION</id>
          <enabled>Y</enabled>
          <name>OBJECT_REVISION</name>
        </field>
        <field>
          <id>PARENT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>PARENT_CHANNEL_ID</name>
        </field>
        <field>
          <id>ROOT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>ROOT_CHANNEL_ID</name>
        </field>
      </channel-log-table>
      <step-log-table>
        <connection>${QF_DB_CONNECTION_LOGGING}</connection>
        <schema>${QF_LOG_TRANSSTEP_SCHEMA}</schema>
        <table>${QF_LOG_TRANSSTEP_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSSTEP_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>N</enabled>
          <name>LOG_FIELD</name>
        </field>
      </step-log-table>
      <metrics-log-table>
        <connection>${QF_DB_CONNECTION_LOGGING}</connection>
        <schema>${QF_LOG_TRANSMETRICS_SCHEMA}</schema>
        <table>${QF_LOG_TRANSMETRICS_TABLE}</table>
        <timeout_days>${QF_LOG_TRANSMETRICS_TIMEOUT_IN_DAYS}</timeout_days>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>METRICS_DATE</id>
          <enabled>Y</enabled>
          <name>METRICS_DATE</name>
        </field>
        <field>
          <id>METRICS_CODE</id>
          <enabled>Y</enabled>
          <name>METRICS_CODE</name>
        </field>
        <field>
          <id>METRICS_DESCRIPTION</id>
          <enabled>Y</enabled>
          <name>METRICS_DESCRIPTION</name>
        </field>
        <field>
          <id>METRICS_SUBJECT</id>
          <enabled>Y</enabled>
          <name>METRICS_SUBJECT</name>
        </field>
        <field>
          <id>METRICS_TYPE</id>
          <enabled>Y</enabled>
          <name>METRICS_TYPE</name>
        </field>
        <field>
          <id>METRICS_VALUE</id>
          <enabled>Y</enabled>
          <name>METRICS_VALUE</name>
        </field>
      </metrics-log-table>
    </log>
    <maxdate>
      <connection />
      <table />
      <field />
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file />
    <capture_step_performance>Y</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
    <created_user>-</created_user>
    <created_date>2016/04/03 09:57:16.279</created_date>
    <modified_user>-</modified_user>
    <modified_date>2017/10/26 09:57:07.160</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA=</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
    <notepad>
      <note>This transformation uses ETL Metadata injection to "mark rows for deletion" from a table in a source database that have been archived/mirrored to a target table in a
target database. This transformation sets the column:

	PARAM_CAN_DELETE_ROW_SOURCE_COLNAME

of the *source* table. This is a generic algorithm that can work with *any* table, as long as the necessary metadata is available to be injected.
This transformation and has parameters:

	PARAM_CDC_LAST_LOAD_UTC								Timestamp for when the target DB was most recently updated successfully
																Used to ensure that we do not delete rows that are not yet fully archived/mirrored.
	PARAM_TABLE_META_ID									Primary key of etl.table_meta row for "source" table from which rows will be deleted
	PARAM_USE_CUSTOM_DELETE_ALGORITHM					"Y" if a custom DELETE algorithm shall be used for this table
	PARAM_ROW_CAN_BE_DELETED_FROM_SECONDS			Number of seconds after the "row_can_be_deleted_from" timestamp that an archived row can be deleted
	PARAM_DYN_DB_CONN_SOURCE_DB_HOST					for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_PORT					for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_DATABASE			for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_USERNAME			for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_PASSWORD			for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_URL					for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_SOURCE_DB_DRIVE					for source DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_HOST					for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_PORT					for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_DATABASE				for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_USERNAME			for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_PASSWORD			for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_DRIVER				for target DB "dynamic" database connections
	PARAM_DYN_DB_CONN_TARGET_DB_URL					for target DB "dynamic" database connections
	PARAM_SOURCE_DB_ID										ID the "source" database containing tables will be mirrored to a "target" database
	PARAM_SOURCE_SCHEMA									Name of schema containing source table to compare to target table
	PARAM_SOURCE_TABLE									Name of source table to compare to target table
	PARAM_LAST_UPDATED_ON_SOURCE_COLNAME			Column of source table that acts as a "last_updated_on" timestamp column
	PARAM_ROW_CAN_BE_DELETED_FROM_SOURCE_COLNAME	Column of source table that acts as a "row_can_be_deleted_from" timestamp column
	PARAM_CAN_DELETE_ROW_SOURCE_COLNAME				Column of source table that indicates if the row can be deleted immediately
	PARAM_TARGET_DB_ID										ID of the target database for which rows of the source DB tables will be "marked for deletion"
	PARAM_TARGET_SCHEMA									Name of schema containing target table to compare with (not currently used)
	PARAM_TARGET_TABLE										Name of target table to compare with (not currently used)</note>
      <xloc>0</xloc>
      <yloc>0</yloc>
      <width>1011</width>
      <heigth>514</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>The query in this job entry must match the query in step 
"Are primary key columns configured for this table?" in
the parent job, "jb_target-mark_rows_for_deletion-table".
This is to avoid a PDI runtime error that will occur here if
an empty stream is sent to an "ETL Metadata Injection"
step. To avoid that possibility here, we check in the parent
job that the metadata is available before executing this
transformation. This should never occur in practice, but
we check anyway in order to provide a clear warning
message, rather than letting PDI choke on this problem.</note>
      <xloc>368</xloc>
      <yloc>720</yloc>
      <width>348</width>
      <heigth>150</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>255</backgroundcolorgreen>
      <backgroundcolorblue>0</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>This "can delete row "column name must be injected,
even though there exists parameter
PARAM_CAN_DELETE_ROW_SOURCE_COLNAME
because I don't think you can insert a PDI variable
into the "Update" step of the template
transformation where this column name is required.</note>
      <xloc>720</xloc>
      <yloc>592</yloc>
      <width>316</width>
      <heigth>94</heigth>
      <fontname>Ubuntu</fontname>
      <fontsize>10</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <connection>
    <name>etl_db</name>
    <server>${QF_ETL_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_ETL_DB_DATABASE}</database>
    <port>${QF_ETL_DB_PORT}</port>
    <username>${QF_ETL_DB_USERNAME}</username>
    <password>${QF_ETL_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_ETL_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <connection>
    <name>logging_db</name>
    <server>${QF_LOGGING_DB_HOST}</server>
    <type>POSTGRESQL</type>
    <access>Native</access>
    <database>${QF_LOGGING_DB_DATABASE}</database>
    <port>${QF_LOGGING_DB_PORT}</port>
    <username>${QF_LOGGING_DB_USERNAME}</username>
    <password>${QF_LOGGING_DB_PASSWORD}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>${QF_LOGGING_DB_PORT}</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <order>
    <hop>
      <from>Source DB primary key column names</from>
      <to>ETL Metadata Injection: tmplt_target-mark_rows_for_deletion-column</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>SELECT statement for source DB table</from>
      <to>ETL Metadata Injection: tmplt_target-mark_rows_for_deletion-column</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Source DB "can_delete_row" column metadata</from>
      <to>ETL Metadata Injection: tmplt_target-mark_rows_for_deletion-column</to>
      <enabled>Y</enabled>
    </hop>
  </order>
  <step>
    <name>ETL Metadata Injection: tmplt_target-mark_rows_for_deletion-column</name>
    <type>MetaInject</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <specification_method>rep_name</specification_method>
    <trans_object_id />
    <trans_name>tmplt_target-mark_rows_for_deletion-column</trans_name>
    <filename />
    <directory_path>${Internal.Entry.Current.Directory}</directory_path>
    <source_step />
    <source_output_fields>    </source_output_fields>
    <target_file />
    <no_execution>N</no_execution>
    <stream_source_step />
    <stream_target_step />
    <mappings>
      <mapping>
        <target_step_name>Update: Mark rows for deletion</target_step_name>
        <target_attribute_key>UPDATE_LOOKUP</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Source DB "can_delete_row" column metadata</source_step>
        <source_field>can_delete_row_col_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Update: Mark rows for deletion</target_step_name>
        <target_attribute_key>KEY_CONDITION</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Source DB primary key column names</source_step>
        <source_field>key_field_value_comparator</source_field>
      </mapping>
      <mapping>
        <target_step_name>Update: Mark rows for deletion</target_step_name>
        <target_attribute_key>UPDATE_STREAM</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Source DB "can_delete_row" column metadata</source_step>
        <source_field>true_field_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Update: Mark rows for deletion</target_step_name>
        <target_attribute_key>KEY_LOOKUP</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Source DB primary key column names</source_step>
        <source_field>source_key_col_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Get primary key column(s) from source DB table</target_step_name>
        <target_attribute_key>SQL</target_attribute_key>
        <target_detail>N</target_detail>
        <source_step>SELECT statement for source DB table</source_step>
        <source_field>select_source_rows_sql</source_field>
      </mapping>
      <mapping>
        <target_step_name>Update: Mark rows for deletion</target_step_name>
        <target_attribute_key>KEY_STREAM</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Source DB primary key column names</source_step>
        <source_field>source_key_col_name</source_field>
      </mapping>
      <mapping>
        <target_step_name>Update: Mark rows for deletion</target_step_name>
        <target_attribute_key>KEY_STREAM2</target_attribute_key>
        <target_detail>Y</target_detail>
        <source_step>Source DB primary key column names</source_step>
        <source_field>no_field</source_field>
      </mapping>
    </mappings>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>208</xloc>
      <yloc>640</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>SELECT statement for source DB table</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>etl_db</connection>
    <sql>WITH
    -- Create table with a string column that contains the primary key column(s) from the 
    -- source (OBO) table:
    select_list AS (
        SELECT 
            -- POSTGRESQL-SPECIFIC
          --array_to_string(array_agg(source_column_name ORDER BY primary_key_column_order ASC), ',') AS "str_value"   &lt;- Why not use this?
            array_to_string(array_agg(source_column_name ORDER BY column_meta_id ASC), ',') AS "str_value"
        FROM 
            etl.column_meta 
        WHERE 
            table_meta_id = ${PARAM_TABLE_META_ID} AND 
            is_primary_key_column = true 
    ),
    -- Create table with a string column that contains the "ORDER BY" clause. 
    -- This consists of the column(s) that make up the primary key for the 
    -- source (OBO) table.
    orderby_list AS (
        SELECT 
           -- POSTGRESQL-SPECIFIC
            array_to_string(array_agg(source_column_name ORDER BY primary_key_column_order ASC), ',') AS "str_value"
        FROM 
            etl.column_meta 
        WHERE 
            table_meta_id = ${PARAM_TABLE_META_ID} AND 
            is_primary_key_column = true
    )
SELECT
    -- Create SELECT statement to select rows from source (OBO) table to mark for deletion.
    -- The WHERE clause includes only rows that should have been archived/mirrored.
    -- Only select rows with "can_delete_row" column = false because only thoses rows need to have this column updated to true.
    -- This will greatly reduce the number of rows selected here if the rows with "can_delete_row" are not currently being deleted.
    'SELECT ' || CAST(select_list.str_value AS VARCHAR) || 
    ' FROM ${PARAM_SOURCE_SCHEMA}.${PARAM_SOURCE_TABLE} ' || 
    'WHERE ${PARAM_ROW_CAN_BE_DELETED_FROM_SOURCE_COLNAME} + INTERVAL ''${PARAM_ROW_CAN_BE_DELETED_FROM_SECONDS} seconds'' &lt; TIMESTAMP ''${PARAM_CDC_LAST_LOAD_UTC}'' ' ||
    ' AND ${PARAM_CAN_DELETE_ROW_SOURCE_COLNAME}=false ' ||
    'ORDER BY ' || CAST(orderby_list.str_value AS VARCHAR) 
    AS "select_source_rows_sql" 
FROM
    select_list
CROSS JOIN
    orderby_list</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>208</xloc>
      <yloc>544</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Source DB "can_delete_row" column metadata</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>etl_db</connection>
    <sql>SELECT
    source_column_name AS "can_delete_row_col_name",
    -- This is a "constant" stream that is used to assign "true" to the "can_delete_row" column.
    'true_field' AS "true_field_name" 
FROM 
    etl.column_meta 
WHERE 
    table_meta_id = ${PARAM_TABLE_META_ID} AND 
    is_can_delete_row_column = true</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>560</xloc>
      <yloc>640</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Source DB primary key column names</name>
    <type>TableInput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>etl_db</connection>
    <sql>SELECT
    source_column_name AS "source_key_col_name",
    '=' AS "key_field_value_comparator",
    -- "Stream field2" is not used in the "Update" step. Nevertheless, we must set 
    -- it to something or an error is thrown during ETL metadata injection. The
    -- only solution I have found is to inject an empty string for this field.
    '' AS "no_field" 
FROM 
    etl.column_meta 
WHERE 
    table_meta_id = ${PARAM_TABLE_META_ID} AND 
    is_primary_key_column = true
ORDER BY 
    primary_key_column_order</sql>
    <limit>0</limit>
    <lookup />
    <execute_each_row>N</execute_each_row>
    <variables_active>Y</variables_active>
    <lazy_conversion_active>N</lazy_conversion_active>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>208</xloc>
      <yloc>752</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step_error_handling>
  </step_error_handling>
  <slave-step-copy-partition-distribution>
  </slave-step-copy-partition-distribution>
  <slave_transformation>N</slave_transformation>
</transformation>
